<?xml version="1.0" encoding="utf-8"?>
<!-- Created by Leo: http://leoeditor.com/leo_toc.html -->
<leo_file xmlns:leo="http://leoeditor.com/namespaces/leo-python-editor/1.1" >
<leo_header file_format="2"/>
<globals/>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ekr.20221020070914.1"><vh>Python3.10/Lib/site-packages/coverage</vh></v>
<v t="ekr.20221020070914.2"><vh>@@clean annotate.py</vh>
<v t="ekr.20221020070914.3"><vh>class AnnotateReporter</vh>
<v t="ekr.20221020070914.4"><vh>AnnotateReporter.__init__</vh></v>
<v t="ekr.20221020070914.5"><vh>AnnotateReporter.blank_re = re.compile(r"/s*(#|$)")</vh></v>
<v t="ekr.20221020070914.6"><vh>AnnotateReporter.report</vh></v>
<v t="ekr.20221020070914.7"><vh>AnnotateReporter.annotate_file</vh></v>
</v>
</v>
<v t="ekr.20221020070914.8"><vh>@@clean bytecode.py</vh>
<v t="ekr.20221020070914.9"><vh>code_objects</vh></v>
</v>
<v t="ekr.20221020070914.10"><vh>@@clean cmdline.py</vh>
<v t="ekr.20221020070914.11"><vh>class Opts</vh></v>
<v t="ekr.20221020070914.12"><vh>class CoverageOptionParser</vh>
<v t="ekr.20221020070914.13"><vh>CoverageOptionParser.__init__</vh></v>
<v t="ekr.20221020070914.14"><vh>class OptionParserError</vh></v>
<v t="ekr.20221020070914.15"><vh>parse_args_ok</vh></v>
<v t="ekr.20221020070914.16"><vh>error</vh></v>
</v>
<v t="ekr.20221020070914.17"><vh>class GlobalOptionParser</vh>
<v t="ekr.20221020070914.18"><vh>GlobalOptionParser.__init__</vh></v>
</v>
<v t="ekr.20221020070914.19"><vh>class CmdOptionParser</vh>
<v t="ekr.20221020070914.20"><vh>CmdOptionParser.__init__</vh></v>
<v t="ekr.20221020070914.21"><vh>CmdOptionParser.__eq__</vh></v>
<v t="ekr.20221020070914.22"><vh>CmdOptionParser.__hash__ = None     # This object doesn't need to be hashed.</vh></v>
<v t="ekr.20221020070914.23"><vh>CmdOptionParser.get_prog_name</vh></v>
</v>
<v t="ekr.20221020070914.24"><vh>In lists of Opts, keep them alphabetized by the option names as they appear</vh></v>
<v t="ekr.20221020070914.25"><vh>show_help</vh></v>
<v t="ekr.20221020070914.26"><vh>OK, ERR, FAIL_UNDER = 0, 1, 2</vh></v>
<v t="ekr.20221020070914.27"><vh>class CoverageScript</vh>
<v t="ekr.20221020070914.28"><vh>CoverageScript.__init__</vh></v>
<v t="ekr.20221020070914.29"><vh>CoverageScript.command_line</vh></v>
<v t="ekr.20221020070914.30"><vh>CoverageScript.do_help</vh></v>
<v t="ekr.20221020070914.31"><vh>CoverageScript.do_run</vh></v>
<v t="ekr.20221020070914.32"><vh>CoverageScript.do_debug</vh></v>
</v>
<v t="ekr.20221020070914.33"><vh>unshell_list</vh></v>
<v t="ekr.20221020070914.34"><vh>unglob_args</vh></v>
<v t="ekr.20221020070914.35"><vh>HELP_TOPICS = {</vh></v>
<v t="ekr.20221020070914.36"><vh>main</vh></v>
</v>
<v t="ekr.20221020070914.37"><vh>@@clean collector.py</vh>
<v t="ekr.20221020070914.38"><vh>class Collector</vh>
<v t="ekr.20221020070914.39"><vh>Collector.__init__</vh></v>
<v t="ekr.20221020070914.40"><vh>Collector.__repr__</vh></v>
<v t="ekr.20221020070914.41"><vh>Collector.use_data</vh></v>
<v t="ekr.20221020070914.42"><vh>Collector.tracer_name</vh></v>
<v t="ekr.20221020070914.43"><vh>Collector._clear_data</vh></v>
<v t="ekr.20221020070914.44"><vh>Collector.reset</vh></v>
<v t="ekr.20221020070914.45"><vh>Collector._start_tracer</vh></v>
<v t="ekr.20221020070914.46"><vh>Collector.The trace function has to be set individually on each thread before</vh></v>
<v t="ekr.20221020070914.47"><vh>Collector._installation_trace</vh></v>
<v t="ekr.20221020070914.48"><vh>Collector.start</vh></v>
<v t="ekr.20221020070914.49"><vh>Collector.stop</vh></v>
<v t="ekr.20221020070914.50"><vh>Collector.pause</vh></v>
<v t="ekr.20221020070914.51"><vh>Collector.resume</vh></v>
<v t="ekr.20221020070914.52"><vh>Collector._activity</vh></v>
<v t="ekr.20221020070914.53"><vh>Collector.switch_context</vh></v>
<v t="ekr.20221020070914.54"><vh>Collector.disable_plugin</vh></v>
<v t="ekr.20221020070914.55"><vh>Collector.cached_mapped_file</vh></v>
<v t="ekr.20221020070914.56"><vh>Collector.mapped_file_dict</vh></v>
<v t="ekr.20221020070914.57"><vh>Collector.plugin_was_disabled</vh></v>
<v t="ekr.20221020070914.58"><vh>Collector.flush_data</vh></v>
</v>
</v>
<v t="ekr.20221020070914.59"><vh>@@clean config.py</vh>
<v t="ekr.20221020070914.60"><vh>class HandyConfigParser</vh>
<v t="ekr.20221020070914.61"><vh>HandyConfigParser.__init__</vh></v>
<v t="ekr.20221020070914.62"><vh>HandyConfigParser.read</vh></v>
<v t="ekr.20221020070914.63"><vh>HandyConfigParser.has_option</vh></v>
<v t="ekr.20221020070914.64"><vh>HandyConfigParser.has_section</vh></v>
<v t="ekr.20221020070914.65"><vh>HandyConfigParser.options</vh></v>
<v t="ekr.20221020070914.66"><vh>HandyConfigParser.get_section</vh></v>
<v t="ekr.20221020070914.67"><vh>HandyConfigParser.get</vh></v>
<v t="ekr.20221020070914.68"><vh>HandyConfigParser.getlist</vh></v>
<v t="ekr.20221020070914.69"><vh>HandyConfigParser.getregexlist</vh></v>
</v>
<v t="ekr.20221020070914.70"><vh>The default line exclusion regexes.</vh></v>
<v t="ekr.20221020070914.71"><vh>class CoverageConfig</vh>
<v t="ekr.20221020070914.72"><vh>CoverageConfig.__init__</vh></v>
<v t="ekr.20221020070914.73"><vh>CoverageConfig.MUST_BE_LIST = {</vh></v>
<v t="ekr.20221020070914.74"><vh>CoverageConfig.from_args</vh></v>
<v t="ekr.20221020070914.75"><vh>CoverageConfig.from_file</vh></v>
<v t="ekr.20221020070914.76"><vh>CoverageConfig.copy</vh></v>
<v t="ekr.20221020070914.77"><vh>CoverageConfig.CONCURRENCY_CHOICES = {"thread", "gevent", "greenlet", "eventlet", "multiprocessing"}</vh></v>
<v t="ekr.20221020070914.78"><vh>CoverageConfig._set_attr_from_config_option</vh></v>
<v t="ekr.20221020070914.79"><vh>CoverageConfig.get_plugin_options</vh></v>
<v t="ekr.20221020070914.80"><vh>CoverageConfig.set_option</vh></v>
<v t="ekr.20221020070914.81"><vh>CoverageConfig.get_option</vh></v>
<v t="ekr.20221020070914.82"><vh>CoverageConfig.post_process_file</vh></v>
<v t="ekr.20221020070914.83"><vh>CoverageConfig.post_process</vh></v>
<v t="ekr.20221020070914.84"><vh>CoverageConfig.debug_info</vh></v>
</v>
<v t="ekr.20221020070914.85"><vh>config_files_to_try</vh></v>
<v t="ekr.20221020070914.86"><vh>read_coverage_config</vh></v>
</v>
<v t="ekr.20221020070914.87"><vh>@@clean context.py</vh>
<v t="ekr.20221020070914.88"><vh>combine_context_switchers</vh>
<v t="ekr.20221020070914.89"><vh>should_start_context</vh></v>
</v>
<v t="ekr.20221020070914.90"><vh>should_start_context_test_function</vh></v>
<v t="ekr.20221020070914.91"><vh>qualname_from_frame</vh></v>
</v>
<v t="ekr.20221020070914.92"><vh>@@clean control.py</vh>
<v t="ekr.20221020070914.93"><vh>override_config</vh></v>
<v t="ekr.20221020070914.94"><vh>DEFAULT_DATAFILE = DefaultValue("MISSING")</vh></v>
<v t="ekr.20221020070914.95"><vh>class Coverage</vh>
<v t="ekr.20221020070914.96"><vh>Coverage.current</vh></v>
<v t="ekr.20221020070914.97"><vh>Coverage.__init__</vh></v>
<v t="ekr.20221020070914.98"><vh>Coverage._init</vh></v>
<v t="ekr.20221020070914.99"><vh>Coverage._post_init</vh></v>
<v t="ekr.20221020070914.100"><vh>Coverage._write_startup_debug</vh></v>
<v t="ekr.20221020070914.101"><vh>Coverage._should_trace</vh></v>
<v t="ekr.20221020070914.102"><vh>Coverage._check_include_omit_etc</vh></v>
<v t="ekr.20221020070914.103"><vh>Coverage._warn</vh></v>
<v t="ekr.20221020070914.104"><vh>Coverage._message</vh></v>
<v t="ekr.20221020070914.105"><vh>Coverage.get_option</vh></v>
<v t="ekr.20221020070914.106"><vh>Coverage.set_option</vh></v>
<v t="ekr.20221020070914.107"><vh>Coverage.load</vh></v>
<v t="ekr.20221020070914.108"><vh>Coverage._init_for_start</vh></v>
<v t="ekr.20221020070914.109"><vh>Coverage._init_data</vh></v>
<v t="ekr.20221020070914.110"><vh>Coverage.start</vh></v>
<v t="ekr.20221020070914.111"><vh>Coverage.stop</vh></v>
<v t="ekr.20221020070914.112"><vh>Coverage._atexit</vh></v>
<v t="ekr.20221020070914.113"><vh>Coverage._on_sigterm</vh></v>
<v t="ekr.20221020070914.114"><vh>Coverage.erase</vh></v>
<v t="ekr.20221020070914.115"><vh>Coverage.switch_context</vh></v>
<v t="ekr.20221020070914.116"><vh>Coverage.clear_exclude</vh></v>
<v t="ekr.20221020070914.117"><vh>Coverage.exclude</vh></v>
<v t="ekr.20221020070914.118"><vh>Coverage._exclude_regex_stale</vh></v>
<v t="ekr.20221020070914.119"><vh>Coverage._exclude_regex</vh></v>
<v t="ekr.20221020070914.120"><vh>Coverage.get_exclude_list</vh></v>
<v t="ekr.20221020070914.121"><vh>Coverage.save</vh></v>
<v t="ekr.20221020070914.122"><vh>Coverage.combine</vh></v>
<v t="ekr.20221020070914.123"><vh>Coverage.get_data</vh></v>
<v t="ekr.20221020070914.124"><vh>Coverage._post_save_work</vh></v>
<v t="ekr.20221020070914.125"><vh>Coverage.analysis</vh></v>
<v t="ekr.20221020070914.126"><vh>Coverage.analysis2</vh></v>
<v t="ekr.20221020070914.127"><vh>Coverage._analyze</vh></v>
<v t="ekr.20221020070914.128"><vh>Coverage._get_file_reporter</vh></v>
<v t="ekr.20221020070914.129"><vh>Coverage._get_file_reporters</vh></v>
<v t="ekr.20221020070914.130"><vh>Coverage.report</vh></v>
<v t="ekr.20221020070914.131"><vh>Coverage.annotate</vh></v>
<v t="ekr.20221020070914.132"><vh>Coverage.html_report</vh></v>
<v t="ekr.20221020070914.133"><vh>Coverage.xml_report</vh></v>
<v t="ekr.20221020070914.134"><vh>Coverage.json_report</vh></v>
<v t="ekr.20221020070914.135"><vh>Coverage.lcov_report</vh></v>
<v t="ekr.20221020070914.136"><vh>Coverage.sys_info</vh></v>
</v>
<v t="ekr.20221020070914.137"><vh>Mega debugging...</vh></v>
<v t="ekr.20221020070914.138"><vh>process_startup</vh></v>
<v t="ekr.20221020070914.139"><vh>_prevent_sub_process_measurement</vh></v>
</v>
<v t="ekr.20221020070914.140"><vh>@@clean data.py</vh>
<v t="ekr.20221020070914.141"><vh>line_counts</vh></v>
<v t="ekr.20221020070914.142"><vh>add_data_to_hash</vh></v>
<v t="ekr.20221020070914.143"><vh>combinable_files</vh></v>
<v t="ekr.20221020070914.144"><vh>combine_parallel_data</vh></v>
<v t="ekr.20221020070914.145"><vh>debug_data_file</vh></v>
</v>
<v t="ekr.20221020070914.146"><vh>@@clean debug.py</vh>
<v t="ekr.20221020070914.147"><vh>class DebugControl</vh>
<v t="ekr.20221020070914.148"><vh>DebugControl.__init__</vh></v>
<v t="ekr.20221020070914.149"><vh>DebugControl.__repr__</vh></v>
<v t="ekr.20221020070914.150"><vh>DebugControl.should</vh></v>
<v t="ekr.20221020070914.151"><vh>DebugControl.without_callers</vh></v>
<v t="ekr.20221020070914.152"><vh>DebugControl.write</vh></v>
</v>
<v t="ekr.20221020070914.153"><vh>class DebugControlString</vh>
<v t="ekr.20221020070914.154"><vh>DebugControlString.__init__</vh></v>
<v t="ekr.20221020070914.155"><vh>DebugControlString.get_output</vh></v>
</v>
<v t="ekr.20221020070914.156"><vh>class NoDebugging</vh></v>
<v t="ekr.20221020070914.157"><vh>info_header</vh></v>
<v t="ekr.20221020070914.158"><vh>info_formatter</vh></v>
<v t="ekr.20221020070914.159"><vh>write_formatted_info</vh></v>
<v t="ekr.20221020070914.160"><vh>short_stack</vh></v>
<v t="ekr.20221020070914.161"><vh>dump_stack_frames</vh></v>
<v t="ekr.20221020070914.162"><vh>clipped_repr</vh></v>
<v t="ekr.20221020070914.163"><vh>short_id</vh></v>
<v t="ekr.20221020070914.164"><vh>add_pid_and_tid</vh></v>
<v t="ekr.20221020070914.165"><vh>class SimpleReprMixin</vh>
<v t="ekr.20221020070914.166"><vh>SimpleReprMixin.__repr__</vh></v>
</v>
<v t="ekr.20221020070914.167"><vh>simplify</vh></v>
<v t="ekr.20221020070914.168"><vh>pp</vh></v>
<v t="ekr.20221020070914.169"><vh>filter_text</vh></v>
<v t="ekr.20221020070914.170"><vh>class CwdTracker</vh>
<v t="ekr.20221020070914.171"><vh>CwdTracker.__init__</vh></v>
<v t="ekr.20221020070914.172"><vh>CwdTracker.filter</vh></v>
</v>
<v t="ekr.20221020070914.173"><vh>class DebugOutputFile</vh>
<v t="ekr.20221020070914.174"><vh>DebugOutputFile.__init__</vh></v>
<v t="ekr.20221020070914.175"><vh>DebugOutputFile.SYS_MOD_NAME = '$coverage.debug.DebugOutputFile.the_one'</vh></v>
<v t="ekr.20221020070914.176"><vh>DebugOutputFile.get_one</vh></v>
<v t="ekr.20221020070914.177"><vh>DebugOutputFile.write</vh></v>
<v t="ekr.20221020070914.178"><vh>DebugOutputFile.flush</vh></v>
</v>
<v t="ekr.20221020070914.179"><vh>log</vh></v>
<v t="ekr.20221020070914.180"><vh>decorate_methods</vh>
<v t="ekr.20221020070914.181"><vh>_decorator</vh></v>
</v>
<v t="ekr.20221020070914.182"><vh>break_in_pudb</vh>
<v t="ekr.20221020070914.183"><vh>_wrapper</vh></v>
</v>
<v t="ekr.20221020070914.184"><vh>OBJ_IDS = itertools.count()</vh></v>
<v t="ekr.20221020070914.185"><vh>show_calls</vh>
<v t="ekr.20221020070914.186"><vh>_decorator</vh></v>
</v>
<v t="ekr.20221020070914.187"><vh>_clean_stack_line</vh></v>
</v>
<v t="ekr.20221020070914.188"><vh>@@clean disposition.py</vh>
<v t="ekr.20221020070914.189"><vh>class FileDisposition</vh></v>
<v t="ekr.20221020070914.190"><vh>FileDisposition "methods": FileDisposition is a pure value object, so it can</vh></v>
<v t="ekr.20221020070914.191"><vh>disposition_init</vh></v>
<v t="ekr.20221020070914.192"><vh>disposition_debug_msg</vh></v>
</v>
<v t="ekr.20221020070914.193"><vh>@@clean env.py</vh>
<v t="ekr.20221020070914.194"><vh>class PYBEHAVIOR</vh></v>
<v t="ekr.20221020070914.195"><vh>Coverage.py specifics.</vh></v>
<v t="ekr.20221020070914.196"><vh>debug_info</vh></v>
</v>
<v t="ekr.20221020070914.197"><vh>@@clean exceptions.py</vh>
<v t="ekr.20221020070914.198"><vh>class _BaseCoverageException</vh></v>
<v t="ekr.20221020070914.199"><vh>class CoverageException</vh></v>
<v t="ekr.20221020070914.200"><vh>class ConfigError</vh></v>
<v t="ekr.20221020070914.201"><vh>class DataError</vh></v>
<v t="ekr.20221020070914.202"><vh>class NoDataError</vh></v>
<v t="ekr.20221020070914.203"><vh>class NoSource</vh></v>
<v t="ekr.20221020070914.204"><vh>class NoCode</vh></v>
<v t="ekr.20221020070914.205"><vh>class NotPython</vh></v>
<v t="ekr.20221020070914.206"><vh>class PluginError</vh></v>
<v t="ekr.20221020070914.207"><vh>class _ExceptionDuringRun</vh></v>
<v t="ekr.20221020070914.208"><vh>class _StopEverything</vh></v>
<v t="ekr.20221020070914.209"><vh>class CoverageWarning</vh></v>
</v>
<v t="ekr.20221020070914.210"><vh>@@clean execfile.py</vh>
<v t="ekr.20221020070914.211"><vh>class DummyLoader</vh></v>
<v t="ekr.20221020070914.212"><vh>find_module</vh></v>
<v t="ekr.20221020070914.213"><vh>class PyRunner</vh>
<v t="ekr.20221020070914.214"><vh>PyRunner.__init__</vh></v>
<v t="ekr.20221020070914.215"><vh>PyRunner.prepare</vh></v>
<v t="ekr.20221020070914.216"><vh>PyRunner._prepare2</vh></v>
<v t="ekr.20221020070914.217"><vh>PyRunner.run</vh></v>
</v>
<v t="ekr.20221020070914.218"><vh>run_python_module</vh></v>
<v t="ekr.20221020070914.219"><vh>run_python_file</vh></v>
<v t="ekr.20221020070914.220"><vh>make_code_from_py</vh></v>
<v t="ekr.20221020070914.221"><vh>make_code_from_pyc</vh></v>
</v>
<v t="ekr.20221020070914.222"><vh>@@clean files.py</vh>
<v t="ekr.20221020070914.223"><vh>set_relative_directory</vh></v>
<v t="ekr.20221020070914.224"><vh>relative_directory</vh></v>
<v t="ekr.20221020070914.225"><vh>relative_filename</vh></v>
<v t="ekr.20221020070914.226"><vh>canonical_filename</vh></v>
<v t="ekr.20221020070914.227"><vh>MAX_FLAT = 100</vh></v>
<v t="ekr.20221020070914.228"><vh>flat_rootname</vh></v>
<v t="ekr.20221020070914.229"><vh>if env.WINDOWS:</vh></v>
<v t="ekr.20221020070914.230"><vh>abs_file</vh></v>
<v t="ekr.20221020070914.231"><vh>python_reported_file</vh></v>
<v t="ekr.20221020070914.232"><vh>RELATIVE_DIR = None</vh></v>
<v t="ekr.20221020070914.233"><vh>isabs_anywhere</vh></v>
<v t="ekr.20221020070914.234"><vh>prep_patterns</vh></v>
<v t="ekr.20221020070914.235"><vh>class TreeMatcher</vh>
<v t="ekr.20221020070914.236"><vh>TreeMatcher.__init__</vh></v>
<v t="ekr.20221020070914.237"><vh>TreeMatcher.__repr__</vh></v>
<v t="ekr.20221020070914.238"><vh>TreeMatcher.info</vh></v>
<v t="ekr.20221020070914.239"><vh>TreeMatcher.match</vh></v>
</v>
<v t="ekr.20221020070914.240"><vh>class ModuleMatcher</vh>
<v t="ekr.20221020070914.241"><vh>ModuleMatcher.__init__</vh></v>
<v t="ekr.20221020070914.242"><vh>ModuleMatcher.__repr__</vh></v>
<v t="ekr.20221020070914.243"><vh>ModuleMatcher.info</vh></v>
<v t="ekr.20221020070914.244"><vh>ModuleMatcher.match</vh></v>
</v>
<v t="ekr.20221020070914.245"><vh>class FnmatchMatcher</vh>
<v t="ekr.20221020070914.246"><vh>FnmatchMatcher.__init__</vh></v>
<v t="ekr.20221020070914.247"><vh>FnmatchMatcher.__repr__</vh></v>
<v t="ekr.20221020070914.248"><vh>FnmatchMatcher.info</vh></v>
<v t="ekr.20221020070914.249"><vh>FnmatchMatcher.match</vh></v>
</v>
<v t="ekr.20221020070914.250"><vh>sep</vh></v>
<v t="ekr.20221020070914.251"><vh>fnmatches_to_regex</vh></v>
<v t="ekr.20221020070914.252"><vh>class PathAliases</vh>
<v t="ekr.20221020070914.253"><vh>PathAliases.__init__</vh></v>
<v t="ekr.20221020070914.254"><vh>PathAliases.pprint</vh></v>
<v t="ekr.20221020070914.255"><vh>PathAliases.add</vh></v>
<v t="ekr.20221020070914.256"><vh>PathAliases.map</vh></v>
</v>
<v t="ekr.20221020070914.257"><vh>find_python_files</vh></v>
</v>
<v t="ekr.20221020070914.258"><vh>@@clean html.py</vh>
<v t="ekr.20221020070914.259"><vh>data_filename</vh></v>
<v t="ekr.20221020070914.260"><vh>read_data</vh></v>
<v t="ekr.20221020070914.261"><vh>write_html</vh></v>
<v t="ekr.20221020070914.262"><vh>class HtmlDataGeneration</vh>
<v t="ekr.20221020070914.263"><vh>HtmlDataGeneration.__init__</vh></v>
<v t="ekr.20221020070914.264"><vh>HtmlDataGeneration.data_for_file</vh></v>
</v>
<v t="ekr.20221020070914.265"><vh>class FileToReport</vh></v>
<v t="ekr.20221020070914.266"><vh>class HtmlReporter</vh>
<v t="ekr.20221020070914.267"><vh>HtmlReporter.__init__</vh></v>
<v t="ekr.20221020070914.268"><vh>HtmlReporter.report</vh></v>
<v t="ekr.20221020070914.269"><vh>HtmlReporter.make_directory</vh></v>
<v t="ekr.20221020070914.270"><vh>HtmlReporter.make_local_static_report_files</vh></v>
<v t="ekr.20221020070914.271"><vh>HtmlReporter.should_report_file</vh></v>
<v t="ekr.20221020070914.272"><vh>HtmlReporter.write_html_file</vh></v>
<v t="ekr.20221020070914.273"><vh>HtmlReporter.index_file</vh></v>
</v>
<v t="ekr.20221020070914.274"><vh>class IncrementalChecker</vh>
<v t="ekr.20221020070914.275"><vh>IncrementalChecker.__init__</vh></v>
<v t="ekr.20221020070914.276"><vh>IncrementalChecker.reset</vh></v>
<v t="ekr.20221020070914.277"><vh>IncrementalChecker.read</vh></v>
<v t="ekr.20221020070914.278"><vh>IncrementalChecker.write</vh></v>
<v t="ekr.20221020070914.279"><vh>IncrementalChecker.check_global_data</vh></v>
<v t="ekr.20221020070914.280"><vh>IncrementalChecker.can_skip_file</vh></v>
<v t="ekr.20221020070914.281"><vh>IncrementalChecker.file_hash</vh></v>
<v t="ekr.20221020070914.282"><vh>IncrementalChecker.set_file_hash</vh></v>
<v t="ekr.20221020070914.283"><vh>IncrementalChecker.index_info</vh></v>
<v t="ekr.20221020070914.284"><vh>IncrementalChecker.set_index_info</vh></v>
</v>
<v t="ekr.20221020070914.285"><vh>Helpers for templates and generating HTML</vh></v>
<v t="ekr.20221020070914.286"><vh>escape</vh></v>
<v t="ekr.20221020070914.287"><vh>pair</vh></v>
</v>
<v t="ekr.20221020070914.288"><vh>@@clean inorout.py</vh>
<v t="ekr.20221020070914.289"><vh>canonical_path</vh></v>
<v t="ekr.20221020070914.290"><vh>name_for_module</vh></v>
<v t="ekr.20221020070914.291"><vh>module_is_namespace</vh></v>
<v t="ekr.20221020070914.292"><vh>module_has_file</vh></v>
<v t="ekr.20221020070914.293"><vh>file_and_path_for_module</vh></v>
<v t="ekr.20221020070914.294"><vh>add_stdlib_paths</vh></v>
<v t="ekr.20221020070914.295"><vh>add_third_party_paths</vh></v>
<v t="ekr.20221020070914.296"><vh>add_coverage_paths</vh></v>
<v t="ekr.20221020070914.297"><vh>class InOrOut</vh>
<v t="ekr.20221020070914.298"><vh>InOrOut.__init__</vh></v>
<v t="ekr.20221020070914.299"><vh>InOrOut.configure</vh></v>
<v t="ekr.20221020070914.300"><vh>InOrOut.should_trace</vh></v>
<v t="ekr.20221020070914.301"><vh>InOrOut.check_include_omit_etc</vh></v>
<v t="ekr.20221020070914.302"><vh>InOrOut.warn_conflicting_settings</vh></v>
<v t="ekr.20221020070914.303"><vh>InOrOut.warn_already_imported_files</vh></v>
<v t="ekr.20221020070914.304"><vh>InOrOut.warn_unimported_source</vh></v>
<v t="ekr.20221020070914.305"><vh>InOrOut._warn_about_unmeasured_code</vh></v>
<v t="ekr.20221020070914.306"><vh>InOrOut.find_possibly_unexecuted_files</vh></v>
<v t="ekr.20221020070914.307"><vh>InOrOut._find_plugin_files</vh></v>
<v t="ekr.20221020070914.308"><vh>InOrOut._find_executable_files</vh></v>
<v t="ekr.20221020070914.309"><vh>InOrOut.sys_info</vh></v>
</v>
</v>
<v t="ekr.20221020070914.310"><vh>@@clean jsonreport.py</vh>
<v t="ekr.20221020070914.311"><vh>class JsonReporter</vh>
<v t="ekr.20221020070914.312"><vh>JsonReporter.__init__</vh></v>
<v t="ekr.20221020070914.313"><vh>JsonReporter.report</vh></v>
<v t="ekr.20221020070914.314"><vh>JsonReporter.report_one_file</vh></v>
</v>
<v t="ekr.20221020071523.1"><vh>_convert_branch_arcs</vh></v>
</v>
<v t="ekr.20221020070914.315"><vh>@@clean lcovreport.py</vh>
<v t="ekr.20221020070914.316"><vh>class LcovReporter</vh>
<v t="ekr.20221020070914.317"><vh>LcovReporter.__init__</vh></v>
<v t="ekr.20221020070914.318"><vh>LcovReporter.report</vh></v>
<v t="ekr.20221020070914.319"><vh>LcovReporter.get_lcov</vh></v>
</v>
</v>
<v t="ekr.20221020070914.320"><vh>@@clean misc.py</vh>
<v t="ekr.20221020070914.321"><vh>isolate_module</vh></v>
<v t="ekr.20221020070914.322"><vh>os = isolate_module(os)</vh></v>
<v t="ekr.20221020070914.323"><vh>class SysModuleSaver</vh>
<v t="ekr.20221020070914.324"><vh>SysModuleSaver.__init__</vh></v>
<v t="ekr.20221020070914.325"><vh>SysModuleSaver.restore</vh></v>
</v>
<v t="ekr.20221020070914.326"><vh>sys_modules_saved</vh></v>
<v t="ekr.20221020070914.327"><vh>import_third_party</vh></v>
<v t="ekr.20221020070914.328"><vh>dummy_decorator_with_args</vh></v>
<v t="ekr.20221020070914.329"><vh>Use PyContracts for assertion testing on parameters and returns, but only if</vh></v>
<v t="ekr.20221020070914.330"><vh>nice_pair</vh></v>
<v t="ekr.20221020070914.331"><vh>expensive</vh></v>
<v t="ekr.20221020070914.332"><vh>bool_or_none</vh></v>
<v t="ekr.20221020070914.333"><vh>join_regex</vh></v>
<v t="ekr.20221020070914.334"><vh>file_be_gone</vh></v>
<v t="ekr.20221020070914.335"><vh>ensure_dir</vh></v>
<v t="ekr.20221020070914.336"><vh>ensure_dir_for_file</vh></v>
<v t="ekr.20221020070914.337"><vh>output_encoding</vh></v>
<v t="ekr.20221020070914.338"><vh>class Hasher</vh>
<v t="ekr.20221020070914.339"><vh>Hasher.__init__</vh></v>
<v t="ekr.20221020070914.340"><vh>Hasher.update</vh></v>
<v t="ekr.20221020070914.341"><vh>Hasher.hexdigest</vh></v>
</v>
<v t="ekr.20221020070914.342"><vh>_needs_to_implement</vh></v>
<v t="ekr.20221020070914.343"><vh>class DefaultValue</vh>
<v t="ekr.20221020070914.344"><vh>DefaultValue.__init__</vh></v>
<v t="ekr.20221020070914.345"><vh>DefaultValue.__repr__</vh></v>
</v>
<v t="ekr.20221020070914.346"><vh>substitute_variables</vh>
<v t="ekr.20221020070914.347"><vh>dollar_replace</vh></v>
</v>
<v t="ekr.20221020070914.348"><vh>format_local_datetime</vh></v>
<v t="ekr.20221020070914.349"><vh>import_local_file</vh></v>
<v t="ekr.20221020070914.350"><vh>human_key</vh>
<v t="ekr.20221020070914.351"><vh>tryint</vh></v>
</v>
<v t="ekr.20221020070914.352"><vh>human_sorted</vh></v>
<v t="ekr.20221020070914.353"><vh>human_sorted_items</vh></v>
<v t="ekr.20221020070914.354"><vh>plural</vh></v>
</v>
<v t="ekr.20221020070914.355"><vh>@@clean multiproc.py</vh>
<v t="ekr.20221020070914.356"><vh>class ProcessWithCoverage</vh>
<v t="ekr.20221020070914.357"><vh>ProcessWithCoverage._bootstrap</vh></v>
</v>
<v t="ekr.20221020070914.358"><vh>class Stowaway</vh>
<v t="ekr.20221020070914.359"><vh>Stowaway.__init__</vh></v>
<v t="ekr.20221020070914.360"><vh>Stowaway.__getstate__</vh></v>
<v t="ekr.20221020070914.361"><vh>Stowaway.__setstate__</vh></v>
</v>
<v t="ekr.20221020070914.362"><vh>patch_multiprocessing</vh></v>
</v>
<v t="ekr.20221020070914.363"><vh>@@clean numbits.py</vh>
<v t="ekr.20221020070914.364"><vh>_to_blob</vh></v>
<v t="ekr.20221020070914.365"><vh>new_contract('blob', lambda v: isinstance(v, bytes))</vh></v>
<v t="ekr.20221020070914.366"><vh>nums_to_numbits</vh></v>
<v t="ekr.20221020070914.367"><vh>numbits_to_nums</vh></v>
<v t="ekr.20221020070914.368"><vh>numbits_union</vh></v>
<v t="ekr.20221020070914.369"><vh>numbits_intersection</vh></v>
<v t="ekr.20221020070914.370"><vh>numbits_any_intersection</vh></v>
<v t="ekr.20221020070914.371"><vh>num_in_numbits</vh></v>
<v t="ekr.20221020070914.372"><vh>register_sqlite_functions</vh></v>
</v>
<v t="ekr.20221020070914.373"><vh>@@clean parser.py</vh>
<v t="ekr.20221020070914.374"><vh>class PythonParser</vh>
<v t="ekr.20221020070914.375"><vh>PythonParser.__init__</vh></v>
<v t="ekr.20221020070914.376"><vh>PythonParser.lines_matching</vh></v>
<v t="ekr.20221020070914.377"><vh>PythonParser._raw_parse</vh></v>
<v t="ekr.20221020070914.378"><vh>PythonParser.first_line</vh></v>
<v t="ekr.20221020070914.379"><vh>PythonParser.first_lines</vh></v>
<v t="ekr.20221020070914.380"><vh>PythonParser.translate_lines</vh></v>
<v t="ekr.20221020070914.381"><vh>PythonParser.translate_arcs</vh></v>
<v t="ekr.20221020070914.382"><vh>PythonParser.parse_source</vh></v>
<v t="ekr.20221020070914.383"><vh>PythonParser.arcs</vh></v>
<v t="ekr.20221020070914.384"><vh>PythonParser._analyze_ast</vh></v>
<v t="ekr.20221020070914.385"><vh>PythonParser.exit_counts</vh></v>
<v t="ekr.20221020070914.386"><vh>PythonParser.missing_arc_description</vh></v>
</v>
<v t="ekr.20221020070914.387"><vh>class ByteParser</vh>
<v t="ekr.20221020070914.388"><vh>ByteParser.__init__</vh></v>
<v t="ekr.20221020070914.389"><vh>ByteParser.child_parsers</vh></v>
<v t="ekr.20221020070914.390"><vh>ByteParser._line_numbers</vh></v>
<v t="ekr.20221020070914.391"><vh>ByteParser._find_statements</vh></v>
</v>
<v t="ekr.20221020070914.392"><vh>AST analysis</vh></v>
<v t="ekr.20221020070914.393"><vh>class BlockBase</vh>
<v t="ekr.20221020070914.394"><vh>BlockBase.process_break_exits</vh></v>
<v t="ekr.20221020070914.395"><vh>BlockBase.process_continue_exits</vh></v>
<v t="ekr.20221020070914.396"><vh>BlockBase.process_raise_exits</vh></v>
<v t="ekr.20221020070914.397"><vh>BlockBase.process_return_exits</vh></v>
</v>
<v t="ekr.20221020070914.398"><vh>class LoopBlock</vh>
<v t="ekr.20221020070914.399"><vh>LoopBlock.__init__</vh></v>
<v t="ekr.20221020070914.400"><vh>LoopBlock.process_break_exits</vh></v>
<v t="ekr.20221020070914.401"><vh>LoopBlock.process_continue_exits</vh></v>
</v>
<v t="ekr.20221020070914.402"><vh>class FunctionBlock</vh>
<v t="ekr.20221020070914.403"><vh>FunctionBlock.__init__</vh></v>
<v t="ekr.20221020070914.404"><vh>FunctionBlock.process_raise_exits</vh></v>
<v t="ekr.20221020070914.405"><vh>FunctionBlock.process_return_exits</vh></v>
</v>
<v t="ekr.20221020070914.406"><vh>class TryBlock</vh>
<v t="ekr.20221020070914.407"><vh>TryBlock.__init__</vh></v>
<v t="ekr.20221020070914.408"><vh>TryBlock.process_break_exits</vh></v>
<v t="ekr.20221020070914.409"><vh>TryBlock.process_continue_exits</vh></v>
<v t="ekr.20221020070914.410"><vh>TryBlock.process_raise_exits</vh></v>
<v t="ekr.20221020070914.411"><vh>TryBlock.process_return_exits</vh></v>
</v>
<v t="ekr.20221020070914.412"><vh>class WithBlock</vh>
<v t="ekr.20221020070914.413"><vh>WithBlock.__init__</vh></v>
<v t="ekr.20221020070914.414"><vh>WithBlock._process_exits</vh></v>
<v t="ekr.20221020070914.415"><vh>WithBlock.process_break_exits</vh></v>
<v t="ekr.20221020070914.416"><vh>WithBlock.process_continue_exits</vh></v>
<v t="ekr.20221020070914.417"><vh>WithBlock.process_raise_exits</vh></v>
<v t="ekr.20221020070914.418"><vh>WithBlock.process_return_exits</vh></v>
</v>
<v t="ekr.20221020070914.419"><vh>class ArcStart</vh>
<v t="ekr.20221020070914.420"><vh>ArcStart.__new__</vh></v>
</v>
<v t="ekr.20221020070914.421"><vh>Define contract words that PyContract doesn't have.</vh></v>
<v t="ekr.20221020070914.422"><vh>class NodeList</vh>
<v t="ekr.20221020070914.423"><vh>NodeList.__init__</vh></v>
</v>
<v t="ekr.20221020070914.424"><vh>TODO: some add_arcs methods here don't add arcs, they return them. Rename them.</vh></v>
<v t="ekr.20221020070914.425"><vh>ast_parse</vh></v>
<v t="ekr.20221020070914.426"><vh>class AstArcAnalyzer</vh>
<v t="ekr.20221020070914.427"><vh>AstArcAnalyzer.__init__</vh></v>
<v t="ekr.20221020070914.428"><vh>AstArcAnalyzer.analyze</vh></v>
<v t="ekr.20221020070914.429"><vh>AstArcAnalyzer.add_arc</vh></v>
<v t="ekr.20221020070914.430"><vh>AstArcAnalyzer.nearest_blocks</vh></v>
<v t="ekr.20221020070914.431"><vh>AstArcAnalyzer.line_for_node</vh></v>
<v t="ekr.20221020070914.432"><vh>AstArcAnalyzer._line_decorated</vh></v>
<v t="ekr.20221020070914.433"><vh>AstArcAnalyzer._line__Assign</vh></v>
<v t="ekr.20221020070914.434"><vh>AstArcAnalyzer._line__ClassDef = _line_decorated</vh></v>
<v t="ekr.20221020070914.435"><vh>AstArcAnalyzer._line__Dict</vh></v>
<v t="ekr.20221020070914.436"><vh>AstArcAnalyzer._line__FunctionDef = _line_decorated</vh></v>
<v t="ekr.20221020070914.437"><vh>AstArcAnalyzer._line__List</vh></v>
<v t="ekr.20221020070914.438"><vh>AstArcAnalyzer._line__Module</vh></v>
<v t="ekr.20221020070914.439"><vh>AstArcAnalyzer.The node types that just flow to the next node with no complications.</vh></v>
<v t="ekr.20221020070914.440"><vh>AstArcAnalyzer.add_arcs</vh></v>
<v t="ekr.20221020070914.441"><vh>AstArcAnalyzer.add_body_arcs</vh></v>
<v t="ekr.20221020070914.442"><vh>AstArcAnalyzer.find_non_missing_node</vh></v>
<v t="ekr.20221020070914.443"><vh>AstArcAnalyzer.Missing nodes: _missing__*</vh></v>
<v t="ekr.20221020070914.444"><vh>AstArcAnalyzer._missing__If</vh></v>
<v t="ekr.20221020070914.445"><vh>AstArcAnalyzer._missing__NodeList</vh></v>
<v t="ekr.20221020070914.446"><vh>AstArcAnalyzer._missing__While</vh></v>
<v t="ekr.20221020070914.447"><vh>AstArcAnalyzer.is_constant_expr</vh></v>
<v t="ekr.20221020070914.448"><vh>AstArcAnalyzer.In the fullness of time, these might be good tests to write:</vh></v>
<v t="ekr.20221020070914.449"><vh>AstArcAnalyzer.process_break_exits</vh></v>
<v t="ekr.20221020070914.450"><vh>AstArcAnalyzer.process_continue_exits</vh></v>
<v t="ekr.20221020070914.451"><vh>AstArcAnalyzer.process_raise_exits</vh></v>
<v t="ekr.20221020070914.452"><vh>AstArcAnalyzer.process_return_exits</vh></v>
<v t="ekr.20221020070914.453"><vh>AstArcAnalyzer.Handlers: _handle__*</vh></v>
<v t="ekr.20221020070914.454"><vh>AstArcAnalyzer._handle__Break</vh></v>
<v t="ekr.20221020070914.455"><vh>AstArcAnalyzer._handle_decorated</vh></v>
<v t="ekr.20221020070914.456"><vh>AstArcAnalyzer._handle__ClassDef = _handle_decorated</vh></v>
<v t="ekr.20221020070914.457"><vh>AstArcAnalyzer._handle__Continue</vh></v>
<v t="ekr.20221020070914.458"><vh>AstArcAnalyzer._handle__For</vh></v>
<v t="ekr.20221020070914.459"><vh>AstArcAnalyzer._handle__AsyncFor = _handle__For</vh></v>
<v t="ekr.20221020070914.460"><vh>AstArcAnalyzer._handle__If</vh></v>
<v t="ekr.20221020070914.461"><vh>AstArcAnalyzer._handle__Match</vh></v>
<v t="ekr.20221020070914.462"><vh>AstArcAnalyzer._handle__NodeList</vh></v>
<v t="ekr.20221020070914.463"><vh>AstArcAnalyzer._handle__Raise</vh></v>
<v t="ekr.20221020070914.464"><vh>AstArcAnalyzer._handle__Return</vh></v>
<v t="ekr.20221020070914.465"><vh>AstArcAnalyzer._handle__Try</vh></v>
<v t="ekr.20221020070914.466"><vh>AstArcAnalyzer._combine_finally_starts</vh></v>
<v t="ekr.20221020070914.467"><vh>AstArcAnalyzer._handle__While</vh></v>
<v t="ekr.20221020070914.468"><vh>AstArcAnalyzer._handle__With</vh></v>
<v t="ekr.20221020070914.469"><vh>AstArcAnalyzer._handle__AsyncWith = _handle__With</vh></v>
<v t="ekr.20221020070914.470"><vh>AstArcAnalyzer._code_object__Module</vh></v>
<v t="ekr.20221020070914.471"><vh>AstArcAnalyzer._code_object__FunctionDef</vh></v>
<v t="ekr.20221020070914.472"><vh>AstArcAnalyzer._code_object__AsyncFunctionDef = _code_object__FunctionDef</vh></v>
<v t="ekr.20221020070914.473"><vh>AstArcAnalyzer._code_object__ClassDef</vh></v>
<v t="ekr.20221020070914.474"><vh>AstArcAnalyzer._make_expression_code_method</vh></v>
</v>
<v t="ekr.20221020070914.475"><vh>Code only used when dumping the AST for debugging.</vh></v>
<v t="ekr.20221020070914.476"><vh>_is_simple_value</vh></v>
<v t="ekr.20221020070914.477"><vh>ast_dump</vh></v>
</v>
<v t="ekr.20221020070914.478"><vh>@@clean phystokens.py</vh>
<v t="ekr.20221020070914.479"><vh>phys_tokens</vh></v>
<v t="ekr.20221020070914.480"><vh>class MatchCaseFinder</vh>
<v t="ekr.20221020070914.481"><vh>MatchCaseFinder.__init__</vh></v>
<v t="ekr.20221020070914.482"><vh>MatchCaseFinder.visit_Match</vh></v>
</v>
<v t="ekr.20221020070914.483"><vh>source_token_lines</vh></v>
<v t="ekr.20221020070914.484"><vh>class CachedTokenizer</vh>
<v t="ekr.20221020070914.485"><vh>CachedTokenizer.__init__</vh></v>
<v t="ekr.20221020070914.486"><vh>CachedTokenizer.generate_tokens</vh></v>
</v>
<v t="ekr.20221020070914.487"><vh>Create our generate_tokens cache as a callable replacement function.</vh></v>
<v t="ekr.20221020070914.488"><vh>source_encoding</vh></v>
<v t="ekr.20221020070914.489"><vh>compile_unicode</vh></v>
<v t="ekr.20221020070914.490"><vh>neuter_encoding_declaration</vh></v>
</v>
<v t="ekr.20221020070914.491"><vh>@@clean plugin.py</vh>
<v t="ekr.20221020070914.492"><vh>class CoveragePlugin</vh>
<v t="ekr.20221020070914.493"><vh>CoveragePlugin.file_tracer</vh></v>
<v t="ekr.20221020070914.494"><vh>CoveragePlugin.file_reporter</vh></v>
<v t="ekr.20221020070914.495"><vh>CoveragePlugin.dynamic_context</vh></v>
<v t="ekr.20221020070914.496"><vh>CoveragePlugin.find_executable_files</vh></v>
<v t="ekr.20221020070914.497"><vh>CoveragePlugin.configure</vh></v>
<v t="ekr.20221020070914.498"><vh>CoveragePlugin.sys_info</vh></v>
</v>
<v t="ekr.20221020070914.499"><vh>class FileTracer</vh>
<v t="ekr.20221020070914.500"><vh>FileTracer.source_filename</vh></v>
<v t="ekr.20221020070914.501"><vh>FileTracer.has_dynamic_source_filename</vh></v>
<v t="ekr.20221020070914.502"><vh>FileTracer.dynamic_source_filename</vh></v>
<v t="ekr.20221020070914.503"><vh>FileTracer.line_number_range</vh></v>
</v>
<v t="ekr.20221020070914.504"><vh>class FileReporter</vh>
<v t="ekr.20221020070914.505"><vh>FileReporter.__init__</vh></v>
<v t="ekr.20221020070914.506"><vh>FileReporter.__repr__</vh></v>
<v t="ekr.20221020070914.507"><vh>FileReporter.relative_filename</vh></v>
<v t="ekr.20221020070914.508"><vh>FileReporter.source</vh></v>
<v t="ekr.20221020070914.509"><vh>FileReporter.lines</vh></v>
<v t="ekr.20221020070914.510"><vh>FileReporter.excluded_lines</vh></v>
<v t="ekr.20221020070914.511"><vh>FileReporter.translate_lines</vh></v>
<v t="ekr.20221020070914.512"><vh>FileReporter.arcs</vh></v>
<v t="ekr.20221020070914.513"><vh>FileReporter.no_branch_lines</vh></v>
<v t="ekr.20221020070914.514"><vh>FileReporter.translate_arcs</vh></v>
<v t="ekr.20221020070914.515"><vh>FileReporter.exit_counts</vh></v>
<v t="ekr.20221020070914.516"><vh>FileReporter.missing_arc_description</vh></v>
<v t="ekr.20221020070914.517"><vh>FileReporter.source_token_lines</vh></v>
<v t="ekr.20221020070914.518"><vh>FileReporter.__eq__</vh></v>
<v t="ekr.20221020070914.519"><vh>FileReporter.__lt__</vh></v>
</v>
</v>
<v t="ekr.20221020070914.520"><vh>@@clean plugin_support.py</vh>
<v t="ekr.20221020070914.521"><vh>class Plugins</vh>
<v t="ekr.20221020070914.522"><vh>Plugins.__init__</vh></v>
<v t="ekr.20221020070914.523"><vh>Plugins.load_plugins</vh></v>
<v t="ekr.20221020070914.524"><vh>Plugins.add_file_tracer</vh></v>
<v t="ekr.20221020070914.525"><vh>Plugins.add_configurer</vh></v>
<v t="ekr.20221020070914.526"><vh>Plugins.add_dynamic_context</vh></v>
<v t="ekr.20221020070914.527"><vh>Plugins.add_noop</vh></v>
<v t="ekr.20221020070914.528"><vh>Plugins._add_plugin</vh></v>
<v t="ekr.20221020070914.529"><vh>Plugins.__bool__</vh></v>
<v t="ekr.20221020070914.530"><vh>Plugins.__iter__</vh></v>
<v t="ekr.20221020070914.531"><vh>Plugins.get</vh></v>
</v>
<v t="ekr.20221020070914.532"><vh>class LabelledDebug</vh>
<v t="ekr.20221020070914.533"><vh>LabelledDebug.__init__</vh></v>
<v t="ekr.20221020070914.534"><vh>LabelledDebug.add_label</vh></v>
<v t="ekr.20221020070914.535"><vh>LabelledDebug.message_prefix</vh></v>
<v t="ekr.20221020070914.536"><vh>LabelledDebug.write</vh></v>
</v>
<v t="ekr.20221020070914.537"><vh>class DebugPluginWrapper</vh>
<v t="ekr.20221020070914.538"><vh>DebugPluginWrapper.__init__</vh></v>
<v t="ekr.20221020070914.539"><vh>DebugPluginWrapper.file_tracer</vh></v>
<v t="ekr.20221020070914.540"><vh>DebugPluginWrapper.file_reporter</vh></v>
<v t="ekr.20221020070914.541"><vh>DebugPluginWrapper.dynamic_context</vh></v>
<v t="ekr.20221020070914.542"><vh>DebugPluginWrapper.find_executable_files</vh></v>
<v t="ekr.20221020070914.543"><vh>DebugPluginWrapper.configure</vh></v>
<v t="ekr.20221020070914.544"><vh>DebugPluginWrapper.sys_info</vh></v>
</v>
<v t="ekr.20221020070914.545"><vh>class DebugFileTracerWrapper</vh>
<v t="ekr.20221020070914.546"><vh>DebugFileTracerWrapper.__init__</vh></v>
<v t="ekr.20221020070914.547"><vh>DebugFileTracerWrapper._show_frame</vh></v>
<v t="ekr.20221020070914.548"><vh>DebugFileTracerWrapper.source_filename</vh></v>
<v t="ekr.20221020070914.549"><vh>DebugFileTracerWrapper.has_dynamic_source_filename</vh></v>
<v t="ekr.20221020070914.550"><vh>DebugFileTracerWrapper.dynamic_source_filename</vh></v>
<v t="ekr.20221020070914.551"><vh>DebugFileTracerWrapper.line_number_range</vh></v>
</v>
<v t="ekr.20221020070914.552"><vh>class DebugFileReporterWrapper</vh>
<v t="ekr.20221020070914.553"><vh>DebugFileReporterWrapper.__init__</vh></v>
<v t="ekr.20221020070914.554"><vh>DebugFileReporterWrapper.relative_filename</vh></v>
<v t="ekr.20221020070914.555"><vh>DebugFileReporterWrapper.lines</vh></v>
<v t="ekr.20221020070914.556"><vh>DebugFileReporterWrapper.excluded_lines</vh></v>
<v t="ekr.20221020070914.557"><vh>DebugFileReporterWrapper.translate_lines</vh></v>
<v t="ekr.20221020070914.558"><vh>DebugFileReporterWrapper.translate_arcs</vh></v>
<v t="ekr.20221020070914.559"><vh>DebugFileReporterWrapper.no_branch_lines</vh></v>
<v t="ekr.20221020070914.560"><vh>DebugFileReporterWrapper.exit_counts</vh></v>
<v t="ekr.20221020070914.561"><vh>DebugFileReporterWrapper.arcs</vh></v>
<v t="ekr.20221020070914.562"><vh>DebugFileReporterWrapper.source</vh></v>
<v t="ekr.20221020070914.563"><vh>DebugFileReporterWrapper.source_token_lines</vh></v>
</v>
</v>
<v t="ekr.20221020070914.564"><vh>@@clean python.py</vh>
<v t="ekr.20221020070914.565"><vh>read_python_source</vh></v>
<v t="ekr.20221020070914.566"><vh>get_python_source</vh></v>
<v t="ekr.20221020070914.567"><vh>get_zip_bytes</vh></v>
<v t="ekr.20221020070914.568"><vh>source_for_file</vh></v>
<v t="ekr.20221020070914.569"><vh>source_for_morf</vh></v>
<v t="ekr.20221020070914.570"><vh>class PythonFileReporter</vh>
<v t="ekr.20221020070914.571"><vh>PythonFileReporter.__init__</vh></v>
<v t="ekr.20221020070914.572"><vh>PythonFileReporter.__repr__</vh></v>
<v t="ekr.20221020070914.573"><vh>PythonFileReporter.relative_filename</vh></v>
<v t="ekr.20221020070914.574"><vh>PythonFileReporter.parser</vh></v>
<v t="ekr.20221020070914.575"><vh>PythonFileReporter.lines</vh></v>
<v t="ekr.20221020070914.576"><vh>PythonFileReporter.excluded_lines</vh></v>
<v t="ekr.20221020070914.577"><vh>PythonFileReporter.translate_lines</vh></v>
<v t="ekr.20221020070914.578"><vh>PythonFileReporter.translate_arcs</vh></v>
<v t="ekr.20221020070914.579"><vh>PythonFileReporter.no_branch_lines</vh></v>
<v t="ekr.20221020070914.580"><vh>PythonFileReporter.arcs</vh></v>
<v t="ekr.20221020070914.581"><vh>PythonFileReporter.exit_counts</vh></v>
<v t="ekr.20221020070914.582"><vh>PythonFileReporter.missing_arc_description</vh></v>
<v t="ekr.20221020070914.583"><vh>PythonFileReporter.source</vh></v>
<v t="ekr.20221020070914.584"><vh>PythonFileReporter.should_be_python</vh></v>
<v t="ekr.20221020070914.585"><vh>PythonFileReporter.source_token_lines</vh></v>
</v>
</v>
<v t="ekr.20221020070914.586"><vh>@@clean pytracer.py</vh>
<v t="ekr.20221020070914.587"><vh>class PyTracer</vh>
<v t="ekr.20221020070914.588"><vh>PyTracer.__init__</vh></v>
<v t="ekr.20221020070914.589"><vh>PyTracer.__repr__</vh></v>
<v t="ekr.20221020070914.590"><vh>PyTracer.log</vh></v>
<v t="ekr.20221020070914.591"><vh>PyTracer._trace</vh></v>
<v t="ekr.20221020070914.592"><vh>PyTracer.start</vh></v>
<v t="ekr.20221020070914.593"><vh>PyTracer.stop</vh></v>
<v t="ekr.20221020070914.594"><vh>PyTracer.activity</vh></v>
<v t="ekr.20221020070914.595"><vh>PyTracer.reset_activity</vh></v>
<v t="ekr.20221020070914.596"><vh>PyTracer.get_stats</vh></v>
</v>
</v>
<v t="ekr.20221020070914.597"><vh>@@clean report.py</vh>
<v t="ekr.20221020070914.598"><vh>render_report</vh></v>
<v t="ekr.20221020070914.599"><vh>get_analysis_to_report</vh></v>
</v>
<v t="ekr.20221020070914.600"><vh>@@clean results.py</vh>
<v t="ekr.20221020070914.601"><vh>class Analysis</vh>
<v t="ekr.20221020070914.602"><vh>Analysis.__init__</vh></v>
<v t="ekr.20221020070914.603"><vh>Analysis.missing_formatted</vh></v>
<v t="ekr.20221020070914.604"><vh>Analysis.has_arcs</vh></v>
<v t="ekr.20221020070914.605"><vh>Analysis.arc_possibilities</vh></v>
<v t="ekr.20221020070914.606"><vh>Analysis.arcs_executed</vh></v>
<v t="ekr.20221020070914.607"><vh>Analysis.arcs_missing</vh></v>
<v t="ekr.20221020070914.608"><vh>Analysis.arcs_unpredicted</vh></v>
<v t="ekr.20221020070914.609"><vh>Analysis._branch_lines</vh></v>
<v t="ekr.20221020070914.610"><vh>Analysis._total_branches</vh></v>
<v t="ekr.20221020070914.611"><vh>Analysis.missing_branch_arcs</vh></v>
<v t="ekr.20221020070914.612"><vh>Analysis.executed_branch_arcs</vh></v>
<v t="ekr.20221020070914.613"><vh>Analysis.branch_stats</vh></v>
</v>
<v t="ekr.20221020070914.614"><vh>class Numbers</vh>
<v t="ekr.20221020070914.615"><vh>Numbers.__init__</vh></v>
<v t="ekr.20221020070914.616"><vh>Numbers.init_args</vh></v>
<v t="ekr.20221020070914.617"><vh>Numbers.n_executed</vh></v>
<v t="ekr.20221020070914.618"><vh>Numbers.n_executed_branches</vh></v>
<v t="ekr.20221020070914.619"><vh>Numbers.pc_covered</vh></v>
<v t="ekr.20221020070914.620"><vh>Numbers.pc_covered_str</vh></v>
<v t="ekr.20221020070914.621"><vh>Numbers.display_covered</vh></v>
<v t="ekr.20221020070914.622"><vh>Numbers.pc_str_width</vh></v>
<v t="ekr.20221020070914.623"><vh>Numbers.ratio_covered</vh></v>
<v t="ekr.20221020070914.624"><vh>Numbers.__add__</vh></v>
<v t="ekr.20221020070914.625"><vh>Numbers.__radd__</vh></v>
</v>
<v t="ekr.20221020070914.626"><vh>_line_ranges</vh></v>
<v t="ekr.20221020070914.627"><vh>format_lines</vh></v>
<v t="ekr.20221020070914.628"><vh>should_fail_under</vh></v>
</v>
<v t="ekr.20221020070914.629"><vh>@@clean sqldata.py</vh>
<v t="ekr.20221020070914.630"><vh>class CoverageData</vh>
<v t="ekr.20221020070914.631"><vh>CoverageData.__init__</vh></v>
<v t="ekr.20221020070914.632"><vh>CoverageData._locked</vh></v>
<v t="ekr.20221020070914.633"><vh>CoverageData._choose_filename</vh></v>
<v t="ekr.20221020070914.634"><vh>CoverageData._reset</vh></v>
<v t="ekr.20221020070914.635"><vh>CoverageData._open_db</vh></v>
<v t="ekr.20221020070914.636"><vh>CoverageData._read_db</vh></v>
<v t="ekr.20221020070914.637"><vh>CoverageData._init_db</vh></v>
<v t="ekr.20221020070914.638"><vh>CoverageData._connect</vh></v>
<v t="ekr.20221020070914.639"><vh>CoverageData.__bool__</vh></v>
<v t="ekr.20221020070914.640"><vh>CoverageData.dumps</vh></v>
<v t="ekr.20221020070914.641"><vh>CoverageData.loads</vh></v>
<v t="ekr.20221020070914.642"><vh>CoverageData._file_id</vh></v>
<v t="ekr.20221020070914.643"><vh>CoverageData._context_id</vh></v>
<v t="ekr.20221020070914.644"><vh>CoverageData.set_context</vh></v>
<v t="ekr.20221020070914.645"><vh>CoverageData._set_context_id</vh></v>
<v t="ekr.20221020070914.646"><vh>CoverageData.base_filename</vh></v>
<v t="ekr.20221020070914.647"><vh>CoverageData.data_filename</vh></v>
<v t="ekr.20221020070914.648"><vh>CoverageData.add_lines</vh></v>
<v t="ekr.20221020070914.649"><vh>CoverageData.add_arcs</vh></v>
<v t="ekr.20221020070914.650"><vh>CoverageData._choose_lines_or_arcs</vh></v>
<v t="ekr.20221020070914.651"><vh>CoverageData.add_file_tracers</vh></v>
<v t="ekr.20221020070914.652"><vh>CoverageData.touch_file</vh></v>
<v t="ekr.20221020070914.653"><vh>CoverageData.touch_files</vh></v>
<v t="ekr.20221020070914.654"><vh>CoverageData.update</vh></v>
<v t="ekr.20221020070914.655"><vh>CoverageData.erase</vh></v>
<v t="ekr.20221020070914.656"><vh>CoverageData.read</vh></v>
<v t="ekr.20221020070914.657"><vh>CoverageData.write</vh></v>
<v t="ekr.20221020070914.658"><vh>CoverageData._start_using</vh></v>
<v t="ekr.20221020070914.659"><vh>CoverageData.has_arcs</vh></v>
<v t="ekr.20221020070914.660"><vh>CoverageData.measured_files</vh></v>
<v t="ekr.20221020070914.661"><vh>CoverageData.measured_contexts</vh></v>
<v t="ekr.20221020070914.662"><vh>CoverageData.file_tracer</vh></v>
<v t="ekr.20221020070914.663"><vh>CoverageData.set_query_context</vh></v>
<v t="ekr.20221020070914.664"><vh>CoverageData.set_query_contexts</vh></v>
<v t="ekr.20221020070914.665"><vh>CoverageData.lines</vh></v>
<v t="ekr.20221020070914.666"><vh>CoverageData.arcs</vh></v>
<v t="ekr.20221020070914.667"><vh>CoverageData.contexts_by_lineno</vh></v>
<v t="ekr.20221020070914.668"><vh>CoverageData.sys_info</vh></v>
</v>
<v t="ekr.20221020070914.669"><vh>filename_suffix</vh></v>
<v t="ekr.20221020070914.670"><vh>class SqliteDb</vh>
<v t="ekr.20221020070914.671"><vh>SqliteDb.__init__</vh></v>
<v t="ekr.20221020070914.672"><vh>SqliteDb._connect</vh></v>
<v t="ekr.20221020070914.673"><vh>SqliteDb.close</vh></v>
<v t="ekr.20221020070914.674"><vh>SqliteDb.__enter__</vh></v>
<v t="ekr.20221020070914.675"><vh>SqliteDb.__exit__</vh></v>
<v t="ekr.20221020070914.676"><vh>SqliteDb.execute</vh></v>
<v t="ekr.20221020070914.677"><vh>SqliteDb.execute_for_rowid</vh></v>
<v t="ekr.20221020070914.678"><vh>SqliteDb.execute_one</vh></v>
<v t="ekr.20221020070914.679"><vh>SqliteDb.executemany</vh></v>
<v t="ekr.20221020070914.680"><vh>SqliteDb.executescript</vh></v>
<v t="ekr.20221020070914.681"><vh>SqliteDb.dump</vh></v>
</v>
<v t="ekr.20221020070914.682"><vh>_regexp</vh></v>
</v>
<v t="ekr.20221020070914.683"><vh>@@clean summary.py</vh>
<v t="ekr.20221020070914.684"><vh>class SummaryReporter</vh>
<v t="ekr.20221020070914.685"><vh>SummaryReporter.__init__</vh></v>
<v t="ekr.20221020070914.686"><vh>SummaryReporter.writeout</vh></v>
<v t="ekr.20221020070914.687"><vh>SummaryReporter.report</vh></v>
<v t="ekr.20221020070914.688"><vh>SummaryReporter.report_one_file</vh></v>
</v>
</v>
<v t="ekr.20221020070914.689"><vh>@@clean templite.py</vh>
<v t="ekr.20221020070914.690"><vh>class TempliteSyntaxError</vh></v>
<v t="ekr.20221020070914.691"><vh>class TempliteValueError</vh></v>
<v t="ekr.20221020070914.692"><vh>class CodeBuilder</vh>
<v t="ekr.20221020070914.693"><vh>CodeBuilder.__init__</vh></v>
<v t="ekr.20221020070914.694"><vh>CodeBuilder.__str__</vh></v>
<v t="ekr.20221020070914.695"><vh>CodeBuilder.add_line</vh></v>
<v t="ekr.20221020070914.696"><vh>CodeBuilder.add_section</vh></v>
<v t="ekr.20221020070914.697"><vh>CodeBuilder.INDENT_STEP = 4      # PEP8 says so!</vh></v>
<v t="ekr.20221020070914.698"><vh>CodeBuilder.indent</vh></v>
<v t="ekr.20221020070914.699"><vh>CodeBuilder.dedent</vh></v>
<v t="ekr.20221020070914.700"><vh>CodeBuilder.get_globals</vh></v>
</v>
<v t="ekr.20221020070914.701"><vh>class Templite</vh>
<v t="ekr.20221020070914.702"><vh>Templite.__init__</vh></v>
<v t="ekr.20221020070914.703"><vh>Templite._expr_code</vh></v>
<v t="ekr.20221020070914.704"><vh>Templite._syntax_error</vh></v>
<v t="ekr.20221020070914.705"><vh>Templite._variable</vh></v>
<v t="ekr.20221020070914.706"><vh>Templite.render</vh></v>
<v t="ekr.20221020070914.707"><vh>Templite._do_dots</vh></v>
</v>
</v>
<v t="ekr.20221020070914.708"><vh>@@clean tomlconfig.py</vh>
<v t="ekr.20221020070914.709"><vh>class TomlDecodeError</vh></v>
<v t="ekr.20221020070914.710"><vh>class TomlConfigParser</vh>
<v t="ekr.20221020070914.711"><vh>TomlConfigParser.__init__</vh></v>
<v t="ekr.20221020070914.712"><vh>TomlConfigParser.read</vh></v>
<v t="ekr.20221020070914.713"><vh>TomlConfigParser._get_section</vh></v>
<v t="ekr.20221020070914.714"><vh>TomlConfigParser._get</vh></v>
<v t="ekr.20221020070914.715"><vh>TomlConfigParser.has_option</vh></v>
<v t="ekr.20221020070914.716"><vh>TomlConfigParser.has_section</vh></v>
<v t="ekr.20221020070914.717"><vh>TomlConfigParser.options</vh></v>
<v t="ekr.20221020070914.718"><vh>TomlConfigParser.get_section</vh></v>
<v t="ekr.20221020070914.719"><vh>TomlConfigParser.get</vh></v>
<v t="ekr.20221020070914.720"><vh>TomlConfigParser._check_type</vh></v>
<v t="ekr.20221020070914.721"><vh>TomlConfigParser.getboolean</vh></v>
<v t="ekr.20221020070914.722"><vh>TomlConfigParser.getlist</vh></v>
<v t="ekr.20221020070914.723"><vh>TomlConfigParser.getregexlist</vh></v>
<v t="ekr.20221020070914.724"><vh>TomlConfigParser.getint</vh></v>
<v t="ekr.20221020070914.725"><vh>TomlConfigParser.getfloat</vh></v>
</v>
</v>
<v t="ekr.20221020070914.726"><vh>@@clean version.py</vh>
<v t="ekr.20221020070914.727"><vh>_make_version</vh></v>
<v t="ekr.20221020070914.728"><vh>_make_url</vh></v>
</v>
<v t="ekr.20221020070914.729"><vh>@@clean xmlreport.py</vh>
<v t="ekr.20221020070914.730"><vh>rate</vh></v>
<v t="ekr.20221020070914.731"><vh>class XmlReporter</vh>
<v t="ekr.20221020070914.732"><vh>XmlReporter.__init__</vh></v>
<v t="ekr.20221020070914.733"><vh>XmlReporter.report</vh></v>
<v t="ekr.20221020070914.734"><vh>XmlReporter.xml_file</vh></v>
</v>
<v t="ekr.20221020070914.735"><vh>serialize_xml</vh></v>
</v>
<v t="ekr.20221020070914.736"><vh>@@clean __init__.py</vh></v>
<v t="ekr.20221020070914.737"><vh>@@clean __main__.py</vh></v>
<v t="ekr.20221020070914.738"><vh>@path fullcoverage</vh>
<v t="ekr.20221020070914.739"><vh>@@clean encodings.py</vh>
<v t="ekr.20221020070914.740"><vh>class FullCoverageTracer</vh>
<v t="ekr.20221020070914.741"><vh>FullCoverageTracer.__init__</vh></v>
<v t="ekr.20221020070914.742"><vh>FullCoverageTracer.fullcoverage_trace</vh></v>
</v>
</v>
</v>
</vnodes>
<tnodes>
<t tx="ekr.20221020070914.1"></t>
<t tx="ekr.20221020070914.10">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Command-line support for coverage.py."""

import glob
import optparse     # pylint: disable=deprecated-module
import os
import os.path
import shlex
import sys
import textwrap
import traceback

import coverage
from coverage import Coverage
from coverage import env
from coverage.collector import CTracer
from coverage.config import CoverageConfig
from coverage.control import DEFAULT_DATAFILE
from coverage.data import combinable_files, debug_data_file
from coverage.debug import info_header, short_stack, write_formatted_info
from coverage.exceptions import _BaseCoverageException, _ExceptionDuringRun, NoSource
from coverage.execfile import PyRunner
from coverage.results import Numbers, should_fail_under

# When adding to this file, alphabetization is important.  Look for
# "alphabetize" comments throughout.

@others
# Profiling using ox_profile.  Install it from GitHub:
#   pip install git+https://github.com/emin63/ox_profile.git
#
# $set_env.py: COVERAGE_PROFILE - Set to use ox_profile.
_profile = os.environ.get("COVERAGE_PROFILE", "")
if _profile:                                                # pragma: debugging
    from ox_profile.core.launchers import SimpleLauncher    # pylint: disable=import-error
    original_main = main

    def main(argv=None):                                    # pylint: disable=function-redefined
        """A wrapper around main that profiles."""
        profiler = SimpleLauncher.launch()
        try:
            return original_main(argv)
        finally:
            data, _ = profiler.query(re_filter='coverage', max_records=100)
            print(profiler.show(query=data, limit=100, sep='', col=''))
            profiler.cancel()
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.100">def _write_startup_debug(self):
    """Write out debug info at startup if needed."""
    wrote_any = False
    with self._debug.without_callers():
        if self._debug.should("config"):
            config_info = self.config.debug_info()
            write_formatted_info(self._debug.write, "config", config_info)
            wrote_any = True

        if self._debug.should("sys"):
            write_formatted_info(self._debug.write, "sys", self.sys_info())
            for plugin in self._plugins:
                header = "sys: " + plugin._coverage_plugin_name
                info = plugin.sys_info()
                write_formatted_info(self._debug.write, header, info)
            wrote_any = True

        if self._debug.should("pybehave"):
            write_formatted_info(self._debug.write, "pybehave", env.debug_info())
            wrote_any = True

    if wrote_any:
        write_formatted_info(self._debug.write, "end", ())

</t>
<t tx="ekr.20221020070914.101">def _should_trace(self, filename, frame):
    """Decide whether to trace execution in `filename`.

    Calls `_should_trace_internal`, and returns the FileDisposition.

    """
    disp = self._inorout.should_trace(filename, frame)
    if self._debug.should('trace'):
        self._debug.write(disposition_debug_msg(disp))
    return disp

</t>
<t tx="ekr.20221020070914.102">def _check_include_omit_etc(self, filename, frame):
    """Check a file name against the include/omit/etc, rules, verbosely.

    Returns a boolean: True if the file should be traced, False if not.

    """
    reason = self._inorout.check_include_omit_etc(filename, frame)
    if self._debug.should('trace'):
        if not reason:
            msg = f"Including {filename!r}"
        else:
            msg = f"Not including {filename!r}: {reason}"
        self._debug.write(msg)

    return not reason

</t>
<t tx="ekr.20221020070914.103">def _warn(self, msg, slug=None, once=False):
    """Use `msg` as a warning.

    For warning suppression, use `slug` as the shorthand.

    If `once` is true, only show this warning once (determined by the
    slug.)

    """
    if self._no_warn_slugs is None:
        if self.config is not None:
            self._no_warn_slugs = list(self.config.disable_warnings)

    if self._no_warn_slugs is not None:
        if slug in self._no_warn_slugs:
            # Don't issue the warning
            return

    self._warnings.append(msg)
    if slug:
        msg = f"{msg} ({slug})"
    if self._debug is not None and self._debug.should('pid'):
        msg = f"[{os.getpid()}] {msg}"
    warnings.warn(msg, category=CoverageWarning, stacklevel=2)

    if once:
        self._no_warn_slugs.append(slug)

</t>
<t tx="ekr.20221020070914.104">def _message(self, msg):
    """Write a message to the user, if configured to do so."""
    if self._messages:
        print(msg)

</t>
<t tx="ekr.20221020070914.105">def get_option(self, option_name):
    """Get an option from the configuration.

    `option_name` is a colon-separated string indicating the section and
    option name.  For example, the ``branch`` option in the ``[run]``
    section of the config file would be indicated with `"run:branch"`.

    Returns the value of the option.  The type depends on the option
    selected.

    As a special case, an `option_name` of ``"paths"`` will return an
    OrderedDict with the entire ``[paths]`` section value.

    .. versionadded:: 4.0

    """
    return self.config.get_option(option_name)

</t>
<t tx="ekr.20221020070914.106">def set_option(self, option_name, value):
    """Set an option in the configuration.

    `option_name` is a colon-separated string indicating the section and
    option name.  For example, the ``branch`` option in the ``[run]``
    section of the config file would be indicated with ``"run:branch"``.

    `value` is the new value for the option.  This should be an
    appropriate Python value.  For example, use True for booleans, not the
    string ``"True"``.

    As an example, calling:

    .. code-block:: python

        cov.set_option("run:branch", True)

    has the same effect as this configuration file:

    .. code-block:: ini

        [run]
        branch = True

    As a special case, an `option_name` of ``"paths"`` will replace the
    entire ``[paths]`` section.  The value should be an OrderedDict.

    .. versionadded:: 4.0

    """
    self.config.set_option(option_name, value)

</t>
<t tx="ekr.20221020070914.107">def load(self):
    """Load previously-collected coverage data from the data file."""
    self._init()
    if self._collector:
        self._collector.reset()
    should_skip = self.config.parallel and not os.path.exists(self.config.data_file)
    if not should_skip:
        self._init_data(suffix=None)
    self._post_init()
    if not should_skip:
        self._data.read()

</t>
<t tx="ekr.20221020070914.108">def _init_for_start(self):
    """Initialization for start()"""
    # Construct the collector.
    concurrency = self.config.concurrency or []
    if "multiprocessing" in concurrency:
        if not patch_multiprocessing:
            raise ConfigError(                      # pragma: only jython
                "multiprocessing is not supported on this Python"
            )
        if self.config.config_file is None:
            raise ConfigError("multiprocessing requires a configuration file")
        patch_multiprocessing(rcfile=self.config.config_file)

    dycon = self.config.dynamic_context
    if not dycon or dycon == "none":
        context_switchers = []
    elif dycon == "test_function":
        context_switchers = [should_start_context_test_function]
    else:
        raise ConfigError(f"Don't understand dynamic_context setting: {dycon!r}")

    context_switchers.extend(
        plugin.dynamic_context for plugin in self._plugins.context_switchers
    )

    should_start_context = combine_context_switchers(context_switchers)

    self._collector = Collector(
        should_trace=self._should_trace,
        check_include=self._check_include_omit_etc,
        should_start_context=should_start_context,
        file_mapper=self._file_mapper,
        timid=self.config.timid,
        branch=self.config.branch,
        warn=self._warn,
        concurrency=concurrency,
    )

    suffix = self._data_suffix_specified
    if suffix:
        if not isinstance(suffix, str):
            # if data_suffix=True, use .machinename.pid.random
            suffix = True
    elif self.config.parallel:
        if suffix is None:
            suffix = True
        elif not isinstance(suffix, str):
            suffix = bool(suffix)
    else:
        suffix = None

    self._init_data(suffix)

    self._collector.use_data(self._data, self.config.context)

    # Early warning if we aren't going to be able to support plugins.
    if self._plugins.file_tracers and not self._collector.supports_plugins:
        self._warn(
            "Plugin file tracers ({}) aren't supported with {}".format(
                ", ".join(
                    plugin._coverage_plugin_name
                        for plugin in self._plugins.file_tracers
                ),
                self._collector.tracer_name(),
            )
        )
        for plugin in self._plugins.file_tracers:
            plugin._coverage_enabled = False

    # Create the file classifying substructure.
    self._inorout = InOrOut(
        warn=self._warn,
        debug=(self._debug if self._debug.should('trace') else None),
    )
    self._inorout.configure(self.config)
    self._inorout.plugins = self._plugins
    self._inorout.disp_class = self._collector.file_disposition_class

    # It's useful to write debug info after initing for start.
    self._should_write_debug = True

    # Register our clean-up handlers.
    atexit.register(self._atexit)
    if self.config.sigterm:
        is_main = (threading.current_thread() == threading.main_thread())
        if is_main and not env.WINDOWS:
            # The Python docs seem to imply that SIGTERM works uniformly even
            # on Windows, but that's not my experience, and this agrees:
            # https://stackoverflow.com/questions/35772001/x/35792192#35792192
            self._old_sigterm = signal.signal(signal.SIGTERM, self._on_sigterm)

</t>
<t tx="ekr.20221020070914.109">def _init_data(self, suffix):
    """Create a data file if we don't have one yet."""
    if self._data is None:
        # Create the data file.  We do this at construction time so that the
        # data file will be written into the directory where the process
        # started rather than wherever the process eventually chdir'd to.
        ensure_dir_for_file(self.config.data_file)
        self._data = CoverageData(
            basename=self.config.data_file,
            suffix=suffix,
            warn=self._warn,
            debug=self._debug,
            no_disk=self._no_disk,
        )

</t>
<t tx="ekr.20221020070914.11">class Opts:
    """A namespace class for individual options we'll build parsers from."""

    # Keep these entries alphabetized (roughly) by the option name as it
    # appears on the command line.

    append = optparse.make_option(
        '-a', '--append', action='store_true',
        help="Append coverage data to .coverage, otherwise it starts clean each time.",
    )
    keep = optparse.make_option(
        '', '--keep', action='store_true',
        help="Keep original coverage files, otherwise they are deleted.",
    )
    branch = optparse.make_option(
        '', '--branch', action='store_true',
        help="Measure branch coverage in addition to statement coverage.",
    )
    concurrency = optparse.make_option(
        '', '--concurrency', action='store', metavar="LIBS",
        help=(
            "Properly measure code using a concurrency library. " +
            "Valid values are: {}, or a comma-list of them."
        ).format(", ".join(sorted(CoverageConfig.CONCURRENCY_CHOICES))),
    )
    context = optparse.make_option(
        '', '--context', action='store', metavar="LABEL",
        help="The context label to record for this coverage run.",
    )
    contexts = optparse.make_option(
        '', '--contexts', action='store', metavar="REGEX1,REGEX2,...",
        help=(
            "Only display data from lines covered in the given contexts. " +
            "Accepts Python regexes, which must be quoted."
        ),
    )
    combine_datafile = optparse.make_option(
        '', '--data-file', action='store', metavar="DATAFILE",
        help=(
            "Base name of the data files to operate on. " +
            "Defaults to '.coverage'. [env: COVERAGE_FILE]"
        ),
    )
    input_datafile = optparse.make_option(
        '', '--data-file', action='store', metavar="INFILE",
        help=(
            "Read coverage data for report generation from this file. " +
            "Defaults to '.coverage'. [env: COVERAGE_FILE]"
        ),
    )
    output_datafile = optparse.make_option(
        '', '--data-file', action='store', metavar="OUTFILE",
        help=(
            "Write the recorded coverage data to this file. " +
            "Defaults to '.coverage'. [env: COVERAGE_FILE]"
        ),
    )
    debug = optparse.make_option(
        '', '--debug', action='store', metavar="OPTS",
        help="Debug options, separated by commas. [env: COVERAGE_DEBUG]",
    )
    directory = optparse.make_option(
        '-d', '--directory', action='store', metavar="DIR",
        help="Write the output files to DIR.",
    )
    fail_under = optparse.make_option(
        '', '--fail-under', action='store', metavar="MIN", type="float",
        help="Exit with a status of 2 if the total coverage is less than MIN.",
    )
    help = optparse.make_option(
        '-h', '--help', action='store_true',
        help="Get help on this command.",
    )
    ignore_errors = optparse.make_option(
        '-i', '--ignore-errors', action='store_true',
        help="Ignore errors while reading source files.",
    )
    include = optparse.make_option(
        '', '--include', action='store', metavar="PAT1,PAT2,...",
        help=(
            "Include only files whose paths match one of these patterns. " +
            "Accepts shell-style wildcards, which must be quoted."
        ),
    )
    pylib = optparse.make_option(
        '-L', '--pylib', action='store_true',
        help=(
            "Measure coverage even inside the Python installed library, " +
            "which isn't done by default."
        ),
    )
    show_missing = optparse.make_option(
        '-m', '--show-missing', action='store_true',
        help="Show line numbers of statements in each module that weren't executed.",
    )
    module = optparse.make_option(
        '-m', '--module', action='store_true',
        help=(
            "&lt;pyfile&gt; is an importable Python module, not a script path, " +
            "to be run as 'python -m' would run it."
        ),
    )
    omit = optparse.make_option(
        '', '--omit', action='store', metavar="PAT1,PAT2,...",
        help=(
            "Omit files whose paths match one of these patterns. " +
            "Accepts shell-style wildcards, which must be quoted."
        ),
    )
    output_xml = optparse.make_option(
        '-o', '', action='store', dest="outfile", metavar="OUTFILE",
        help="Write the XML report to this file. Defaults to 'coverage.xml'",
    )
    output_json = optparse.make_option(
        '-o', '', action='store', dest="outfile", metavar="OUTFILE",
        help="Write the JSON report to this file. Defaults to 'coverage.json'",
    )
    output_lcov = optparse.make_option(
        '-o', '', action='store', dest='outfile', metavar="OUTFILE",
        help="Write the LCOV report to this file. Defaults to 'coverage.lcov'",
    )
    json_pretty_print = optparse.make_option(
        '', '--pretty-print', action='store_true',
        help="Format the JSON for human readers.",
    )
    parallel_mode = optparse.make_option(
        '-p', '--parallel-mode', action='store_true',
        help=(
            "Append the machine name, process id and random number to the " +
            "data file name to simplify collecting data from " +
            "many processes."
        ),
    )
    precision = optparse.make_option(
        '', '--precision', action='store', metavar='N', type=int,
        help=(
            "Number of digits after the decimal point to display for " +
            "reported coverage percentages."
        ),
    )
    quiet = optparse.make_option(
        '-q', '--quiet', action='store_true',
        help="Don't print messages about what is happening.",
    )
    rcfile = optparse.make_option(
        '', '--rcfile', action='store',
        help=(
            "Specify configuration file. " +
            "By default '.coveragerc', 'setup.cfg', 'tox.ini', and " +
            "'pyproject.toml' are tried. [env: COVERAGE_RCFILE]"
        ),
    )
    show_contexts = optparse.make_option(
        '--show-contexts', action='store_true',
        help="Show contexts for covered lines.",
    )
    skip_covered = optparse.make_option(
        '--skip-covered', action='store_true',
        help="Skip files with 100% coverage.",
    )
    no_skip_covered = optparse.make_option(
        '--no-skip-covered', action='store_false', dest='skip_covered',
        help="Disable --skip-covered.",
    )
    skip_empty = optparse.make_option(
        '--skip-empty', action='store_true',
        help="Skip files with no code.",
    )
    sort = optparse.make_option(
        '--sort', action='store', metavar='COLUMN',
        help=(
            "Sort the report by the named column: name, stmts, miss, branch, brpart, or cover. " +
             "Default is name."
        ),
    )
    source = optparse.make_option(
        '', '--source', action='store', metavar="SRC1,SRC2,...",
        help="A list of directories or importable names of code to measure.",
    )
    timid = optparse.make_option(
        '', '--timid', action='store_true',
        help=(
            "Use a simpler but slower trace method. Try this if you get " +
            "seemingly impossible results!"
        ),
    )
    title = optparse.make_option(
        '', '--title', action='store', metavar="TITLE",
        help="A text string to use as the title on the HTML.",
    )
    version = optparse.make_option(
        '', '--version', action='store_true',
        help="Display version information and exit.",
    )


</t>
<t tx="ekr.20221020070914.110">def start(self):
    """Start measuring code coverage.

    Coverage measurement only occurs in functions called after
    :meth:`start` is invoked.  Statements in the same scope as
    :meth:`start` won't be measured.

    Once you invoke :meth:`start`, you must also call :meth:`stop`
    eventually, or your process might not shut down cleanly.

    """
    self._init()
    if not self._inited_for_start:
        self._inited_for_start = True
        self._init_for_start()
    self._post_init()

    # Issue warnings for possible problems.
    self._inorout.warn_conflicting_settings()

    # See if we think some code that would eventually be measured has
    # already been imported.
    if self._warn_preimported_source:
        self._inorout.warn_already_imported_files()

    if self._auto_load:
        self.load()

    self._collector.start()
    self._started = True
    self._instances.append(self)

</t>
<t tx="ekr.20221020070914.111">def stop(self):
    """Stop measuring code coverage."""
    if self._instances:
        if self._instances[-1] is self:
            self._instances.pop()
    if self._started:
        self._collector.stop()
    self._started = False

</t>
<t tx="ekr.20221020070914.112">def _atexit(self, event="atexit"):
    """Clean up on process shutdown."""
    if self._debug.should("process"):
        self._debug.write(f"{event}: pid: {os.getpid()}, instance: {self!r}")
    if self._started:
        self.stop()
    if self._auto_save:
        self.save()

</t>
<t tx="ekr.20221020070914.113">def _on_sigterm(self, signum_unused, frame_unused):
    """A handler for signal.SIGTERM."""
    self._atexit("sigterm")
    # Statements after here won't be seen by metacov because we just wrote
    # the data, and are about to kill the process.
    signal.signal(signal.SIGTERM, self._old_sigterm)    # pragma: not covered
    os.kill(os.getpid(), signal.SIGTERM)                # pragma: not covered

</t>
<t tx="ekr.20221020070914.114">def erase(self):
    """Erase previously collected coverage data.

    This removes the in-memory data collected in this session as well as
    discarding the data file.

    """
    self._init()
    self._post_init()
    if self._collector:
        self._collector.reset()
    self._init_data(suffix=None)
    self._data.erase(parallel=self.config.parallel)
    self._data = None
    self._inited_for_start = False

</t>
<t tx="ekr.20221020070914.115">def switch_context(self, new_context):
    """Switch to a new dynamic context.

    `new_context` is a string to use as the :ref:`dynamic context
    &lt;dynamic_contexts&gt;` label for collected data.  If a :ref:`static
    context &lt;static_contexts&gt;` is in use, the static and dynamic context
    labels will be joined together with a pipe character.

    Coverage collection must be started already.

    .. versionadded:: 5.0

    """
    if not self._started:                           # pragma: part started
        raise CoverageException("Cannot switch context, coverage is not started")

    if self._collector.should_start_context:
        self._warn("Conflicting dynamic contexts", slug="dynamic-conflict", once=True)

    self._collector.switch_context(new_context)

</t>
<t tx="ekr.20221020070914.116">def clear_exclude(self, which='exclude'):
    """Clear the exclude list."""
    self._init()
    setattr(self.config, which + "_list", [])
    self._exclude_regex_stale()

</t>
<t tx="ekr.20221020070914.117">def exclude(self, regex, which='exclude'):
    """Exclude source lines from execution consideration.

    A number of lists of regular expressions are maintained.  Each list
    selects lines that are treated differently during reporting.

    `which` determines which list is modified.  The "exclude" list selects
    lines that are not considered executable at all.  The "partial" list
    indicates lines with branches that are not taken.

    `regex` is a regular expression.  The regex is added to the specified
    list.  If any of the regexes in the list is found in a line, the line
    is marked for special treatment during reporting.

    """
    self._init()
    excl_list = getattr(self.config, which + "_list")
    excl_list.append(regex)
    self._exclude_regex_stale()

</t>
<t tx="ekr.20221020070914.118">def _exclude_regex_stale(self):
    """Drop all the compiled exclusion regexes, a list was modified."""
    self._exclude_re.clear()

</t>
<t tx="ekr.20221020070914.119">def _exclude_regex(self, which):
    """Return a compiled regex for the given exclusion list."""
    if which not in self._exclude_re:
        excl_list = getattr(self.config, which + "_list")
        self._exclude_re[which] = join_regex(excl_list)
    return self._exclude_re[which]

</t>
<t tx="ekr.20221020070914.12">class CoverageOptionParser(optparse.OptionParser):
    """Base OptionParser for coverage.py.

    Problems don't exit the program.
    Defaults are initialized for all options.

    """

    @others
</t>
<t tx="ekr.20221020070914.120">def get_exclude_list(self, which='exclude'):
    """Return a list of excluded regex patterns.

    `which` indicates which list is desired.  See :meth:`exclude` for the
    lists that are available, and their meaning.

    """
    self._init()
    return getattr(self.config, which + "_list")

</t>
<t tx="ekr.20221020070914.121">def save(self):
    """Save the collected coverage data to the data file."""
    data = self.get_data()
    data.write()

</t>
<t tx="ekr.20221020070914.122">def combine(self, data_paths=None, strict=False, keep=False):
    """Combine together a number of similarly-named coverage data files.

    All coverage data files whose name starts with `data_file` (from the
    coverage() constructor) will be read, and combined together into the
    current measurements.

    `data_paths` is a list of files or directories from which data should
    be combined. If no list is passed, then the data files from the
    directory indicated by the current data file (probably the current
    directory) will be combined.

    If `strict` is true, then it is an error to attempt to combine when
    there are no data files to combine.

    If `keep` is true, then original input data files won't be deleted.

    .. versionadded:: 4.0
        The `data_paths` parameter.

    .. versionadded:: 4.3
        The `strict` parameter.

    .. versionadded: 5.5
        The `keep` parameter.
    """
    self._init()
    self._init_data(suffix=None)
    self._post_init()
    self.get_data()

    aliases = None
    if self.config.paths:
        aliases = PathAliases(
            debugfn=(self._debug.write if self._debug.should("pathmap") else None),
            relative=self.config.relative_files,
        )
        for paths in self.config.paths.values():
            result = paths[0]
            for pattern in paths[1:]:
                aliases.add(pattern, result)

    combine_parallel_data(
        self._data,
        aliases=aliases,
        data_paths=data_paths,
        strict=strict,
        keep=keep,
        message=self._message,
    )

</t>
<t tx="ekr.20221020070914.123">def get_data(self):
    """Get the collected data.

    Also warn about various problems collecting data.

    Returns a :class:`coverage.CoverageData`, the collected coverage data.

    .. versionadded:: 4.0

    """
    self._init()
    self._init_data(suffix=None)
    self._post_init()

    for plugin in self._plugins:
        if not plugin._coverage_enabled:
            self._collector.plugin_was_disabled(plugin)

    if self._collector and self._collector.flush_data():
        self._post_save_work()

    return self._data

</t>
<t tx="ekr.20221020070914.124">def _post_save_work(self):
    """After saving data, look for warnings, post-work, etc.

    Warn about things that should have happened but didn't.
    Look for unexecuted files.

    """
    # If there are still entries in the source_pkgs_unmatched list,
    # then we never encountered those packages.
    if self._warn_unimported_source:
        self._inorout.warn_unimported_source()

    # Find out if we got any data.
    if not self._data and self._warn_no_data:
        self._warn("No data was collected.", slug="no-data-collected")

    # Touch all the files that could have executed, so that we can
    # mark completely unexecuted files as 0% covered.
    if self._data is not None:
        file_paths = collections.defaultdict(list)
        for file_path, plugin_name in self._inorout.find_possibly_unexecuted_files():
            file_path = self._file_mapper(file_path)
            file_paths[plugin_name].append(file_path)
        for plugin_name, paths in file_paths.items():
            self._data.touch_files(paths, plugin_name)

    if self.config.note:
        self._warn("The '[run] note' setting is no longer supported.")

</t>
<t tx="ekr.20221020070914.125"># Backward compatibility with version 1.
def analysis(self, morf):
    """Like `analysis2` but doesn't return excluded line numbers."""
    f, s, _, m, mf = self.analysis2(morf)
    return f, s, m, mf

</t>
<t tx="ekr.20221020070914.126">def analysis2(self, morf):
    """Analyze a module.

    `morf` is a module or a file name.  It will be analyzed to determine
    its coverage statistics.  The return value is a 5-tuple:

    * The file name for the module.
    * A list of line numbers of executable statements.
    * A list of line numbers of excluded statements.
    * A list of line numbers of statements not run (missing from
      execution).
    * A readable formatted string of the missing line numbers.

    The analysis uses the source file itself and the current measured
    coverage data.

    """
    analysis = self._analyze(morf)
    return (
        analysis.filename,
        sorted(analysis.statements),
        sorted(analysis.excluded),
        sorted(analysis.missing),
        analysis.missing_formatted(),
    )

</t>
<t tx="ekr.20221020070914.127">def _analyze(self, it):
    """Analyze a single morf or code unit.

    Returns an `Analysis` object.

    """
    # All reporting comes through here, so do reporting initialization.
    self._init()
    self._post_init()

    data = self.get_data()
    if not isinstance(it, FileReporter):
        it = self._get_file_reporter(it)

    return Analysis(data, self.config.precision, it, self._file_mapper)

</t>
<t tx="ekr.20221020070914.128">def _get_file_reporter(self, morf):
    """Get a FileReporter for a module or file name."""
    plugin = None
    file_reporter = "python"

    if isinstance(morf, str):
        mapped_morf = self._file_mapper(morf)
        plugin_name = self._data.file_tracer(mapped_morf)
        if plugin_name:
            plugin = self._plugins.get(plugin_name)

            if plugin:
                file_reporter = plugin.file_reporter(mapped_morf)
                if file_reporter is None:
                    raise PluginError(
                        "Plugin {!r} did not provide a file reporter for {!r}.".format(
                            plugin._coverage_plugin_name, morf
                        )
                    )

    if file_reporter == "python":
        file_reporter = PythonFileReporter(morf, self)

    return file_reporter

</t>
<t tx="ekr.20221020070914.129">def _get_file_reporters(self, morfs=None):
    """Get a list of FileReporters for a list of modules or file names.

    For each module or file name in `morfs`, find a FileReporter.  Return
    the list of FileReporters.

    If `morfs` is a single module or file name, this returns a list of one
    FileReporter.  If `morfs` is empty or None, then the list of all files
    measured is used to find the FileReporters.

    """
    if not morfs:
        morfs = self._data.measured_files()

    # Be sure we have a collection.
    if not isinstance(morfs, (list, tuple, set)):
        morfs = [morfs]

    file_reporters = [self._get_file_reporter(morf) for morf in morfs]
    return file_reporters

</t>
<t tx="ekr.20221020070914.13">def __init__(self, *args, **kwargs):
    super().__init__(add_help_option=False, *args, **kwargs)
    self.set_defaults(
        # Keep these arguments alphabetized by their names.
        action=None,
        append=None,
        branch=None,
        concurrency=None,
        context=None,
        contexts=None,
        data_file=None,
        debug=None,
        directory=None,
        fail_under=None,
        help=None,
        ignore_errors=None,
        include=None,
        keep=None,
        module=None,
        omit=None,
        parallel_mode=None,
        precision=None,
        pylib=None,
        quiet=None,
        rcfile=True,
        show_contexts=None,
        show_missing=None,
        skip_covered=None,
        skip_empty=None,
        sort=None,
        source=None,
        timid=None,
        title=None,
        version=None,
    )

    self.disable_interspersed_args()

</t>
<t tx="ekr.20221020070914.130">def report(
    self, morfs=None, show_missing=None, ignore_errors=None,
    file=None, omit=None, include=None, skip_covered=None,
    contexts=None, skip_empty=None, precision=None, sort=None
):
    """Write a textual summary report to `file`.

    Each module in `morfs` is listed, with counts of statements, executed
    statements, missing statements, and a list of lines missed.

    If `show_missing` is true, then details of which lines or branches are
    missing will be included in the report.  If `ignore_errors` is true,
    then a failure while reporting a single file will not stop the entire
    report.

    `file` is a file-like object, suitable for writing.

    `include` is a list of file name patterns.  Files that match will be
    included in the report. Files matching `omit` will not be included in
    the report.

    If `skip_covered` is true, don't report on files with 100% coverage.

    If `skip_empty` is true, don't report on empty files (those that have
    no statements).

    `contexts` is a list of regular expressions.  Only data from
    :ref:`dynamic contexts &lt;dynamic_contexts&gt;` that match one of those
    expressions (using :func:`re.search &lt;python:re.search&gt;`) will be
    included in the report.

    `precision` is the number of digits to display after the decimal
    point for percentages.

    All of the arguments default to the settings read from the
    :ref:`configuration file &lt;config&gt;`.

    Returns a float, the total percentage covered.

    .. versionadded:: 4.0
        The `skip_covered` parameter.

    .. versionadded:: 5.0
        The `contexts` and `skip_empty` parameters.

    .. versionadded:: 5.2
        The `precision` parameter.

    """
    with override_config(
        self,
        ignore_errors=ignore_errors, report_omit=omit, report_include=include,
        show_missing=show_missing, skip_covered=skip_covered,
        report_contexts=contexts, skip_empty=skip_empty, precision=precision,
        sort=sort
    ):
        reporter = SummaryReporter(self)
        return reporter.report(morfs, outfile=file)

</t>
<t tx="ekr.20221020070914.131">def annotate(
    self, morfs=None, directory=None, ignore_errors=None,
    omit=None, include=None, contexts=None,
):
    """Annotate a list of modules.

    .. note::

        This method has been obsoleted by more modern reporting tools,
        including the :meth:`html_report` method.  It will be removed in a
        future version.

    Each module in `morfs` is annotated.  The source is written to a new
    file, named with a ",cover" suffix, with each line prefixed with a
    marker to indicate the coverage of the line.  Covered lines have "&gt;",
    excluded lines have "-", and missing lines have "!".

    See :meth:`report` for other arguments.

    """
    print("The annotate command will be removed in a future version.")
    print("Get in touch if you still use it: ned@nedbatchelder.com")

    with override_config(self,
        ignore_errors=ignore_errors, report_omit=omit,
        report_include=include, report_contexts=contexts,
    ):
        reporter = AnnotateReporter(self)
        reporter.report(morfs, directory=directory)

</t>
<t tx="ekr.20221020070914.132">def html_report(
    self, morfs=None, directory=None, ignore_errors=None,
    omit=None, include=None, extra_css=None, title=None,
    skip_covered=None, show_contexts=None, contexts=None,
    skip_empty=None, precision=None,
):
    """Generate an HTML report.

    The HTML is written to `directory`.  The file "index.html" is the
    overview starting point, with links to more detailed pages for
    individual modules.

    `extra_css` is a path to a file of other CSS to apply on the page.
    It will be copied into the HTML directory.

    `title` is a text string (not HTML) to use as the title of the HTML
    report.

    See :meth:`report` for other arguments.

    Returns a float, the total percentage covered.

    .. note::

        The HTML report files are generated incrementally based on the
        source files and coverage results. If you modify the report files,
        the changes will not be considered.  You should be careful about
        changing the files in the report folder.

    """
    with override_config(self,
        ignore_errors=ignore_errors, report_omit=omit, report_include=include,
        html_dir=directory, extra_css=extra_css, html_title=title,
        html_skip_covered=skip_covered, show_contexts=show_contexts, report_contexts=contexts,
        html_skip_empty=skip_empty, precision=precision,
    ):
        reporter = HtmlReporter(self)
        ret = reporter.report(morfs)
        return ret

</t>
<t tx="ekr.20221020070914.133">def xml_report(
    self, morfs=None, outfile=None, ignore_errors=None,
    omit=None, include=None, contexts=None, skip_empty=None,
):
    """Generate an XML report of coverage results.

    The report is compatible with Cobertura reports.

    Each module in `morfs` is included in the report.  `outfile` is the
    path to write the file to, "-" will write to stdout.

    See :meth:`report` for other arguments.

    Returns a float, the total percentage covered.

    """
    with override_config(self,
        ignore_errors=ignore_errors, report_omit=omit, report_include=include,
        xml_output=outfile, report_contexts=contexts, skip_empty=skip_empty,
    ):
        return render_report(self.config.xml_output, XmlReporter(self), morfs, self._message)

</t>
<t tx="ekr.20221020070914.134">def json_report(
    self, morfs=None, outfile=None, ignore_errors=None,
    omit=None, include=None, contexts=None, pretty_print=None,
    show_contexts=None
):
    """Generate a JSON report of coverage results.

    Each module in `morfs` is included in the report.  `outfile` is the
    path to write the file to, "-" will write to stdout.

    See :meth:`report` for other arguments.

    Returns a float, the total percentage covered.

    .. versionadded:: 5.0

    """
    with override_config(self,
        ignore_errors=ignore_errors, report_omit=omit, report_include=include,
        json_output=outfile, report_contexts=contexts, json_pretty_print=pretty_print,
        json_show_contexts=show_contexts
    ):
        return render_report(self.config.json_output, JsonReporter(self), morfs, self._message)

</t>
<t tx="ekr.20221020070914.135">def lcov_report(
    self, morfs=None, outfile=None, ignore_errors=None,
    omit=None, include=None, contexts=None,
):
    """Generate an LCOV report of coverage results.

    Each module in 'morfs' is included in the report. 'outfile' is the
    path to write the file to, "-" will write to stdout.

    See :meth 'report' for other arguments.

    .. versionadded:: 6.3
    """
    with override_config(self,
        ignore_errors=ignore_errors, report_omit=omit, report_include=include,
        lcov_output=outfile,  report_contexts=contexts,
    ):
        return render_report(self.config.lcov_output, LcovReporter(self), morfs, self._message)

</t>
<t tx="ekr.20221020070914.136">def sys_info(self):
    """Return a list of (key, value) pairs showing internal information."""

    import coverage as covmod

    self._init()
    self._post_init()

    def plugin_info(plugins):
        """Make an entry for the sys_info from a list of plug-ins."""
        entries = []
        for plugin in plugins:
            entry = plugin._coverage_plugin_name
            if not plugin._coverage_enabled:
                entry += " (disabled)"
            entries.append(entry)
        return entries

    info = [
        ('coverage_version', covmod.__version__),
        ('coverage_module', covmod.__file__),
        ('tracer', self._collector.tracer_name() if self._collector else "-none-"),
        ('CTracer', 'available' if CTracer else "unavailable"),
        ('plugins.file_tracers', plugin_info(self._plugins.file_tracers)),
        ('plugins.configurers', plugin_info(self._plugins.configurers)),
        ('plugins.context_switchers', plugin_info(self._plugins.context_switchers)),
        ('configs_attempted', self.config.attempted_config_files),
        ('configs_read', self.config.config_files_read),
        ('config_file', self.config.config_file),
        ('config_contents',
            repr(self.config._config_contents)
            if self.config._config_contents
            else '-none-'
        ),
        ('data_file', self._data.data_filename() if self._data is not None else "-none-"),
        ('python', sys.version.replace('\n', '')),
        ('platform', platform.platform()),
        ('implementation', platform.python_implementation()),
        ('executable', sys.executable),
        ('def_encoding', sys.getdefaultencoding()),
        ('fs_encoding', sys.getfilesystemencoding()),
        ('pid', os.getpid()),
        ('cwd', os.getcwd()),
        ('path', sys.path),
        ('environment', human_sorted(
            f"{k} = {v}"
            for k, v in os.environ.items()
            if (
                any(slug in k for slug in ("COV", "PY")) or
                (k in ("HOME", "TEMP", "TMP"))
            )
        )),
        ('command_line', " ".join(getattr(sys, 'argv', ['-none-']))),
    ]

    if self._inorout:
        info.extend(self._inorout.sys_info())

    info.extend(CoverageData.sys_info())

    return info


</t>
<t tx="ekr.20221020070914.137"># Mega debugging...
# $set_env.py: COVERAGE_DEBUG_CALLS - Lots and lots of output about calls to Coverage.
if int(os.environ.get("COVERAGE_DEBUG_CALLS", 0)):              # pragma: debugging
    from coverage.debug import decorate_methods, show_calls

    Coverage = decorate_methods(show_calls(show_args=True), butnot=['get_data'])(Coverage)


</t>
<t tx="ekr.20221020070914.138">def process_startup():
    """Call this at Python start-up to perhaps measure coverage.

    If the environment variable COVERAGE_PROCESS_START is defined, coverage
    measurement is started.  The value of the variable is the config file
    to use.

    There are two ways to configure your Python installation to invoke this
    function when Python starts:

    #. Create or append to sitecustomize.py to add these lines::

        import coverage
        coverage.process_startup()

    #. Create a .pth file in your Python installation containing::

        import coverage; coverage.process_startup()

    Returns the :class:`Coverage` instance that was started, or None if it was
    not started by this call.

    """
    cps = os.environ.get("COVERAGE_PROCESS_START")
    if not cps:
        # No request for coverage, nothing to do.
        return None

    # This function can be called more than once in a process. This happens
    # because some virtualenv configurations make the same directory visible
    # twice in sys.path.  This means that the .pth file will be found twice,
    # and executed twice, executing this function twice.  We set a global
    # flag (an attribute on this function) to indicate that coverage.py has
    # already been started, so we can avoid doing it twice.
    #
    # https://github.com/nedbat/coveragepy/issues/340 has more details.

    if hasattr(process_startup, "coverage"):
        # We've annotated this function before, so we must have already
        # started coverage.py in this process.  Nothing to do.
        return None

    cov = Coverage(config_file=cps)
    process_startup.coverage = cov
    cov._warn_no_data = False
    cov._warn_unimported_source = False
    cov._warn_preimported_source = False
    cov._auto_save = True
    cov.start()

    return cov


</t>
<t tx="ekr.20221020070914.139">def _prevent_sub_process_measurement():
    """Stop any subprocess auto-measurement from writing data."""
    auto_created_coverage = getattr(process_startup, "coverage", None)
    if auto_created_coverage is not None:
        auto_created_coverage._auto_save = False
</t>
<t tx="ekr.20221020070914.14">class OptionParserError(Exception):
    """Used to stop the optparse error handler ending the process."""
    pass

</t>
<t tx="ekr.20221020070914.140">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Coverage data for coverage.py.

This file had the 4.x JSON data support, which is now gone.  This file still
has storage-agnostic helpers, and is kept to avoid changing too many imports.
CoverageData is now defined in sqldata.py, and imported here to keep the
imports working.

"""

import glob
import os.path

from coverage.exceptions import CoverageException, NoDataError
from coverage.misc import file_be_gone, human_sorted, plural
from coverage.sqldata import CoverageData


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.141">def line_counts(data, fullpath=False):
    """Return a dict summarizing the line coverage data.

    Keys are based on the file names, and values are the number of executed
    lines.  If `fullpath` is true, then the keys are the full pathnames of
    the files, otherwise they are the basenames of the files.

    Returns a dict mapping file names to counts of lines.

    """
    summ = {}
    if fullpath:
        # pylint: disable=unnecessary-lambda-assignment
        filename_fn = lambda f: f
    else:
        filename_fn = os.path.basename
    for filename in data.measured_files():
        summ[filename_fn(filename)] = len(data.lines(filename))
    return summ


</t>
<t tx="ekr.20221020070914.142">def add_data_to_hash(data, filename, hasher):
    """Contribute `filename`'s data to the `hasher`.

    `hasher` is a `coverage.misc.Hasher` instance to be updated with
    the file's data.  It should only get the results data, not the run
    data.

    """
    if data.has_arcs():
        hasher.update(sorted(data.arcs(filename) or []))
    else:
        hasher.update(sorted(data.lines(filename) or []))
    hasher.update(data.file_tracer(filename))


</t>
<t tx="ekr.20221020070914.143">def combinable_files(data_file, data_paths=None):
    """Make a list of data files to be combined.

    `data_file` is a path to a data file.  `data_paths` is a list of files or
    directories of files.

    Returns a list of absolute file paths.
    """
    data_dir, local = os.path.split(os.path.abspath(data_file))

    data_paths = data_paths or [data_dir]
    files_to_combine = []
    for p in data_paths:
        if os.path.isfile(p):
            files_to_combine.append(os.path.abspath(p))
        elif os.path.isdir(p):
            pattern = glob.escape(os.path.join(os.path.abspath(p), local)) +".*"
            files_to_combine.extend(glob.glob(pattern))
        else:
            raise NoDataError(f"Couldn't combine from non-existent path '{p}'")
    return files_to_combine


</t>
<t tx="ekr.20221020070914.144">def combine_parallel_data(
    data, aliases=None, data_paths=None, strict=False, keep=False, message=None,
):
    """Combine a number of data files together.

    `data` is a CoverageData.

    Treat `data.filename` as a file prefix, and combine the data from all
    of the data files starting with that prefix plus a dot.

    If `aliases` is provided, it's a `PathAliases` object that is used to
    re-map paths to match the local machine's.

    If `data_paths` is provided, it is a list of directories or files to
    combine.  Directories are searched for files that start with
    `data.filename` plus dot as a prefix, and those files are combined.

    If `data_paths` is not provided, then the directory portion of
    `data.filename` is used as the directory to search for data files.

    Unless `keep` is True every data file found and combined is then deleted from disk. If a file
    cannot be read, a warning will be issued, and the file will not be
    deleted.

    If `strict` is true, and no files are found to combine, an error is
    raised.

    """
    files_to_combine = combinable_files(data.base_filename(), data_paths)

    if strict and not files_to_combine:
        raise NoDataError("No data to combine")

    files_combined = 0
    for f in files_to_combine:
        if f == data.data_filename():
            # Sometimes we are combining into a file which is one of the
            # parallel files.  Skip that file.
            if data._debug.should('dataio'):
                data._debug.write(f"Skipping combining ourself: {f!r}")
            continue
        if data._debug.should('dataio'):
            data._debug.write(f"Combining data file {f!r}")
        try:
            new_data = CoverageData(f, debug=data._debug)
            new_data.read()
        except CoverageException as exc:
            if data._warn:
                # The CoverageException has the file name in it, so just
                # use the message as the warning.
                data._warn(str(exc))
        else:
            data.update(new_data, aliases=aliases)
            files_combined += 1
            if message:
                try:
                    file_name = os.path.relpath(f)
                except ValueError:
                    # ValueError can be raised under Windows when os.getcwd() returns a
                    # folder from a different drive than the drive of f, in which case
                    # we print the original value of f instead of its relative path
                    file_name = f
                message(f"Combined data file {file_name}")
            if not keep:
                if data._debug.should('dataio'):
                    data._debug.write(f"Deleting combined data file {f!r}")
                file_be_gone(f)

    if strict and not files_combined:
        raise NoDataError("No usable data files")


</t>
<t tx="ekr.20221020070914.145">def debug_data_file(filename):
    """Implementation of 'coverage debug data'."""
    data = CoverageData(filename)
    filename = data.data_filename()
    print(f"path: {filename}")
    if not os.path.exists(filename):
        print("No data collected: file doesn't exist")
        return
    data.read()
    print(f"has_arcs: {data.has_arcs()!r}")
    summary = line_counts(data, fullpath=True)
    filenames = human_sorted(summary.keys())
    nfiles = len(filenames)
    print(f"{nfiles} file{plural(nfiles)}:")
    for f in filenames:
        line = f"{f}: {summary[f]} line{plural(summary[f])}"
        plugin = data.file_tracer(f)
        if plugin:
            line += f" [{plugin}]"
        print(line)
</t>
<t tx="ekr.20221020070914.146">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Control of and utilities for debugging."""

import contextlib
import functools
import inspect
import io
import itertools
import os
import pprint
import reprlib
import sys
import types
import _thread

from coverage.misc import isolate_module

os = isolate_module(os)


# When debugging, it can be helpful to force some options, especially when
# debugging the configuration mechanisms you usually use to control debugging!
# This is a list of forced debugging options.
FORCED_DEBUG = []
FORCED_DEBUG_FILE = None


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.147">class DebugControl:
    """Control and output for debugging."""

    show_repr_attr = False      # For SimpleReprMixin

    @others
</t>
<t tx="ekr.20221020070914.148">def __init__(self, options, output):
    """Configure the options and output file for debugging."""
    self.options = list(options) + FORCED_DEBUG
    self.suppress_callers = False

    filters = []
    if self.should('pid'):
        filters.append(add_pid_and_tid)
    self.output = DebugOutputFile.get_one(
        output,
        show_process=self.should('process'),
        filters=filters,
    )
    self.raw_output = self.output.outfile

</t>
<t tx="ekr.20221020070914.149">def __repr__(self):
    return f"&lt;DebugControl options={self.options!r} raw_output={self.raw_output!r}&gt;"

</t>
<t tx="ekr.20221020070914.15">def parse_args_ok(self, args=None, options=None):
    """Call optparse.parse_args, but return a triple:

    (ok, options, args)

    """
    try:
        options, args = super().parse_args(args, options)
    except self.OptionParserError:
        return False, None, None
    return True, options, args

</t>
<t tx="ekr.20221020070914.150">def should(self, option):
    """Decide whether to output debug information in category `option`."""
    if option == "callers" and self.suppress_callers:
        return False
    return (option in self.options)

</t>
<t tx="ekr.20221020070914.151">@contextlib.contextmanager
def without_callers(self):
    """A context manager to prevent call stacks from being logged."""
    old = self.suppress_callers
    self.suppress_callers = True
    try:
        yield
    finally:
        self.suppress_callers = old

</t>
<t tx="ekr.20221020070914.152">def write(self, msg):
    """Write a line of debug output.

    `msg` is the line to write. A newline will be appended.

    """
    self.output.write(msg+"\n")
    if self.should('self'):
        caller_self = inspect.stack()[1][0].f_locals.get('self')
        if caller_self is not None:
            self.output.write(f"self: {caller_self!r}\n")
    if self.should('callers'):
        dump_stack_frames(out=self.output, skip=1)
    self.output.flush()


</t>
<t tx="ekr.20221020070914.153">class DebugControlString(DebugControl):
    """A `DebugControl` that writes to a StringIO, for testing."""
    @others
</t>
<t tx="ekr.20221020070914.154">def __init__(self, options):
    super().__init__(options, io.StringIO())

</t>
<t tx="ekr.20221020070914.155">def get_output(self):
    """Get the output text from the `DebugControl`."""
    return self.raw_output.getvalue()


</t>
<t tx="ekr.20221020070914.156">class NoDebugging:
    """A replacement for DebugControl that will never try to do anything."""
    def should(self, option):               # pylint: disable=unused-argument
        """Should we write debug messages?  Never."""
        return False


</t>
<t tx="ekr.20221020070914.157">def info_header(label):
    """Make a nice header string."""
    return "--{:-&lt;60s}".format(" "+label+" ")


</t>
<t tx="ekr.20221020070914.158">def info_formatter(info):
    """Produce a sequence of formatted lines from info.

    `info` is a sequence of pairs (label, data).  The produced lines are
    nicely formatted, ready to print.

    """
    info = list(info)
    if not info:
        return
    label_len = 30
    assert all(len(l) &lt; label_len for l, _ in info)
    for label, data in info:
        if data == []:
            data = "-none-"
        if isinstance(data, tuple) and len(repr(tuple(data))) &lt; 30:
            # Convert to tuple to scrub namedtuples.
            yield "%*s: %r" % (label_len, label, tuple(data))
        elif isinstance(data, (list, set, tuple)):
            prefix = "%*s:" % (label_len, label)
            for e in data:
                yield "%*s %s" % (label_len+1, prefix, e)
                prefix = ""
        else:
            yield "%*s: %s" % (label_len, label, data)


</t>
<t tx="ekr.20221020070914.159">def write_formatted_info(write, header, info):
    """Write a sequence of (label,data) pairs nicely.

    `write` is a function write(str) that accepts each line of output.
    `header` is a string to start the section.  `info` is a sequence of
    (label, data) pairs, where label is a str, and data can be a single
    value, or a list/set/tuple.

    """
    write(info_header(header))
    for line in info_formatter(info):
        write(f" {line}")


</t>
<t tx="ekr.20221020070914.16">def error(self, msg):
    """Override optparse.error so sys.exit doesn't get called."""
    show_help(msg)
    raise self.OptionParserError


</t>
<t tx="ekr.20221020070914.160">def short_stack(limit=None, skip=0):
    """Return a string summarizing the call stack.

    The string is multi-line, with one line per stack frame. Each line shows
    the function name, the file name, and the line number:

        ...
        start_import_stop : /Users/ned/coverage/trunk/tests/coveragetest.py @95
        import_local_file : /Users/ned/coverage/trunk/tests/coveragetest.py @81
        import_local_file : /Users/ned/coverage/trunk/coverage/backward.py @159
        ...

    `limit` is the number of frames to include, defaulting to all of them.

    `skip` is the number of frames to skip, so that debugging functions can
    call this and not be included in the result.

    """
    stack = inspect.stack()[limit:skip:-1]
    return "\n".join("%30s : %s:%d" % (t[3], t[1], t[2]) for t in stack)


</t>
<t tx="ekr.20221020070914.161">def dump_stack_frames(limit=None, out=None, skip=0):
    """Print a summary of the stack to stdout, or someplace else."""
    out = out or sys.stdout
    out.write(short_stack(limit=limit, skip=skip+1))
    out.write("\n")


</t>
<t tx="ekr.20221020070914.162">def clipped_repr(text, numchars=50):
    """`repr(text)`, but limited to `numchars`."""
    r = reprlib.Repr()
    r.maxstring = numchars
    return r.repr(text)


</t>
<t tx="ekr.20221020070914.163">def short_id(id64):
    """Given a 64-bit id, make a shorter 16-bit one."""
    id16 = 0
    for offset in range(0, 64, 16):
        id16 ^= id64 &gt;&gt; offset
    return id16 &amp; 0xFFFF


</t>
<t tx="ekr.20221020070914.164">def add_pid_and_tid(text):
    """A filter to add pid and tid to debug messages."""
    # Thread ids are useful, but too long. Make a shorter one.
    tid = f"{short_id(_thread.get_ident()):04x}"
    text = f"{os.getpid():5d}.{tid}: {text}"
    return text


</t>
<t tx="ekr.20221020070914.165">class SimpleReprMixin:
    """A mixin implementing a simple __repr__."""
    simple_repr_ignore = ['simple_repr_ignore', '$coverage.object_id']

    @others
</t>
<t tx="ekr.20221020070914.166">def __repr__(self):
    show_attrs = (
        (k, v) for k, v in self.__dict__.items()
        if getattr(v, "show_repr_attr", True)
        and not callable(v)
        and k not in self.simple_repr_ignore
    )
    return "&lt;{klass} @0x{id:x} {attrs}&gt;".format(
        klass=self.__class__.__name__,
        id=id(self),
        attrs=" ".join(f"{k}={v!r}" for k, v in show_attrs),
    )


</t>
<t tx="ekr.20221020070914.167">def simplify(v):                                            # pragma: debugging
    """Turn things which are nearly dict/list/etc into dict/list/etc."""
    if isinstance(v, dict):
        return {k:simplify(vv) for k, vv in v.items()}
    elif isinstance(v, (list, tuple)):
        return type(v)(simplify(vv) for vv in v)
    elif hasattr(v, "__dict__"):
        return simplify({'.'+k: v for k, v in v.__dict__.items()})
    else:
        return v


</t>
<t tx="ekr.20221020070914.168">def pp(v):                                                  # pragma: debugging
    """Debug helper to pretty-print data, including SimpleNamespace objects."""
    # Might not be needed in 3.9+
    pprint.pprint(simplify(v))


</t>
<t tx="ekr.20221020070914.169">def filter_text(text, filters):
    """Run `text` through a series of filters.

    `filters` is a list of functions. Each takes a string and returns a
    string.  Each is run in turn.

    Returns: the final string that results after all of the filters have
    run.

    """
    clean_text = text.rstrip()
    ending = text[len(clean_text):]
    text = clean_text
    for fn in filters:
        lines = []
        for line in text.splitlines():
            lines.extend(fn(line).splitlines())
        text = "\n".join(lines)
    return text + ending


</t>
<t tx="ekr.20221020070914.17">class GlobalOptionParser(CoverageOptionParser):
    """Command-line parser for coverage.py global option arguments."""

    @others
</t>
<t tx="ekr.20221020070914.170">class CwdTracker:                                   # pragma: debugging
    """A class to add cwd info to debug messages."""
    @others
</t>
<t tx="ekr.20221020070914.171">def __init__(self):
    self.cwd = None

</t>
<t tx="ekr.20221020070914.172">def filter(self, text):
    """Add a cwd message for each new cwd."""
    cwd = os.getcwd()
    if cwd != self.cwd:
        text = f"cwd is now {cwd!r}\n" + text
        self.cwd = cwd
    return text


</t>
<t tx="ekr.20221020070914.173">class DebugOutputFile:                              # pragma: debugging
    """A file-like object that includes pid and cwd information."""
    @others
</t>
<t tx="ekr.20221020070914.174">def __init__(self, outfile, show_process, filters):
    self.outfile = outfile
    self.show_process = show_process
    self.filters = list(filters)

    if self.show_process:
        self.filters.insert(0, CwdTracker().filter)
        self.write(f"New process: executable: {sys.executable!r}\n")
        self.write("New process: cmd: {!r}\n".format(getattr(sys, 'argv', None)))
        if hasattr(os, 'getppid'):
            self.write(f"New process: pid: {os.getpid()!r}, parent pid: {os.getppid()!r}\n")

</t>
<t tx="ekr.20221020070914.175">SYS_MOD_NAME = '$coverage.debug.DebugOutputFile.the_one'
SINGLETON_ATTR = 'the_one_and_is_interim'

</t>
<t tx="ekr.20221020070914.176">@classmethod
def get_one(cls, fileobj=None, show_process=True, filters=(), interim=False):
    """Get a DebugOutputFile.

    If `fileobj` is provided, then a new DebugOutputFile is made with it.

    If `fileobj` isn't provided, then a file is chosen
    (COVERAGE_DEBUG_FILE, or stderr), and a process-wide singleton
    DebugOutputFile is made.

    `show_process` controls whether the debug file adds process-level
    information, and filters is a list of other message filters to apply.

    `filters` are the text filters to apply to the stream to annotate with
    pids, etc.

    If `interim` is true, then a future `get_one` can replace this one.

    """
    if fileobj is not None:
        # Make DebugOutputFile around the fileobj passed.
        return cls(fileobj, show_process, filters)

    # Because of the way igor.py deletes and re-imports modules,
    # this class can be defined more than once. But we really want
    # a process-wide singleton. So stash it in sys.modules instead of
    # on a class attribute. Yes, this is aggressively gross.
    singleton_module = sys.modules.get(cls.SYS_MOD_NAME)
    the_one, is_interim = getattr(singleton_module, cls.SINGLETON_ATTR, (None, True))
    if the_one is None or is_interim:
        if fileobj is None:
            debug_file_name = os.environ.get("COVERAGE_DEBUG_FILE", FORCED_DEBUG_FILE)
            if debug_file_name in ("stdout", "stderr"):
                fileobj = getattr(sys, debug_file_name)
            elif debug_file_name:
                fileobj = open(debug_file_name, "a")
            else:
                fileobj = sys.stderr
        the_one = cls(fileobj, show_process, filters)
        singleton_module = types.ModuleType(cls.SYS_MOD_NAME)
        setattr(singleton_module, cls.SINGLETON_ATTR, (the_one, interim))
        sys.modules[cls.SYS_MOD_NAME] = singleton_module
    return the_one

</t>
<t tx="ekr.20221020070914.177">def write(self, text):
    """Just like file.write, but filter through all our filters."""
    self.outfile.write(filter_text(text, self.filters))
    self.outfile.flush()

</t>
<t tx="ekr.20221020070914.178">def flush(self):
    """Flush our file."""
    self.outfile.flush()


</t>
<t tx="ekr.20221020070914.179">def log(msg, stack=False):                                  # pragma: debugging
    """Write a log message as forcefully as possible."""
    out = DebugOutputFile.get_one(interim=True)
    out.write(msg+"\n")
    if stack:
        dump_stack_frames(out=out, skip=1)


</t>
<t tx="ekr.20221020070914.18">def __init__(self):
    super().__init__()

    self.add_options([
        Opts.help,
        Opts.version,
    ])


</t>
<t tx="ekr.20221020070914.180">def decorate_methods(decorator, butnot=(), private=False):  # pragma: debugging
    """A class decorator to apply a decorator to methods."""
    @others
    return _decorator


</t>
<t tx="ekr.20221020070914.181">def _decorator(cls):
    for name, meth in inspect.getmembers(cls, inspect.isroutine):
        if name not in cls.__dict__:
            continue
        if name != "__init__":
            if not private and name.startswith("_"):
                continue
        if name in butnot:
            continue
        setattr(cls, name, decorator(meth))
    return cls
</t>
<t tx="ekr.20221020070914.182">def break_in_pudb(func):                                    # pragma: debugging
    """A function decorator to stop in the debugger for each call."""
    @others
    return _wrapper


</t>
<t tx="ekr.20221020070914.183">@functools.wraps(func)
def _wrapper(*args, **kwargs):
    import pudb
    sys.stdout = sys.__stdout__
    pudb.set_trace()
    return func(*args, **kwargs)
</t>
<t tx="ekr.20221020070914.184">OBJ_IDS = itertools.count()
CALLS = itertools.count()
OBJ_ID_ATTR = "$coverage.object_id"

</t>
<t tx="ekr.20221020070914.185">def show_calls(show_args=True, show_stack=False, show_return=False):    # pragma: debugging
    """A method decorator to debug-log each call to the function."""
    @others
    return _decorator


</t>
<t tx="ekr.20221020070914.186">def _decorator(func):
    @functools.wraps(func)
    def _wrapper(self, *args, **kwargs):
        oid = getattr(self, OBJ_ID_ATTR, None)
        if oid is None:
            oid = f"{os.getpid():08d} {next(OBJ_IDS):04d}"
            setattr(self, OBJ_ID_ATTR, oid)
        extra = ""
        if show_args:
            eargs = ", ".join(map(repr, args))
            ekwargs = ", ".join("{}={!r}".format(*item) for item in kwargs.items())
            extra += "("
            extra += eargs
            if eargs and ekwargs:
                extra += ", "
            extra += ekwargs
            extra += ")"
        if show_stack:
            extra += " @ "
            extra += "; ".join(_clean_stack_line(l) for l in short_stack().splitlines())
        callid = next(CALLS)
        msg = f"{oid} {callid:04d} {func.__name__}{extra}\n"
        DebugOutputFile.get_one(interim=True).write(msg)
        ret = func(self, *args, **kwargs)
        if show_return:
            msg = f"{oid} {callid:04d} {func.__name__} return {ret!r}\n"
            DebugOutputFile.get_one(interim=True).write(msg)
        return ret
    return _wrapper
</t>
<t tx="ekr.20221020070914.187">def _clean_stack_line(s):                                   # pragma: debugging
    """Simplify some paths in a stack trace, for compactness."""
    s = s.strip()
    s = s.replace(os.path.dirname(__file__) + '/', '')
    s = s.replace(os.path.dirname(os.__file__) + '/', '')
    s = s.replace(sys.prefix + '/', '')
    return s
</t>
<t tx="ekr.20221020070914.188">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Simple value objects for tracking what to do with files."""


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.189">class FileDisposition:
    """A simple value type for recording what to do with a file."""

    def __repr__(self):
        return f"&lt;FileDisposition {self.canonical_filename!r}: trace={self.trace}&gt;"


</t>
<t tx="ekr.20221020070914.19">class CmdOptionParser(CoverageOptionParser):
    """Parse one of the new-style commands for coverage.py."""

    @others
</t>
<t tx="ekr.20221020070914.190"># FileDisposition "methods": FileDisposition is a pure value object, so it can
# be implemented in either C or Python.  Acting on them is done with these
# functions.

</t>
<t tx="ekr.20221020070914.191">def disposition_init(cls, original_filename):
    """Construct and initialize a new FileDisposition object."""
    disp = cls()
    disp.original_filename = original_filename
    disp.canonical_filename = original_filename
    disp.source_filename = None
    disp.trace = False
    disp.reason = ""
    disp.file_tracer = None
    disp.has_dynamic_filename = False
    return disp


</t>
<t tx="ekr.20221020070914.192">def disposition_debug_msg(disp):
    """Make a nice debug message of what the FileDisposition is doing."""
    if disp.trace:
        msg = f"Tracing {disp.original_filename!r}"
        if disp.original_filename != disp.source_filename:
            msg += f" as {disp.source_filename!r}"
        if disp.file_tracer:
            msg += f": will be traced by {disp.file_tracer!r}"
    else:
        msg = f"Not tracing {disp.original_filename!r}: {disp.reason}"
    return msg
</t>
<t tx="ekr.20221020070914.193">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Determine facts about the environment."""

import os
import platform
import sys

# Operating systems.
WINDOWS = sys.platform == "win32"
LINUX = sys.platform.startswith("linux")
OSX = sys.platform == "darwin"

# Python implementations.
CPYTHON = (platform.python_implementation() == "CPython")
PYPY = (platform.python_implementation() == "PyPy")
JYTHON = (platform.python_implementation() == "Jython")
IRONPYTHON = (platform.python_implementation() == "IronPython")

# Python versions. We amend version_info with one more value, a zero if an
# official version, or 1 if built from source beyond an official version.
PYVERSION = sys.version_info + (int(platform.python_version()[-1] == "+"),)

if PYPY:
    PYPYVERSION = sys.pypy_version_info

@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.194"># Python behavior.
class PYBEHAVIOR:
    """Flags indicating this Python's behavior."""

    # Does Python conform to PEP626, Precise line numbers for debugging and other tools.
    # https://www.python.org/dev/peps/pep-0626
    pep626 = CPYTHON and (PYVERSION &gt; (3, 10, 0, 'alpha', 4))

    # Is "if __debug__" optimized away?
    if PYPY:
        optimize_if_debug = True
    else:
        optimize_if_debug = not pep626

    # Is "if not __debug__" optimized away? The exact details have changed
    # across versions.
    if pep626:
        optimize_if_not_debug = 1
    elif PYPY:
        if PYVERSION &gt;= (3, 9):
            optimize_if_not_debug = 2
        elif PYVERSION[:2] == (3, 8):
            optimize_if_not_debug = 3
        else:
            optimize_if_not_debug = 1
    else:
        if PYVERSION &gt;= (3, 8, 0, 'beta', 1):
            optimize_if_not_debug = 2
        else:
            optimize_if_not_debug = 1

    # Can co_lnotab have negative deltas?
    negative_lnotab = not (PYPY and PYPYVERSION &lt; (7, 2))

    # 3.7 changed how functions with only docstrings are numbered.
    docstring_only_function = (not PYPY) and ((3, 7, 0, 'beta', 5) &lt;= PYVERSION &lt;= (3, 10))

    # When a break/continue/return statement in a try block jumps to a finally
    # block, does the finally block do the break/continue/return (pre-3.8), or
    # does the finally jump back to the break/continue/return (3.8) to do the
    # work?
    finally_jumps_back = ((3, 8) &lt;= PYVERSION &lt; (3, 10))

    # When a function is decorated, does the trace function get called for the
    # @-line and also the def-line (new behavior in 3.8)? Or just the @-line
    # (old behavior)?
    trace_decorated_def = (CPYTHON and PYVERSION &gt;= (3, 8)) or (PYPY and PYVERSION &gt;= (3, 9))

    # Functions are no longer claimed to start at their earliest decorator even though
    # the decorators are traced?
    def_ast_no_decorator = (PYPY and PYVERSION &gt;= (3, 9))

    # CPython 3.11 now jumps to the decorator line again while executing
    # the decorator.
    trace_decorator_line_again = (CPYTHON and PYVERSION &gt; (3, 11, 0, 'alpha', 3, 0))

    # Are while-true loops optimized into absolute jumps with no loop setup?
    nix_while_true = (PYVERSION &gt;= (3, 8))

    # CPython 3.9a1 made sys.argv[0] and other reported files absolute paths.
    report_absolute_files = ((CPYTHON or (PYPYVERSION &gt;= (7, 3, 10))) and PYVERSION &gt;= (3, 9))

    # Lines after break/continue/return/raise are no longer compiled into the
    # bytecode.  They used to be marked as missing, now they aren't executable.
    omit_after_jump = pep626

    # PyPy has always omitted statements after return.
    omit_after_return = omit_after_jump or PYPY

    # Modules used to have firstlineno equal to the line number of the first
    # real line of code.  Now they always start at 1.
    module_firstline_1 = pep626

    # Are "if 0:" lines (and similar) kept in the compiled code?
    keep_constant_test = pep626

    # When leaving a with-block, do we visit the with-line again for the exit?
    exit_through_with = (PYVERSION &gt;= (3, 10, 0, 'beta'))

    # Match-case construct.
    match_case = (PYVERSION &gt;= (3, 10))

    # Some words are keywords in some places, identifiers in other places.
    soft_keywords = (PYVERSION &gt;= (3, 10))

    # Modules start with a line numbered zero. This means empty modules have
    # only a 0-number line, which is ignored, giving a truly empty module.
    empty_is_empty = (PYVERSION &gt;= (3, 11, 0, 'beta', 4))

</t>
<t tx="ekr.20221020070914.195"># Coverage.py specifics.

# Are we using the C-implemented trace function?
C_TRACER = os.getenv('COVERAGE_TEST_TRACER', 'c') == 'c'

# Are we coverage-measuring ourselves?
METACOV = os.getenv('COVERAGE_COVERAGE', '') != ''

# Are we running our test suite?
# Even when running tests, you can use COVERAGE_TESTING=0 to disable the
# test-specific behavior like contracts.
TESTING = os.getenv('COVERAGE_TESTING', '') == 'True'

# Environment COVERAGE_NO_CONTRACTS=1 can turn off contracts while debugging
# tests to remove noise from stack traces.
# $set_env.py: COVERAGE_NO_CONTRACTS - Disable PyContracts to simplify stack traces.
USE_CONTRACTS = (
    TESTING
    and not bool(int(os.environ.get("COVERAGE_NO_CONTRACTS", 0)))
    and (PYVERSION &lt; (3, 11))
)

</t>
<t tx="ekr.20221020070914.196">def debug_info():
    """Return a list of (name, value) pairs for printing debug information."""
    info = [
        (name, value) for name, value in globals().items()
        if not name.startswith("_") and
            name not in {"PYBEHAVIOR", "debug_info"} and
            not isinstance(value, type(os))
    ]
    info += [
        (name, value) for name, value in PYBEHAVIOR.__dict__.items()
        if not name.startswith("_")
    ]
    return sorted(info)
</t>
<t tx="ekr.20221020070914.197">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Exceptions coverage.py can raise."""


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.198">class _BaseCoverageException(Exception):
    """The base-base of all Coverage exceptions."""
    pass


</t>
<t tx="ekr.20221020070914.199">class CoverageException(_BaseCoverageException):
    """The base class of all exceptions raised by Coverage.py."""
    pass


</t>
<t tx="ekr.20221020070914.2">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Source file annotation for coverage.py."""

import os
import re

from coverage.files import flat_rootname
from coverage.misc import ensure_dir, isolate_module
from coverage.report import get_analysis_to_report

os = isolate_module(os)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.20">def __init__(self, action, options, defaults=None, usage=None, description=None):
    """Create an OptionParser for a coverage.py command.

    `action` is the slug to put into `options.action`.
    `options` is a list of Option's for the command.
    `defaults` is a dict of default value for options.
    `usage` is the usage string to display in help.
    `description` is the description of the command, for the help text.

    """
    if usage:
        usage = "%prog " + usage
    super().__init__(
        usage=usage,
        description=description,
    )
    self.set_defaults(action=action, **(defaults or {}))
    self.add_options(options)
    self.cmd = action

</t>
<t tx="ekr.20221020070914.200">class ConfigError(_BaseCoverageException):
    """A problem with a config file, or a value in one."""
    pass


</t>
<t tx="ekr.20221020070914.201">class DataError(CoverageException):
    """An error in using a data file."""
    pass

</t>
<t tx="ekr.20221020070914.202">class NoDataError(CoverageException):
    """We didn't have data to work with."""
    pass


</t>
<t tx="ekr.20221020070914.203">class NoSource(CoverageException):
    """We couldn't find the source for a module."""
    pass


</t>
<t tx="ekr.20221020070914.204">class NoCode(NoSource):
    """We couldn't find any code at all."""
    pass


</t>
<t tx="ekr.20221020070914.205">class NotPython(CoverageException):
    """A source file turned out not to be parsable Python."""
    pass


</t>
<t tx="ekr.20221020070914.206">class PluginError(CoverageException):
    """A plugin misbehaved."""
    pass


</t>
<t tx="ekr.20221020070914.207">class _ExceptionDuringRun(CoverageException):
    """An exception happened while running customer code.

    Construct it with three arguments, the values from `sys.exc_info`.

    """
    pass


</t>
<t tx="ekr.20221020070914.208">class _StopEverything(_BaseCoverageException):
    """An exception that means everything should stop.

    The CoverageTest class converts these to SkipTest, so that when running
    tests, raising this exception will automatically skip the test.

    """
    pass


</t>
<t tx="ekr.20221020070914.209">class CoverageWarning(Warning):
    """A warning from Coverage.py."""
    pass
</t>
<t tx="ekr.20221020070914.21">def __eq__(self, other):
    # A convenience equality, so that I can put strings in unit test
    # results, and they will compare equal to objects.
    return (other == f"&lt;CmdOptionParser:{self.cmd}&gt;")

</t>
<t tx="ekr.20221020070914.210">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Execute files of Python code."""

import importlib.machinery
import importlib.util
import inspect
import marshal
import os
import struct
import sys
import types

from coverage import env
from coverage.exceptions import CoverageException, _ExceptionDuringRun, NoCode, NoSource
from coverage.files import canonical_filename, python_reported_file
from coverage.misc import isolate_module
from coverage.phystokens import compile_unicode
from coverage.python import get_python_source

os = isolate_module(os)


PYC_MAGIC_NUMBER = importlib.util.MAGIC_NUMBER

@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.211">class DummyLoader:
    """A shim for the pep302 __loader__, emulating pkgutil.ImpLoader.

    Currently only implements the .fullname attribute
    """
    def __init__(self, fullname, *_args):
        self.fullname = fullname


</t>
<t tx="ekr.20221020070914.212">def find_module(modulename):
    """Find the module named `modulename`.

    Returns the file path of the module, the name of the enclosing
    package, and the spec.
    """
    try:
        spec = importlib.util.find_spec(modulename)
    except ImportError as err:
        raise NoSource(str(err)) from err
    if not spec:
        raise NoSource(f"No module named {modulename!r}")
    pathname = spec.origin
    packagename = spec.name
    if spec.submodule_search_locations:
        mod_main = modulename + ".__main__"
        spec = importlib.util.find_spec(mod_main)
        if not spec:
            raise NoSource(
                f"No module named {mod_main}; " +
                f"{modulename!r} is a package and cannot be directly executed"
            )
        pathname = spec.origin
        packagename = spec.name
    packagename = packagename.rpartition(".")[0]
    return pathname, packagename, spec


</t>
<t tx="ekr.20221020070914.213">class PyRunner:
    """Multi-stage execution of Python code.

    This is meant to emulate real Python execution as closely as possible.

    """
    @others
</t>
<t tx="ekr.20221020070914.214">def __init__(self, args, as_module=False):
    self.args = args
    self.as_module = as_module

    self.arg0 = args[0]
    self.package = self.modulename = self.pathname = self.loader = self.spec = None

</t>
<t tx="ekr.20221020070914.215">def prepare(self):
    """Set sys.path properly.

    This needs to happen before any importing, and without importing anything.
    """
    if self.as_module:
        path0 = os.getcwd()
    elif os.path.isdir(self.arg0):
        # Running a directory means running the __main__.py file in that
        # directory.
        path0 = self.arg0
    else:
        path0 = os.path.abspath(os.path.dirname(self.arg0))

    if os.path.isdir(sys.path[0]):
        # sys.path fakery.  If we are being run as a command, then sys.path[0]
        # is the directory of the "coverage" script.  If this is so, replace
        # sys.path[0] with the directory of the file we're running, or the
        # current directory when running modules.  If it isn't so, then we
        # don't know what's going on, and just leave it alone.
        top_file = inspect.stack()[-1][0].f_code.co_filename
        sys_path_0_abs = os.path.abspath(sys.path[0])
        top_file_dir_abs = os.path.abspath(os.path.dirname(top_file))
        sys_path_0_abs = canonical_filename(sys_path_0_abs)
        top_file_dir_abs = canonical_filename(top_file_dir_abs)
        if sys_path_0_abs != top_file_dir_abs:
            path0 = None

    else:
        # sys.path[0] is a file. Is the next entry the directory containing
        # that file?
        if sys.path[1] == os.path.dirname(sys.path[0]):
            # Can it be right to always remove that?
            del sys.path[1]

    if path0 is not None:
        sys.path[0] = python_reported_file(path0)

</t>
<t tx="ekr.20221020070914.216">def _prepare2(self):
    """Do more preparation to run Python code.

    Includes finding the module to run and adjusting sys.argv[0].
    This method is allowed to import code.

    """
    if self.as_module:
        self.modulename = self.arg0
        pathname, self.package, self.spec = find_module(self.modulename)
        if self.spec is not None:
            self.modulename = self.spec.name
        self.loader = DummyLoader(self.modulename)
        self.pathname = os.path.abspath(pathname)
        self.args[0] = self.arg0 = self.pathname
    elif os.path.isdir(self.arg0):
        # Running a directory means running the __main__.py file in that
        # directory.
        for ext in [".py", ".pyc", ".pyo"]:
            try_filename = os.path.join(self.arg0, "__main__" + ext)
            # 3.8.10 changed how files are reported when running a
            # directory.  But I'm not sure how far this change is going to
            # spread, so I'll just hard-code it here for now.
            if env.PYVERSION &gt;= (3, 8, 10):
                try_filename = os.path.abspath(try_filename)
            if os.path.exists(try_filename):
                self.arg0 = try_filename
                break
        else:
            raise NoSource(f"Can't find '__main__' module in '{self.arg0}'")

        # Make a spec. I don't know if this is the right way to do it.
        try_filename = python_reported_file(try_filename)
        self.spec = importlib.machinery.ModuleSpec("__main__", None, origin=try_filename)
        self.spec.has_location = True
        self.package = ""
        self.loader = DummyLoader("__main__")
    else:
        self.loader = DummyLoader("__main__")

    self.arg0 = python_reported_file(self.arg0)

</t>
<t tx="ekr.20221020070914.217">def run(self):
    """Run the Python code!"""

    self._prepare2()

    # Create a module to serve as __main__
    main_mod = types.ModuleType('__main__')

    from_pyc = self.arg0.endswith((".pyc", ".pyo"))
    main_mod.__file__ = self.arg0
    if from_pyc:
        main_mod.__file__ = main_mod.__file__[:-1]
    if self.package is not None:
        main_mod.__package__ = self.package
    main_mod.__loader__ = self.loader
    if self.spec is not None:
        main_mod.__spec__ = self.spec

    main_mod.__builtins__ = sys.modules['builtins']

    sys.modules['__main__'] = main_mod

    # Set sys.argv properly.
    sys.argv = self.args

    try:
        # Make a code object somehow.
        if from_pyc:
            code = make_code_from_pyc(self.arg0)
        else:
            code = make_code_from_py(self.arg0)
    except CoverageException:
        raise
    except Exception as exc:
        msg = f"Couldn't run '{self.arg0}' as Python code: {exc.__class__.__name__}: {exc}"
        raise CoverageException(msg) from exc

    # Execute the code object.
    # Return to the original directory in case the test code exits in
    # a non-existent directory.
    cwd = os.getcwd()
    try:
        exec(code, main_mod.__dict__)
    except SystemExit:                          # pylint: disable=try-except-raise
        # The user called sys.exit().  Just pass it along to the upper
        # layers, where it will be handled.
        raise
    except Exception:
        # Something went wrong while executing the user code.
        # Get the exc_info, and pack them into an exception that we can
        # throw up to the outer loop.  We peel one layer off the traceback
        # so that the coverage.py code doesn't appear in the final printed
        # traceback.
        typ, err, tb = sys.exc_info()

        # PyPy3 weirdness.  If I don't access __context__, then somehow it
        # is non-None when the exception is reported at the upper layer,
        # and a nested exception is shown to the user.  This getattr fixes
        # it somehow? https://bitbucket.org/pypy/pypy/issue/1903
        getattr(err, '__context__', None)

        # Call the excepthook.
        try:
            err.__traceback__ = err.__traceback__.tb_next
            sys.excepthook(typ, err, tb.tb_next)
        except SystemExit:                      # pylint: disable=try-except-raise
            raise
        except Exception as exc:
            # Getting the output right in the case of excepthook
            # shenanigans is kind of involved.
            sys.stderr.write("Error in sys.excepthook:\n")
            typ2, err2, tb2 = sys.exc_info()
            err2.__suppress_context__ = True
            err2.__traceback__ = err2.__traceback__.tb_next
            sys.__excepthook__(typ2, err2, tb2.tb_next)
            sys.stderr.write("\nOriginal exception was:\n")
            raise _ExceptionDuringRun(typ, err, tb.tb_next) from exc
        else:
            sys.exit(1)
    finally:
        os.chdir(cwd)


</t>
<t tx="ekr.20221020070914.218">def run_python_module(args):
    """Run a Python module, as though with ``python -m name args...``.

    `args` is the argument array to present as sys.argv, including the first
    element naming the module being executed.

    This is a helper for tests, to encapsulate how to use PyRunner.

    """
    runner = PyRunner(args, as_module=True)
    runner.prepare()
    runner.run()


</t>
<t tx="ekr.20221020070914.219">def run_python_file(args):
    """Run a Python file as if it were the main program on the command line.

    `args` is the argument array to present as sys.argv, including the first
    element naming the file being executed.  `package` is the name of the
    enclosing package, if any.

    This is a helper for tests, to encapsulate how to use PyRunner.

    """
    runner = PyRunner(args, as_module=False)
    runner.prepare()
    runner.run()


</t>
<t tx="ekr.20221020070914.22">__hash__ = None     # This object doesn't need to be hashed.

</t>
<t tx="ekr.20221020070914.220">def make_code_from_py(filename):
    """Get source from `filename` and make a code object of it."""
    # Open the source file.
    try:
        source = get_python_source(filename)
    except (OSError, NoSource) as exc:
        raise NoSource(f"No file to run: '{filename}'") from exc

    code = compile_unicode(source, filename, "exec")
    return code


</t>
<t tx="ekr.20221020070914.221">def make_code_from_pyc(filename):
    """Get a code object from a .pyc file."""
    try:
        fpyc = open(filename, "rb")
    except OSError as exc:
        raise NoCode(f"No file to run: '{filename}'") from exc

    with fpyc:
        # First four bytes are a version-specific magic number.  It has to
        # match or we won't run the file.
        magic = fpyc.read(4)
        if magic != PYC_MAGIC_NUMBER:
            raise NoCode(f"Bad magic number in .pyc file: {magic!r} != {PYC_MAGIC_NUMBER!r}")

        flags = struct.unpack('&lt;L', fpyc.read(4))[0]
        hash_based = flags &amp; 0x01
        if hash_based:
            fpyc.read(8)    # Skip the hash.
        else:
            # Skip the junk in the header that we don't need.
            fpyc.read(4)    # Skip the moddate.
            fpyc.read(4)    # Skip the size.

        # The rest of the file is the code object we want.
        code = marshal.load(fpyc)

    return code
</t>
<t tx="ekr.20221020070914.222">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""File wrangling."""

import fnmatch
import hashlib
import ntpath
import os
import os.path
import posixpath
import re
import sys

from coverage import env
from coverage.exceptions import ConfigError
from coverage.misc import contract, human_sorted, isolate_module, join_regex


os = isolate_module(os)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.223">def set_relative_directory():
    """Set the directory that `relative_filename` will be relative to."""
    global RELATIVE_DIR, CANONICAL_FILENAME_CACHE

    # The current directory
    abs_curdir = abs_file(os.curdir)
    if not abs_curdir.endswith(os.sep):
        # Suffix with separator only if not at the system root
        abs_curdir = abs_curdir + os.sep

    # The absolute path to our current directory.
    RELATIVE_DIR = os.path.normcase(abs_curdir)

    # Cache of results of calling the canonical_filename() method, to
    # avoid duplicating work.
    CANONICAL_FILENAME_CACHE = {}


</t>
<t tx="ekr.20221020070914.224">def relative_directory():
    """Return the directory that `relative_filename` is relative to."""
    return RELATIVE_DIR


</t>
<t tx="ekr.20221020070914.225">@contract(returns='unicode')
def relative_filename(filename):
    """Return the relative form of `filename`.

    The file name will be relative to the current directory when the
    `set_relative_directory` was called.

    """
    fnorm = os.path.normcase(filename)
    if fnorm.startswith(RELATIVE_DIR):
        filename = filename[len(RELATIVE_DIR):]
    return filename


</t>
<t tx="ekr.20221020070914.226">@contract(returns='unicode')
def canonical_filename(filename):
    """Return a canonical file name for `filename`.

    An absolute path with no redundant components and normalized case.

    """
    if filename not in CANONICAL_FILENAME_CACHE:
        cf = filename
        if not os.path.isabs(filename):
            for path in [os.curdir] + sys.path:
                if path is None:
                    continue
                f = os.path.join(path, filename)
                try:
                    exists = os.path.exists(f)
                except UnicodeError:
                    exists = False
                if exists:
                    cf = f
                    break
        cf = abs_file(cf)
        CANONICAL_FILENAME_CACHE[filename] = cf
    return CANONICAL_FILENAME_CACHE[filename]


</t>
<t tx="ekr.20221020070914.227">MAX_FLAT = 100

</t>
<t tx="ekr.20221020070914.228">@contract(filename='unicode', returns='unicode')
def flat_rootname(filename):
    """A base for a flat file name to correspond to this file.

    Useful for writing files about the code where you want all the files in
    the same directory, but need to differentiate same-named files from
    different directories.

    For example, the file a/b/c.py will return 'd_86bbcbe134d28fd2_c_py'

    """
    dirname, basename = ntpath.split(filename)
    if dirname:
        fp = hashlib.new("sha3_256", dirname.encode("UTF-8")).hexdigest()[:16]
        prefix = f"d_{fp}_"
    else:
        prefix = ""
    return prefix + basename.replace(".", "_")


</t>
<t tx="ekr.20221020070914.229">if env.WINDOWS:

    _ACTUAL_PATH_CACHE = {}
    _ACTUAL_PATH_LIST_CACHE = {}

    def actual_path(path):
        """Get the actual path of `path`, including the correct case."""
        if path in _ACTUAL_PATH_CACHE:
            return _ACTUAL_PATH_CACHE[path]

        head, tail = os.path.split(path)
        if not tail:
            # This means head is the drive spec: normalize it.
            actpath = head.upper()
        elif not head:
            actpath = tail
        else:
            head = actual_path(head)
            if head in _ACTUAL_PATH_LIST_CACHE:
                files = _ACTUAL_PATH_LIST_CACHE[head]
            else:
                try:
                    files = os.listdir(head)
                except Exception:
                    # This will raise OSError, or this bizarre TypeError:
                    # https://bugs.python.org/issue1776160
                    files = []
                _ACTUAL_PATH_LIST_CACHE[head] = files
            normtail = os.path.normcase(tail)
            for f in files:
                if os.path.normcase(f) == normtail:
                    tail = f
                    break
            actpath = os.path.join(head, tail)
        _ACTUAL_PATH_CACHE[path] = actpath
        return actpath

else:
    def actual_path(path):
        """The actual path for non-Windows platforms."""
        return path


</t>
<t tx="ekr.20221020070914.23">def get_prog_name(self):
    """Override of an undocumented function in optparse.OptionParser."""
    program_name = super().get_prog_name()

    # Include the sub-command for this parser as part of the command.
    return f"{program_name} {self.cmd}"

</t>
<t tx="ekr.20221020070914.230">@contract(returns='unicode')
def abs_file(path):
    """Return the absolute normalized form of `path`."""
    return actual_path(os.path.abspath(os.path.realpath(path)))


</t>
<t tx="ekr.20221020070914.231">def python_reported_file(filename):
    """Return the string as Python would describe this file name."""
    if env.PYBEHAVIOR.report_absolute_files:
        filename = os.path.abspath(filename)
    return filename


</t>
<t tx="ekr.20221020070914.232">RELATIVE_DIR = None
CANONICAL_FILENAME_CACHE = None
set_relative_directory()


</t>
<t tx="ekr.20221020070914.233">def isabs_anywhere(filename):
    """Is `filename` an absolute path on any OS?"""
    return ntpath.isabs(filename) or posixpath.isabs(filename)


</t>
<t tx="ekr.20221020070914.234">def prep_patterns(patterns):
    """Prepare the file patterns for use in a `FnmatchMatcher`.

    If a pattern starts with a wildcard, it is used as a pattern
    as-is.  If it does not start with a wildcard, then it is made
    absolute with the current directory.

    If `patterns` is None, an empty list is returned.

    """
    prepped = []
    for p in patterns or []:
        if p.startswith(("*", "?")):
            prepped.append(p)
        else:
            prepped.append(abs_file(p))
    return prepped


</t>
<t tx="ekr.20221020070914.235">class TreeMatcher:
    """A matcher for files in a tree.

    Construct with a list of paths, either files or directories. Paths match
    with the `match` method if they are one of the files, or if they are
    somewhere in a subtree rooted at one of the directories.

    """
    @others
</t>
<t tx="ekr.20221020070914.236">def __init__(self, paths, name="unknown"):
    self.original_paths = human_sorted(paths)
    self.paths = list(map(os.path.normcase, paths))
    self.name = name

</t>
<t tx="ekr.20221020070914.237">def __repr__(self):
    return f"&lt;TreeMatcher {self.name} {self.original_paths!r}&gt;"

</t>
<t tx="ekr.20221020070914.238">def info(self):
    """A list of strings for displaying when dumping state."""
    return self.original_paths

</t>
<t tx="ekr.20221020070914.239">def match(self, fpath):
    """Does `fpath` indicate a file in one of our trees?"""
    fpath = os.path.normcase(fpath)
    for p in self.paths:
        if fpath.startswith(p):
            if fpath == p:
                # This is the same file!
                return True
            if fpath[len(p)] == os.sep:
                # This is a file in the directory
                return True
    return False


</t>
<t tx="ekr.20221020070914.24"># In lists of Opts, keep them alphabetized by the option names as they appear
# on the command line, since these lists determine the order of the options in
# the help output.
#
# In COMMANDS, keep the keys (command names) alphabetized.

GLOBAL_ARGS = [
    Opts.debug,
    Opts.help,
    Opts.rcfile,
]

COMMANDS = {
    'annotate': CmdOptionParser(
        "annotate",
        [
            Opts.directory,
            Opts.input_datafile,
            Opts.ignore_errors,
            Opts.include,
            Opts.omit,
            ] + GLOBAL_ARGS,
        usage="[options] [modules]",
        description=(
            "Make annotated copies of the given files, marking statements that are executed " +
            "with &gt; and statements that are missed with !."
        ),
    ),

    'combine': CmdOptionParser(
        "combine",
        [
            Opts.append,
            Opts.combine_datafile,
            Opts.keep,
            Opts.quiet,
            ] + GLOBAL_ARGS,
        usage="[options] &lt;path1&gt; &lt;path2&gt; ... &lt;pathN&gt;",
        description=(
            "Combine data from multiple coverage files collected " +
            "with 'run -p'.  The combined results are written to a single " +
            "file representing the union of the data. The positional " +
            "arguments are data files or directories containing data files. " +
            "If no paths are provided, data files in the default data file's " +
            "directory are combined."
        ),
    ),

    'debug': CmdOptionParser(
        "debug", GLOBAL_ARGS,
        usage="&lt;topic&gt;",
        description=(
            "Display information about the internals of coverage.py, " +
            "for diagnosing problems. " +
            "Topics are: " +
                "'data' to show a summary of the collected data; " +
                "'sys' to show installation information; " +
                "'config' to show the configuration; " +
                "'premain' to show what is calling coverage; " +
                "'pybehave' to show internal flags describing Python behavior."
        ),
    ),

    'erase': CmdOptionParser(
        "erase",
        [
            Opts.combine_datafile
            ] + GLOBAL_ARGS,
        description="Erase previously collected coverage data.",
    ),

    'help': CmdOptionParser(
        "help", GLOBAL_ARGS,
        usage="[command]",
        description="Describe how to use coverage.py",
    ),

    'html': CmdOptionParser(
        "html",
        [
            Opts.contexts,
            Opts.directory,
            Opts.input_datafile,
            Opts.fail_under,
            Opts.ignore_errors,
            Opts.include,
            Opts.omit,
            Opts.precision,
            Opts.quiet,
            Opts.show_contexts,
            Opts.skip_covered,
            Opts.no_skip_covered,
            Opts.skip_empty,
            Opts.title,
            ] + GLOBAL_ARGS,
        usage="[options] [modules]",
        description=(
            "Create an HTML report of the coverage of the files.  " +
            "Each file gets its own page, with the source decorated to show " +
            "executed, excluded, and missed lines."
        ),
    ),

    'json': CmdOptionParser(
        "json",
        [
            Opts.contexts,
            Opts.input_datafile,
            Opts.fail_under,
            Opts.ignore_errors,
            Opts.include,
            Opts.omit,
            Opts.output_json,
            Opts.json_pretty_print,
            Opts.quiet,
            Opts.show_contexts,
            ] + GLOBAL_ARGS,
        usage="[options] [modules]",
        description="Generate a JSON report of coverage results.",
    ),

    'lcov': CmdOptionParser(
        "lcov",
        [
            Opts.input_datafile,
            Opts.fail_under,
            Opts.ignore_errors,
            Opts.include,
            Opts.output_lcov,
            Opts.omit,
            Opts.quiet,
            ] + GLOBAL_ARGS,
        usage="[options] [modules]",
        description="Generate an LCOV report of coverage results.",
    ),

    'report': CmdOptionParser(
        "report",
        [
            Opts.contexts,
            Opts.input_datafile,
            Opts.fail_under,
            Opts.ignore_errors,
            Opts.include,
            Opts.omit,
            Opts.precision,
            Opts.sort,
            Opts.show_missing,
            Opts.skip_covered,
            Opts.no_skip_covered,
            Opts.skip_empty,
            ] + GLOBAL_ARGS,
        usage="[options] [modules]",
        description="Report coverage statistics on modules.",
    ),

    'run': CmdOptionParser(
        "run",
        [
            Opts.append,
            Opts.branch,
            Opts.concurrency,
            Opts.context,
            Opts.output_datafile,
            Opts.include,
            Opts.module,
            Opts.omit,
            Opts.pylib,
            Opts.parallel_mode,
            Opts.source,
            Opts.timid,
            ] + GLOBAL_ARGS,
        usage="[options] &lt;pyfile&gt; [program options]",
        description="Run a Python program, measuring code execution.",
    ),

    'xml': CmdOptionParser(
        "xml",
        [
            Opts.input_datafile,
            Opts.fail_under,
            Opts.ignore_errors,
            Opts.include,
            Opts.omit,
            Opts.output_xml,
            Opts.quiet,
            Opts.skip_empty,
            ] + GLOBAL_ARGS,
        usage="[options] [modules]",
        description="Generate an XML report of coverage results.",
    ),
}


</t>
<t tx="ekr.20221020070914.240">class ModuleMatcher:
    """A matcher for modules in a tree."""
    @others
</t>
<t tx="ekr.20221020070914.241">def __init__(self, module_names, name="unknown"):
    self.modules = list(module_names)
    self.name = name

</t>
<t tx="ekr.20221020070914.242">def __repr__(self):
    return f"&lt;ModuleMatcher {self.name} {self.modules!r}&gt;"

</t>
<t tx="ekr.20221020070914.243">def info(self):
    """A list of strings for displaying when dumping state."""
    return self.modules

</t>
<t tx="ekr.20221020070914.244">def match(self, module_name):
    """Does `module_name` indicate a module in one of our packages?"""
    if not module_name:
        return False

    for m in self.modules:
        if module_name.startswith(m):
            if module_name == m:
                return True
            if module_name[len(m)] == '.':
                # This is a module in the package
                return True

    return False


</t>
<t tx="ekr.20221020070914.245">class FnmatchMatcher:
    """A matcher for files by file name pattern."""
    @others
</t>
<t tx="ekr.20221020070914.246">def __init__(self, pats, name="unknown"):
    self.pats = list(pats)
    self.re = fnmatches_to_regex(self.pats, case_insensitive=env.WINDOWS)
    self.name = name

</t>
<t tx="ekr.20221020070914.247">def __repr__(self):
    return f"&lt;FnmatchMatcher {self.name} {self.pats!r}&gt;"

</t>
<t tx="ekr.20221020070914.248">def info(self):
    """A list of strings for displaying when dumping state."""
    return self.pats

</t>
<t tx="ekr.20221020070914.249">def match(self, fpath):
    """Does `fpath` match one of our file name patterns?"""
    return self.re.match(fpath) is not None


</t>
<t tx="ekr.20221020070914.25">def show_help(error=None, topic=None, parser=None):
    """Display an error message, or the named topic."""
    assert error or topic or parser

    program_path = sys.argv[0]
    if program_path.endswith(os.path.sep + '__main__.py'):
        # The path is the main module of a package; get that path instead.
        program_path = os.path.dirname(program_path)
    program_name = os.path.basename(program_path)
    if env.WINDOWS:
        # entry_points={'console_scripts':...} on Windows makes files
        # called coverage.exe, coverage3.exe, and coverage-3.5.exe. These
        # invoke coverage-script.py, coverage3-script.py, and
        # coverage-3.5-script.py.  argv[0] is the .py file, but we want to
        # get back to the original form.
        auto_suffix = "-script.py"
        if program_name.endswith(auto_suffix):
            program_name = program_name[:-len(auto_suffix)]

    help_params = dict(coverage.__dict__)
    help_params['program_name'] = program_name
    if CTracer is not None:
        help_params['extension_modifier'] = 'with C extension'
    else:
        help_params['extension_modifier'] = 'without C extension'

    if error:
        print(error, file=sys.stderr)
        print(f"Use '{program_name} help' for help.", file=sys.stderr)
    elif parser:
        print(parser.format_help().strip())
        print()
    else:
        help_msg = textwrap.dedent(HELP_TOPICS.get(topic, '')).strip()
        if help_msg:
            print(help_msg.format(**help_params))
        else:
            print(f"Don't know topic {topic!r}")
    print("Full documentation is at {__url__}".format(**help_params))


</t>
<t tx="ekr.20221020070914.250">def sep(s):
    """Find the path separator used in this string, or os.sep if none."""
    sep_match = re.search(r"[\\/]", s)
    if sep_match:
        the_sep = sep_match[0]
    else:
        the_sep = os.sep
    return the_sep


</t>
<t tx="ekr.20221020070914.251">def fnmatches_to_regex(patterns, case_insensitive=False, partial=False):
    """Convert fnmatch patterns to a compiled regex that matches any of them.

    Slashes are always converted to match either slash or backslash, for
    Windows support, even when running elsewhere.

    If `partial` is true, then the pattern will match if the target string
    starts with the pattern. Otherwise, it must match the entire string.

    Returns: a compiled regex object.  Use the .match method to compare target
    strings.

    """
    regexes = (fnmatch.translate(pattern) for pattern in patterns)
    # Python3.7 fnmatch translates "/" as "/". Before that, it translates as "\/",
    # so we have to deal with maybe a backslash.
    regexes = (re.sub(r"\\?/", r"[\\\\/]", regex) for regex in regexes)

    if partial:
        # fnmatch always adds a \Z to match the whole string, which we don't
        # want, so we remove the \Z.  While removing it, we only replace \Z if
        # followed by paren (introducing flags), or at end, to keep from
        # destroying a literal \Z in the pattern.
        regexes = (re.sub(r'\\Z(\(\?|$)', r'\1', regex) for regex in regexes)

    flags = 0
    if case_insensitive:
        flags |= re.IGNORECASE
    compiled = re.compile(join_regex(regexes), flags=flags)

    return compiled


</t>
<t tx="ekr.20221020070914.252">class PathAliases:
    """A collection of aliases for paths.

    When combining data files from remote machines, often the paths to source
    code are different, for example, due to OS differences, or because of
    serialized checkouts on continuous integration machines.

    A `PathAliases` object tracks a list of pattern/result pairs, and can
    map a path through those aliases to produce a unified path.

    """
    @others
</t>
<t tx="ekr.20221020070914.253">def __init__(self, debugfn=None, relative=False):
    self.aliases = []   # A list of (original_pattern, regex, result)
    self.debugfn = debugfn or (lambda msg: 0)
    self.relative = relative
    self.pprinted = False
</t>
<t tx="ekr.20221020070914.254">
def pprint(self):
    """Dump the important parts of the PathAliases, for debugging."""
    self.debugfn(f"Aliases (relative={self.relative}):")
    for original_pattern, regex, result in self.aliases:
        self.debugfn(f" Rule: {original_pattern!r} -&gt; {result!r} using regex {regex.pattern!r}")

</t>
<t tx="ekr.20221020070914.255">def add(self, pattern, result):
    """Add the `pattern`/`result` pair to the list of aliases.

    `pattern` is an `fnmatch`-style pattern.  `result` is a simple
    string.  When mapping paths, if a path starts with a match against
    `pattern`, then that match is replaced with `result`.  This models
    isomorphic source trees being rooted at different places on two
    different machines.

    `pattern` can't end with a wildcard component, since that would
    match an entire tree, and not just its root.

    """
    original_pattern = pattern
    pattern_sep = sep(pattern)

    if len(pattern) &gt; 1:
        pattern = pattern.rstrip(r"\/")

    # The pattern can't end with a wildcard component.
    if pattern.endswith("*"):
        raise ConfigError("Pattern must not end with wildcards.")

    # The pattern is meant to match a filepath.  Let's make it absolute
    # unless it already is, or is meant to match any prefix.
    if not pattern.startswith('*') and not isabs_anywhere(pattern + pattern_sep):
        pattern = abs_file(pattern)
    if not pattern.endswith(pattern_sep):
        pattern += pattern_sep

    # Make a regex from the pattern.
    regex = fnmatches_to_regex([pattern], case_insensitive=True, partial=True)

    # Normalize the result: it must end with a path separator.
    result_sep = sep(result)
    result = result.rstrip(r"\/") + result_sep
    self.aliases.append((original_pattern, regex, result))

</t>
<t tx="ekr.20221020070914.256">def map(self, path):
    """Map `path` through the aliases.

    `path` is checked against all of the patterns.  The first pattern to
    match is used to replace the root of the path with the result root.
    Only one pattern is ever used.  If no patterns match, `path` is
    returned unchanged.

    The separator style in the result is made to match that of the result
    in the alias.

    Returns the mapped path.  If a mapping has happened, this is a
    canonical path.  If no mapping has happened, it is the original value
    of `path` unchanged.

    """
    if not self.pprinted:
        self.pprint()
        self.pprinted = True

    for original_pattern, regex, result in self.aliases:
        m = regex.match(path)
        if m:
            new = path.replace(m[0], result)
            new = new.replace(sep(path), sep(result))
            if not self.relative:
                new = canonical_filename(new)
            self.debugfn(
                f"Matched path {path!r} to rule {original_pattern!r} -&gt; {result!r}, " +
                f"producing {new!r}"
            )
            return new
    self.debugfn(f"No rules match, path {path!r} is unchanged")
    return path


</t>
<t tx="ekr.20221020070914.257">def find_python_files(dirname):
    """Yield all of the importable Python files in `dirname`, recursively.

    To be importable, the files have to be in a directory with a __init__.py,
    except for `dirname` itself, which isn't required to have one.  The
    assumption is that `dirname` was specified directly, so the user knows
    best, but sub-directories are checked for a __init__.py to be sure we only
    find the importable files.

    """
    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dirname)):
        if i &gt; 0 and '__init__.py' not in filenames:
            # If a directory doesn't have __init__.py, then it isn't
            # importable and neither are its files
            del dirnames[:]
            continue
        for filename in filenames:
            # We're only interested in files that look like reasonable Python
            # files: Must end with .py or .pyw, and must not have certain funny
            # characters that probably mean they are editor junk.
            if re.match(r"^[^.#~!$@%^&amp;*()+=,]+\.pyw?$", filename):
                yield os.path.join(dirpath, filename)
</t>
<t tx="ekr.20221020070914.258">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""HTML reporting for coverage.py."""

import datetime
import json
import os
import re
import shutil
import types

import coverage
from coverage.data import add_data_to_hash
from coverage.exceptions import NoDataError
from coverage.files import flat_rootname
from coverage.misc import ensure_dir, file_be_gone, Hasher, isolate_module, format_local_datetime
from coverage.misc import human_sorted, plural
from coverage.report import get_analysis_to_report
from coverage.results import Numbers
from coverage.templite import Templite

os = isolate_module(os)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.259">def data_filename(fname):
    """Return the path to an "htmlfiles" data file of ours.
    """
    static_dir = os.path.join(os.path.dirname(__file__), "htmlfiles")
    static_filename = os.path.join(static_dir, fname)
    return static_filename


</t>
<t tx="ekr.20221020070914.26">OK, ERR, FAIL_UNDER = 0, 1, 2


</t>
<t tx="ekr.20221020070914.260">def read_data(fname):
    """Return the contents of a data file of ours."""
    with open(data_filename(fname)) as data_file:
        return data_file.read()


</t>
<t tx="ekr.20221020070914.261">def write_html(fname, html):
    """Write `html` to `fname`, properly encoded."""
    html = re.sub(r"(\A\s+)|(\s+$)", "", html, flags=re.MULTILINE) + "\n"
    with open(fname, "wb") as fout:
        fout.write(html.encode('ascii', 'xmlcharrefreplace'))


</t>
<t tx="ekr.20221020070914.262">class HtmlDataGeneration:
    """Generate structured data to be turned into HTML reports."""

    EMPTY = "(empty)"

    @others
</t>
<t tx="ekr.20221020070914.263">def __init__(self, cov):
    self.coverage = cov
    self.config = self.coverage.config
    data = self.coverage.get_data()
    self.has_arcs = data.has_arcs()
    if self.config.show_contexts:
        if data.measured_contexts() == {""}:
            self.coverage._warn("No contexts were measured")
    data.set_query_contexts(self.config.report_contexts)

</t>
<t tx="ekr.20221020070914.264">def data_for_file(self, fr, analysis):
    """Produce the data needed for one file's report."""
    if self.has_arcs:
        missing_branch_arcs = analysis.missing_branch_arcs()
        arcs_executed = analysis.arcs_executed()

    if self.config.show_contexts:
        contexts_by_lineno = analysis.data.contexts_by_lineno(analysis.filename)

    lines = []

    for lineno, tokens in enumerate(fr.source_token_lines(), start=1):
        # Figure out how to mark this line.
        category = None
        short_annotations = []
        long_annotations = []

        if lineno in analysis.excluded:
            category = 'exc'
        elif lineno in analysis.missing:
            category = 'mis'
        elif self.has_arcs and lineno in missing_branch_arcs:
            category = 'par'
            for b in missing_branch_arcs[lineno]:
                if b &lt; 0:
                    short_annotations.append("exit")
                else:
                    short_annotations.append(b)
                long_annotations.append(fr.missing_arc_description(lineno, b, arcs_executed))
        elif lineno in analysis.statements:
            category = 'run'

        contexts = contexts_label = None
        context_list = None
        if category and self.config.show_contexts:
            contexts = human_sorted(c or self.EMPTY for c in contexts_by_lineno.get(lineno, ()))
            if contexts == [self.EMPTY]:
                contexts_label = self.EMPTY
            else:
                contexts_label = f"{len(contexts)} ctx"
                context_list = contexts

        lines.append(types.SimpleNamespace(
            tokens=tokens,
            number=lineno,
            category=category,
            statement=(lineno in analysis.statements),
            contexts=contexts,
            contexts_label=contexts_label,
            context_list=context_list,
            short_annotations=short_annotations,
            long_annotations=long_annotations,
        ))

    file_data = types.SimpleNamespace(
        relative_filename=fr.relative_filename(),
        nums=analysis.numbers,
        lines=lines,
    )

    return file_data


</t>
<t tx="ekr.20221020070914.265">class FileToReport:
    """A file we're considering reporting."""
    def __init__(self, fr, analysis):
        self.fr = fr
        self.analysis = analysis
        self.rootname = flat_rootname(fr.relative_filename())
        self.html_filename = self.rootname + ".html"


</t>
<t tx="ekr.20221020070914.266">class HtmlReporter:
    """HTML reporting."""

    # These files will be copied from the htmlfiles directory to the output
    # directory.
    STATIC_FILES = [
        "style.css",
        "coverage_html.js",
        "keybd_closed.png",
        "keybd_open.png",
        "favicon_32.png",
    ]

    @others
</t>
<t tx="ekr.20221020070914.267">def __init__(self, cov):
    self.coverage = cov
    self.config = self.coverage.config
    self.directory = self.config.html_dir

    self.skip_covered = self.config.html_skip_covered
    if self.skip_covered is None:
        self.skip_covered = self.config.skip_covered
    self.skip_empty = self.config.html_skip_empty
    if self.skip_empty is None:
        self.skip_empty = self.config.skip_empty
    self.skipped_covered_count = 0
    self.skipped_empty_count = 0

    title = self.config.html_title

    if self.config.extra_css:
        self.extra_css = os.path.basename(self.config.extra_css)
    else:
        self.extra_css = None

    self.data = self.coverage.get_data()
    self.has_arcs = self.data.has_arcs()

    self.file_summaries = []
    self.all_files_nums = []
    self.incr = IncrementalChecker(self.directory)
    self.datagen = HtmlDataGeneration(self.coverage)
    self.totals = Numbers(precision=self.config.precision)
    self.directory_was_empty = False
    self.first_fr = None
    self.final_fr = None

    self.template_globals = {
        # Functions available in the templates.
        'escape': escape,
        'pair': pair,
        'len': len,

        # Constants for this report.
        '__url__': coverage.__url__,
        '__version__': coverage.__version__,
        'title': title,
        'time_stamp': format_local_datetime(datetime.datetime.now()),
        'extra_css': self.extra_css,
        'has_arcs': self.has_arcs,
        'show_contexts': self.config.show_contexts,

        # Constants for all reports.
        # These css classes determine which lines are highlighted by default.
        'category': {
            'exc': 'exc show_exc',
            'mis': 'mis show_mis',
            'par': 'par run show_par',
            'run': 'run',
        },
    }
    self.pyfile_html_source = read_data("pyfile.html")
    self.source_tmpl = Templite(self.pyfile_html_source, self.template_globals)

</t>
<t tx="ekr.20221020070914.268">def report(self, morfs):
    """Generate an HTML report for `morfs`.

    `morfs` is a list of modules or file names.

    """
    # Read the status data and check that this run used the same
    # global data as the last run.
    self.incr.read()
    self.incr.check_global_data(self.config, self.pyfile_html_source)

    # Process all the files. For each page we need to supply a link
    # to the next and previous page.
    files_to_report = []

    for fr, analysis in get_analysis_to_report(self.coverage, morfs):
        ftr = FileToReport(fr, analysis)
        should = self.should_report_file(ftr)
        if should:
            files_to_report.append(ftr)
        else:
            file_be_gone(os.path.join(self.directory, ftr.html_filename))

    for i, ftr in enumerate(files_to_report):
        if i == 0:
            prev_html = "index.html"
        else:
            prev_html = files_to_report[i - 1].html_filename
        if i == len(files_to_report) - 1:
            next_html = "index.html"
        else:
            next_html = files_to_report[i + 1].html_filename
        self.write_html_file(ftr, prev_html, next_html)

    if not self.all_files_nums:
        raise NoDataError("No data to report.")

    self.totals = sum(self.all_files_nums)

    # Write the index file.
    if files_to_report:
        first_html = files_to_report[0].html_filename
        final_html = files_to_report[-1].html_filename
    else:
        first_html = final_html = "index.html"
    self.index_file(first_html, final_html)

    self.make_local_static_report_files()
    return self.totals.n_statements and self.totals.pc_covered

</t>
<t tx="ekr.20221020070914.269">def make_directory(self):
    """Make sure our htmlcov directory exists."""
    ensure_dir(self.directory)
    if not os.listdir(self.directory):
        self.directory_was_empty = True

</t>
<t tx="ekr.20221020070914.27">class CoverageScript:
    """The command-line interface to coverage.py."""

    @others
</t>
<t tx="ekr.20221020070914.270">def make_local_static_report_files(self):
    """Make local instances of static files for HTML report."""
    # The files we provide must always be copied.
    for static in self.STATIC_FILES:
        shutil.copyfile(data_filename(static), os.path.join(self.directory, static))

    # Only write the .gitignore file if the directory was originally empty.
    # .gitignore can't be copied from the source tree because it would
    # prevent the static files from being checked in.
    if self.directory_was_empty:
        with open(os.path.join(self.directory, ".gitignore"), "w") as fgi:
            fgi.write("# Created by coverage.py\n*\n")

    # The user may have extra CSS they want copied.
    if self.extra_css:
        shutil.copyfile(self.config.extra_css, os.path.join(self.directory, self.extra_css))

</t>
<t tx="ekr.20221020070914.271">def should_report_file(self, ftr):
    """Determine if we'll report this file."""
    # Get the numbers for this file.
    nums = ftr.analysis.numbers
    self.all_files_nums.append(nums)

    if self.skip_covered:
        # Don't report on 100% files.
        no_missing_lines = (nums.n_missing == 0)
        no_missing_branches = (nums.n_partial_branches == 0)
        if no_missing_lines and no_missing_branches:
            # If there's an existing file, remove it.
            self.skipped_covered_count += 1
            return False

    if self.skip_empty:
        # Don't report on empty files.
        if nums.n_statements == 0:
            self.skipped_empty_count += 1
            return False

    return True

</t>
<t tx="ekr.20221020070914.272">def write_html_file(self, ftr, prev_html, next_html):
    """Generate an HTML file for one source file."""
    self.make_directory()

    # Find out if the file on disk is already correct.
    if self.incr.can_skip_file(self.data, ftr.fr, ftr.rootname):
        self.file_summaries.append(self.incr.index_info(ftr.rootname))
        return

    # Write the HTML page for this file.
    file_data = self.datagen.data_for_file(ftr.fr, ftr.analysis)
    for ldata in file_data.lines:
        # Build the HTML for the line.
        html = []
        for tok_type, tok_text in ldata.tokens:
            if tok_type == "ws":
                html.append(escape(tok_text))
            else:
                tok_html = escape(tok_text) or '&amp;nbsp;'
                html.append(
                    f'&lt;span class="{tok_type}"&gt;{tok_html}&lt;/span&gt;'
                )
        ldata.html = ''.join(html)

        if ldata.short_annotations:
            # 202F is NARROW NO-BREAK SPACE.
            # 219B is RIGHTWARDS ARROW WITH STROKE.
            ldata.annotate = ",&amp;nbsp;&amp;nbsp; ".join(
                f"{ldata.number}&amp;#x202F;&amp;#x219B;&amp;#x202F;{d}"
                for d in ldata.short_annotations
            )
        else:
            ldata.annotate = None

        if ldata.long_annotations:
            longs = ldata.long_annotations
            if len(longs) == 1:
                ldata.annotate_long = longs[0]
            else:
                ldata.annotate_long = "{:d} missed branches: {}".format(
                    len(longs),
                    ", ".join(
                        f"{num:d}) {ann_long}"
                        for num, ann_long in enumerate(longs, start=1)
                    ),
                )
        else:
            ldata.annotate_long = None

        css_classes = []
        if ldata.category:
            css_classes.append(self.template_globals['category'][ldata.category])
        ldata.css_class = ' '.join(css_classes) or "pln"

    html_path = os.path.join(self.directory, ftr.html_filename)
    html = self.source_tmpl.render({
        **file_data.__dict__,
        'prev_html': prev_html,
        'next_html': next_html,
    })
    write_html(html_path, html)

    # Save this file's information for the index file.
    index_info = {
        'nums': ftr.analysis.numbers,
        'html_filename': ftr.html_filename,
        'relative_filename': ftr.fr.relative_filename(),
    }
    self.file_summaries.append(index_info)
    self.incr.set_index_info(ftr.rootname, index_info)

</t>
<t tx="ekr.20221020070914.273">def index_file(self, first_html, final_html):
    """Write the index.html file for this report."""
    self.make_directory()
    index_tmpl = Templite(read_data("index.html"), self.template_globals)

    skipped_covered_msg = skipped_empty_msg = ""
    if self.skipped_covered_count:
        n = self.skipped_covered_count
        skipped_covered_msg = f"{n} file{plural(n)} skipped due to complete coverage."
    if self.skipped_empty_count:
        n = self.skipped_empty_count
        skipped_empty_msg = f"{n} empty file{plural(n)} skipped."

    html = index_tmpl.render({
        'files': self.file_summaries,
        'totals': self.totals,
        'skipped_covered_msg': skipped_covered_msg,
        'skipped_empty_msg': skipped_empty_msg,
        'first_html': first_html,
        'final_html': final_html,
    })

    index_file = os.path.join(self.directory, "index.html")
    write_html(index_file, html)
    self.coverage._message(f"Wrote HTML report to {index_file}")

    # Write the latest hashes for next time.
    self.incr.write()


</t>
<t tx="ekr.20221020070914.274">class IncrementalChecker:
    """Logic and data to support incremental reporting."""

    STATUS_FILE = "status.json"
    STATUS_FORMAT = 2

    #           pylint: disable=wrong-spelling-in-comment,useless-suppression
    #  The data looks like:
    #
    #  {
    #      "format": 2,
    #      "globals": "540ee119c15d52a68a53fe6f0897346d",
    #      "version": "4.0a1",
    #      "files": {
    #          "cogapp___init__": {
    #              "hash": "e45581a5b48f879f301c0f30bf77a50c",
    #              "index": {
    #                  "html_filename": "cogapp___init__.html",
    #                  "relative_filename": "cogapp/__init__",
    #                  "nums": [ 1, 14, 0, 0, 0, 0, 0 ]
    #              }
    #          },
    #          ...
    #          "cogapp_whiteutils": {
    #              "hash": "8504bb427fc488c4176809ded0277d51",
    #              "index": {
    #                  "html_filename": "cogapp_whiteutils.html",
    #                  "relative_filename": "cogapp/whiteutils",
    #                  "nums": [ 1, 59, 0, 1, 28, 2, 2 ]
    #              }
    #          }
    #      }
    #  }

    @others
</t>
<t tx="ekr.20221020070914.275">def __init__(self, directory):
    self.directory = directory
    self.reset()

</t>
<t tx="ekr.20221020070914.276">def reset(self):
    """Initialize to empty. Causes all files to be reported."""
    self.globals = ''
    self.files = {}

</t>
<t tx="ekr.20221020070914.277">def read(self):
    """Read the information we stored last time."""
    usable = False
    try:
        status_file = os.path.join(self.directory, self.STATUS_FILE)
        with open(status_file) as fstatus:
            status = json.load(fstatus)
    except (OSError, ValueError):
        usable = False
    else:
        usable = True
        if status['format'] != self.STATUS_FORMAT:
            usable = False
        elif status['version'] != coverage.__version__:
            usable = False

    if usable:
        self.files = {}
        for filename, fileinfo in status['files'].items():
            fileinfo['index']['nums'] = Numbers(*fileinfo['index']['nums'])
            self.files[filename] = fileinfo
        self.globals = status['globals']
    else:
        self.reset()

</t>
<t tx="ekr.20221020070914.278">def write(self):
    """Write the current status."""
    status_file = os.path.join(self.directory, self.STATUS_FILE)
    files = {}
    for filename, fileinfo in self.files.items():
        fileinfo['index']['nums'] = fileinfo['index']['nums'].init_args()
        files[filename] = fileinfo

    status = {
        'format': self.STATUS_FORMAT,
        'version': coverage.__version__,
        'globals': self.globals,
        'files': files,
    }
    with open(status_file, "w") as fout:
        json.dump(status, fout, separators=(',', ':'))

</t>
<t tx="ekr.20221020070914.279">def check_global_data(self, *data):
    """Check the global data that can affect incremental reporting."""
    m = Hasher()
    for d in data:
        m.update(d)
    these_globals = m.hexdigest()
    if self.globals != these_globals:
        self.reset()
        self.globals = these_globals

</t>
<t tx="ekr.20221020070914.28">def __init__(self):
    self.global_option = False
    self.coverage = None

</t>
<t tx="ekr.20221020070914.280">def can_skip_file(self, data, fr, rootname):
    """Can we skip reporting this file?

    `data` is a CoverageData object, `fr` is a `FileReporter`, and
    `rootname` is the name being used for the file.
    """
    m = Hasher()
    m.update(fr.source().encode('utf-8'))
    add_data_to_hash(data, fr.filename, m)
    this_hash = m.hexdigest()

    that_hash = self.file_hash(rootname)

    if this_hash == that_hash:
        # Nothing has changed to require the file to be reported again.
        return True
    else:
        self.set_file_hash(rootname, this_hash)
        return False

</t>
<t tx="ekr.20221020070914.281">def file_hash(self, fname):
    """Get the hash of `fname`'s contents."""
    return self.files.get(fname, {}).get('hash', '')

</t>
<t tx="ekr.20221020070914.282">def set_file_hash(self, fname, val):
    """Set the hash of `fname`'s contents."""
    self.files.setdefault(fname, {})['hash'] = val

</t>
<t tx="ekr.20221020070914.283">def index_info(self, fname):
    """Get the information for index.html for `fname`."""
    return self.files.get(fname, {}).get('index', {})

</t>
<t tx="ekr.20221020070914.284">def set_index_info(self, fname, info):
    """Set the information for index.html for `fname`."""
    self.files.setdefault(fname, {})['index'] = info


</t>
<t tx="ekr.20221020070914.285"># Helpers for templates and generating HTML

</t>
<t tx="ekr.20221020070914.286">def escape(t):
    """HTML-escape the text in `t`.

    This is only suitable for HTML text, not attributes.

    """
    # Convert HTML special chars into HTML entities.
    return t.replace("&amp;", "&amp;amp;").replace("&lt;", "&amp;lt;")


</t>
<t tx="ekr.20221020070914.287">def pair(ratio):
    """Format a pair of numbers so JavaScript can read them in an attribute."""
    return "%s %s" % ratio
</t>
<t tx="ekr.20221020070914.288">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Determining whether files are being measured/reported or not."""

import importlib.util
import inspect
import itertools
import os
import platform
import re
import sys
import sysconfig
import traceback

from coverage import env
from coverage.disposition import FileDisposition, disposition_init
from coverage.exceptions import CoverageException, PluginError
from coverage.files import TreeMatcher, FnmatchMatcher, ModuleMatcher
from coverage.files import prep_patterns, find_python_files, canonical_filename
from coverage.misc import sys_modules_saved
from coverage.python import source_for_file, source_for_morf


# Pypy has some unusual stuff in the "stdlib".  Consider those locations
# when deciding where the stdlib is.  These modules are not used for anything,
# they are modules importable from the pypy lib directories, so that we can
# find those directories.
_structseq = _pypy_irc_topic = None
if env.PYPY:
    try:
        import _structseq
    except ImportError:
        pass

    try:
        import _pypy_irc_topic
    except ImportError:
        pass


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.289">def canonical_path(morf, directory=False):
    """Return the canonical path of the module or file `morf`.

    If the module is a package, then return its directory. If it is a
    module, then return its file, unless `directory` is True, in which
    case return its enclosing directory.

    """
    morf_path = canonical_filename(source_for_morf(morf))
    if morf_path.endswith("__init__.py") or directory:
        morf_path = os.path.split(morf_path)[0]
    return morf_path


</t>
<t tx="ekr.20221020070914.29">def command_line(self, argv):
    """The bulk of the command line interface to coverage.py.

    `argv` is the argument list to process.

    Returns 0 if all is well, 1 if something went wrong.

    """
    # Collect the command-line options.
    if not argv:
        show_help(topic='minimum_help')
        return OK

    # The command syntax we parse depends on the first argument.  Global
    # switch syntax always starts with an option.
    self.global_option = argv[0].startswith('-')
    if self.global_option:
        parser = GlobalOptionParser()
    else:
        parser = COMMANDS.get(argv[0])
        if not parser:
            show_help(f"Unknown command: {argv[0]!r}")
            return ERR
        argv = argv[1:]

    ok, options, args = parser.parse_args_ok(argv)
    if not ok:
        return ERR

    # Handle help and version.
    if self.do_help(options, args, parser):
        return OK

    # Listify the list options.
    source = unshell_list(options.source)
    omit = unshell_list(options.omit)
    include = unshell_list(options.include)
    debug = unshell_list(options.debug)
    contexts = unshell_list(options.contexts)

    if options.concurrency is not None:
        concurrency = options.concurrency.split(",")
    else:
        concurrency = None

    # Do something.
    self.coverage = Coverage(
        data_file=options.data_file or DEFAULT_DATAFILE,
        data_suffix=options.parallel_mode,
        cover_pylib=options.pylib,
        timid=options.timid,
        branch=options.branch,
        config_file=options.rcfile,
        source=source,
        omit=omit,
        include=include,
        debug=debug,
        concurrency=concurrency,
        check_preimported=True,
        context=options.context,
        messages=not options.quiet,
    )

    if options.action == "debug":
        return self.do_debug(args)

    elif options.action == "erase":
        self.coverage.erase()
        return OK

    elif options.action == "run":
        return self.do_run(options, args)

    elif options.action == "combine":
        if options.append:
            self.coverage.load()
        data_paths = args or None
        self.coverage.combine(data_paths, strict=True, keep=bool(options.keep))
        self.coverage.save()
        return OK

    # Remaining actions are reporting, with some common options.
    report_args = dict(
        morfs=unglob_args(args),
        ignore_errors=options.ignore_errors,
        omit=omit,
        include=include,
        contexts=contexts,
    )

    # We need to be able to import from the current directory, because
    # plugins may try to, for example, to read Django settings.
    sys.path.insert(0, '')

    self.coverage.load()

    total = None
    if options.action == "report":
        total = self.coverage.report(
            precision=options.precision,
            show_missing=options.show_missing,
            skip_covered=options.skip_covered,
            skip_empty=options.skip_empty,
            sort=options.sort,
            **report_args
        )
    elif options.action == "annotate":
        self.coverage.annotate(directory=options.directory, **report_args)
    elif options.action == "html":
        total = self.coverage.html_report(
            directory=options.directory,
            precision=options.precision,
            skip_covered=options.skip_covered,
            skip_empty=options.skip_empty,
            show_contexts=options.show_contexts,
            title=options.title,
            **report_args
        )
    elif options.action == "xml":
        total = self.coverage.xml_report(
            outfile=options.outfile,
            skip_empty=options.skip_empty,
            **report_args
        )
    elif options.action == "json":
        total = self.coverage.json_report(
            outfile=options.outfile,
            pretty_print=options.pretty_print,
            show_contexts=options.show_contexts,
            **report_args
        )
    elif options.action == "lcov":
        total = self.coverage.lcov_report(
            outfile=options.outfile,
            **report_args
        )
    else:
        # There are no other possible actions.
        raise AssertionError

    if total is not None:
        # Apply the command line fail-under options, and then use the config
        # value, so we can get fail_under from the config file.
        if options.fail_under is not None:
            self.coverage.set_option("report:fail_under", options.fail_under)
        if options.precision is not None:
            self.coverage.set_option("report:precision", options.precision)

        fail_under = self.coverage.get_option("report:fail_under")
        precision = self.coverage.get_option("report:precision")
        if should_fail_under(total, fail_under, precision):
            msg = "total of {total} is less than fail-under={fail_under:.{p}f}".format(
                total=Numbers(precision=precision).display_covered(total),
                fail_under=fail_under,
                p=precision,
            )
            print("Coverage failure:", msg)
            return FAIL_UNDER

    return OK

</t>
<t tx="ekr.20221020070914.290">def name_for_module(filename, frame):
    """Get the name of the module for a filename and frame.

    For configurability's sake, we allow __main__ modules to be matched by
    their importable name.

    If loaded via runpy (aka -m), we can usually recover the "original"
    full dotted module name, otherwise, we resort to interpreting the
    file name to get the module's name.  In the case that the module name
    can't be determined, None is returned.

    """
    module_globals = frame.f_globals if frame is not None else {}
    if module_globals is None:          # pragma: only ironpython
        # IronPython doesn't provide globals: https://github.com/IronLanguages/main/issues/1296
        module_globals = {}

    dunder_name = module_globals.get('__name__', None)

    if isinstance(dunder_name, str) and dunder_name != '__main__':
        # This is the usual case: an imported module.
        return dunder_name

    loader = module_globals.get('__loader__', None)
    for attrname in ('fullname', 'name'):   # attribute renamed in py3.2
        if hasattr(loader, attrname):
            fullname = getattr(loader, attrname)
        else:
            continue

        if isinstance(fullname, str) and fullname != '__main__':
            # Module loaded via: runpy -m
            return fullname

    # Script as first argument to Python command line.
    inspectedname = inspect.getmodulename(filename)
    if inspectedname is not None:
        return inspectedname
    else:
        return dunder_name


</t>
<t tx="ekr.20221020070914.291">def module_is_namespace(mod):
    """Is the module object `mod` a PEP420 namespace module?"""
    return hasattr(mod, '__path__') and getattr(mod, '__file__', None) is None


</t>
<t tx="ekr.20221020070914.292">def module_has_file(mod):
    """Does the module object `mod` have an existing __file__ ?"""
    mod__file__ = getattr(mod, '__file__', None)
    if mod__file__ is None:
        return False
    return os.path.exists(mod__file__)


</t>
<t tx="ekr.20221020070914.293">def file_and_path_for_module(modulename):
    """Find the file and search path for `modulename`.

    Returns:
        filename: The filename of the module, or None.
        path: A list (possibly empty) of directories to find submodules in.

    """
    filename = None
    path = []
    try:
        spec = importlib.util.find_spec(modulename)
    except Exception:
        pass
    else:
        if spec is not None:
            filename = spec.origin
            path = list(spec.submodule_search_locations or ())
    return filename, path


</t>
<t tx="ekr.20221020070914.294">def add_stdlib_paths(paths):
    """Add paths where the stdlib can be found to the set `paths`."""
    # Look at where some standard modules are located. That's the
    # indication for "installed with the interpreter". In some
    # environments (virtualenv, for example), these modules may be
    # spread across a few locations. Look at all the candidate modules
    # we've imported, and take all the different ones.
    modules_we_happen_to_have = [
        inspect, itertools, os, platform, re, sysconfig, traceback,
        _pypy_irc_topic, _structseq,
    ]
    for m in modules_we_happen_to_have:
        if m is not None and hasattr(m, "__file__"):
            paths.add(canonical_path(m, directory=True))

    if _structseq and not hasattr(_structseq, '__file__'):
        # PyPy 2.4 has no __file__ in the builtin modules, but the code
        # objects still have the file names.  So dig into one to find
        # the path to exclude.  The "filename" might be synthetic,
        # don't be fooled by those.
        structseq_file = _structseq.structseq_new.__code__.co_filename
        if not structseq_file.startswith("&lt;"):
            paths.add(canonical_path(structseq_file))


</t>
<t tx="ekr.20221020070914.295">def add_third_party_paths(paths):
    """Add locations for third-party packages to the set `paths`."""
    # Get the paths that sysconfig knows about.
    scheme_names = set(sysconfig.get_scheme_names())

    for scheme in scheme_names:
        # https://foss.heptapod.net/pypy/pypy/-/issues/3433
        better_scheme = "pypy_posix" if scheme == "pypy" else scheme
        if os.name in better_scheme.split("_"):
            config_paths = sysconfig.get_paths(scheme)
            for path_name in ["platlib", "purelib", "scripts"]:
                paths.add(config_paths[path_name])


</t>
<t tx="ekr.20221020070914.296">def add_coverage_paths(paths):
    """Add paths where coverage.py code can be found to the set `paths`."""
    cover_path = canonical_path(__file__, directory=True)
    paths.add(cover_path)
    if env.TESTING:
        # Don't include our own test code.
        paths.add(os.path.join(cover_path, "tests"))

        # When testing, we use PyContracts, which should be considered
        # part of coverage.py, and it uses six. Exclude those directories
        # just as we exclude ourselves.
        if env.USE_CONTRACTS:
            import contracts
            import six
            for mod in [contracts, six]:
                paths.add(canonical_path(mod))


</t>
<t tx="ekr.20221020070914.297">class InOrOut:
    """Machinery for determining what files to measure."""

    @others
</t>
<t tx="ekr.20221020070914.298">def __init__(self, warn, debug):
    self.warn = warn
    self.debug = debug

    # The matchers for should_trace.
    self.source_match = None
    self.source_pkgs_match = None
    self.pylib_paths = self.cover_paths = self.third_paths = None
    self.pylib_match = self.cover_match = self.third_match = None
    self.include_match = self.omit_match = None
    self.plugins = []
    self.disp_class = FileDisposition

    # The source argument can be directories or package names.
    self.source = []
    self.source_pkgs = []
    self.source_pkgs_unmatched = []
    self.omit = self.include = None

    # Is the source inside a third-party area?
    self.source_in_third = False

</t>
<t tx="ekr.20221020070914.299">def configure(self, config):
    """Apply the configuration to get ready for decision-time."""
    self.source_pkgs.extend(config.source_pkgs)
    for src in config.source or []:
        if os.path.isdir(src):
            self.source.append(canonical_filename(src))
        else:
            self.source_pkgs.append(src)
    self.source_pkgs_unmatched = self.source_pkgs[:]

    self.omit = prep_patterns(config.run_omit)
    self.include = prep_patterns(config.run_include)

    # The directories for files considered "installed with the interpreter".
    self.pylib_paths = set()
    if not config.cover_pylib:
        add_stdlib_paths(self.pylib_paths)

    # To avoid tracing the coverage.py code itself, we skip anything
    # located where we are.
    self.cover_paths = set()
    add_coverage_paths(self.cover_paths)

    # Find where third-party packages are installed.
    self.third_paths = set()
    add_third_party_paths(self.third_paths)

    def debug(msg):
        if self.debug:
            self.debug.write(msg)

    # Generally useful information
    debug("sys.path:" + "".join(f"\n    {p}" for p in sys.path))

    # Create the matchers we need for should_trace
    if self.source or self.source_pkgs:
        against = []
        if self.source:
            self.source_match = TreeMatcher(self.source, "source")
            against.append(f"trees {self.source_match!r}")
        if self.source_pkgs:
            self.source_pkgs_match = ModuleMatcher(self.source_pkgs, "source_pkgs")
            against.append(f"modules {self.source_pkgs_match!r}")
        debug("Source matching against " + " and ".join(against))
    else:
        if self.pylib_paths:
            self.pylib_match = TreeMatcher(self.pylib_paths, "pylib")
            debug(f"Python stdlib matching: {self.pylib_match!r}")
    if self.include:
        self.include_match = FnmatchMatcher(self.include, "include")
        debug(f"Include matching: {self.include_match!r}")
    if self.omit:
        self.omit_match = FnmatchMatcher(self.omit, "omit")
        debug(f"Omit matching: {self.omit_match!r}")

    self.cover_match = TreeMatcher(self.cover_paths, "coverage")
    debug(f"Coverage code matching: {self.cover_match!r}")

    self.third_match = TreeMatcher(self.third_paths, "third")
    debug(f"Third-party lib matching: {self.third_match!r}")

    # Check if the source we want to measure has been installed as a
    # third-party package.
    with sys_modules_saved():
        for pkg in self.source_pkgs:
            try:
                modfile, path = file_and_path_for_module(pkg)
                debug(f"Imported source package {pkg!r} as {modfile!r}")
            except CoverageException as exc:
                debug(f"Couldn't import source package {pkg!r}: {exc}")
                continue
            if modfile:
                if self.third_match.match(modfile):
                    debug(
                        f"Source is in third-party because of source_pkg {pkg!r} at {modfile!r}"
                    )
                    self.source_in_third = True
            else:
                for pathdir in path:
                    if self.third_match.match(pathdir):
                        debug(
                            f"Source is in third-party because of {pkg!r} path directory " +
                            f"at {pathdir!r}"
                        )
                        self.source_in_third = True

    for src in self.source:
        if self.third_match.match(src):
            debug(f"Source is in third-party because of source directory {src!r}")
            self.source_in_third = True

</t>
<t tx="ekr.20221020070914.3">class AnnotateReporter:
    """Generate annotated source files showing line coverage.

    This reporter creates annotated copies of the measured source files. Each
    .py file is copied as a .py,cover file, with a left-hand margin annotating
    each line::

        &gt; def h(x):
        -     if 0:   #pragma: no cover
        -         pass
        &gt;     if x == 1:
        !         a = 1
        &gt;     else:
        &gt;         a = 2

        &gt; h(2)

    Executed lines use '&gt;', lines not executed use '!', lines excluded from
    consideration use '-'.

    """

    @others
</t>
<t tx="ekr.20221020070914.30">def do_help(self, options, args, parser):
    """Deal with help requests.

    Return True if it handled the request, False if not.

    """
    # Handle help.
    if options.help:
        if self.global_option:
            show_help(topic='help')
        else:
            show_help(parser=parser)
        return True

    if options.action == "help":
        if args:
            for a in args:
                parser = COMMANDS.get(a)
                if parser:
                    show_help(parser=parser)
                else:
                    show_help(topic=a)
        else:
            show_help(topic='help')
        return True

    # Handle version.
    if options.version:
        show_help(topic='version')
        return True

    return False

</t>
<t tx="ekr.20221020070914.300">def should_trace(self, filename, frame=None):
    """Decide whether to trace execution in `filename`, with a reason.

    This function is called from the trace function.  As each new file name
    is encountered, this function determines whether it is traced or not.

    Returns a FileDisposition object.

    """
    original_filename = filename
    disp = disposition_init(self.disp_class, filename)

    def nope(disp, reason):
        """Simple helper to make it easy to return NO."""
        disp.trace = False
        disp.reason = reason
        return disp

    if original_filename.startswith('&lt;'):
        return nope(disp, "not a real original file name")

    if frame is not None:
        # Compiled Python files have two file names: frame.f_code.co_filename is
        # the file name at the time the .pyc was compiled.  The second name is
        # __file__, which is where the .pyc was actually loaded from.  Since
        # .pyc files can be moved after compilation (for example, by being
        # installed), we look for __file__ in the frame and prefer it to the
        # co_filename value.
        dunder_file = frame.f_globals and frame.f_globals.get('__file__')
        if dunder_file:
            filename = source_for_file(dunder_file)
            if original_filename and not original_filename.startswith('&lt;'):
                orig = os.path.basename(original_filename)
                if orig != os.path.basename(filename):
                    # Files shouldn't be renamed when moved. This happens when
                    # exec'ing code.  If it seems like something is wrong with
                    # the frame's file name, then just use the original.
                    filename = original_filename

    if not filename:
        # Empty string is pretty useless.
        return nope(disp, "empty string isn't a file name")

    if filename.startswith('memory:'):
        return nope(disp, "memory isn't traceable")

    if filename.startswith('&lt;'):
        # Lots of non-file execution is represented with artificial
        # file names like "&lt;string&gt;", "&lt;doctest readme.txt[0]&gt;", or
        # "&lt;exec_function&gt;".  Don't ever trace these executions, since we
        # can't do anything with the data later anyway.
        return nope(disp, "not a real file name")

    # Jython reports the .class file to the tracer, use the source file.
    if filename.endswith("$py.class"):
        filename = filename[:-9] + ".py"

    canonical = canonical_filename(filename)
    disp.canonical_filename = canonical

    # Try the plugins, see if they have an opinion about the file.
    plugin = None
    for plugin in self.plugins.file_tracers:
        if not plugin._coverage_enabled:
            continue

        try:
            file_tracer = plugin.file_tracer(canonical)
            if file_tracer is not None:
                file_tracer._coverage_plugin = plugin
                disp.trace = True
                disp.file_tracer = file_tracer
                if file_tracer.has_dynamic_source_filename():
                    disp.has_dynamic_filename = True
                else:
                    disp.source_filename = canonical_filename(
                        file_tracer.source_filename()
                    )
                break
        except Exception:
            plugin_name = plugin._coverage_plugin_name
            tb = traceback.format_exc()
            self.warn(f"Disabling plug-in {plugin_name!r} due to an exception:\n{tb}")
            plugin._coverage_enabled = False
            continue
    else:
        # No plugin wanted it: it's Python.
        disp.trace = True
        disp.source_filename = canonical

    if not disp.has_dynamic_filename:
        if not disp.source_filename:
            raise PluginError(
                f"Plugin {plugin!r} didn't set source_filename for '{disp.original_filename}'"
            )
        reason = self.check_include_omit_etc(disp.source_filename, frame)
        if reason:
            nope(disp, reason)

    return disp

</t>
<t tx="ekr.20221020070914.301">def check_include_omit_etc(self, filename, frame):
    """Check a file name against the include, omit, etc, rules.

    Returns a string or None.  String means, don't trace, and is the reason
    why.  None means no reason found to not trace.

    """
    modulename = name_for_module(filename, frame)

    # If the user specified source or include, then that's authoritative
    # about the outer bound of what to measure and we don't have to apply
    # any canned exclusions. If they didn't, then we have to exclude the
    # stdlib and coverage.py directories.
    if self.source_match or self.source_pkgs_match:
        extra = ""
        ok = False
        if self.source_pkgs_match:
            if self.source_pkgs_match.match(modulename):
                ok = True
                if modulename in self.source_pkgs_unmatched:
                    self.source_pkgs_unmatched.remove(modulename)
            else:
                extra = f"module {modulename!r} "
        if not ok and self.source_match:
            if self.source_match.match(filename):
                ok = True
        if not ok:
            return extra + "falls outside the --source spec"
        if not self.source_in_third:
            if self.third_match.match(filename):
                return "inside --source, but is third-party"
    elif self.include_match:
        if not self.include_match.match(filename):
            return "falls outside the --include trees"
    else:
        # We exclude the coverage.py code itself, since a little of it
        # will be measured otherwise.
        if self.cover_match.match(filename):
            return "is part of coverage.py"

        # If we aren't supposed to trace installed code, then check if this
        # is near the Python standard library and skip it if so.
        if self.pylib_match and self.pylib_match.match(filename):
            return "is in the stdlib"

        # Exclude anything in the third-party installation areas.
        if self.third_match.match(filename):
            return "is a third-party module"

    # Check the file against the omit pattern.
    if self.omit_match and self.omit_match.match(filename):
        return "is inside an --omit pattern"

    # No point tracing a file we can't later write to SQLite.
    try:
        filename.encode("utf-8")
    except UnicodeEncodeError:
        return "non-encodable filename"

    # No reason found to skip this file.
    return None

</t>
<t tx="ekr.20221020070914.302">def warn_conflicting_settings(self):
    """Warn if there are settings that conflict."""
    if self.include:
        if self.source or self.source_pkgs:
            self.warn("--include is ignored because --source is set", slug="include-ignored")

</t>
<t tx="ekr.20221020070914.303">def warn_already_imported_files(self):
    """Warn if files have already been imported that we will be measuring."""
    if self.include or self.source or self.source_pkgs:
        warned = set()
        for mod in list(sys.modules.values()):
            filename = getattr(mod, "__file__", None)
            if filename is None:
                continue
            if filename in warned:
                continue

            if len(getattr(mod, "__path__", ())) &gt; 1:
                # A namespace package, which confuses this code, so ignore it.
                continue

            disp = self.should_trace(filename)
            if disp.has_dynamic_filename:
                # A plugin with dynamic filenames: the Python file
                # shouldn't cause a warning, since it won't be the subject
                # of tracing anyway.
                continue
            if disp.trace:
                msg = f"Already imported a file that will be measured: {filename}"
                self.warn(msg, slug="already-imported")
                warned.add(filename)
            elif self.debug and self.debug.should('trace'):
                self.debug.write(
                    "Didn't trace already imported file {!r}: {}".format(
                        disp.original_filename, disp.reason
                    )
                )

</t>
<t tx="ekr.20221020070914.304">def warn_unimported_source(self):
    """Warn about source packages that were of interest, but never traced."""
    for pkg in self.source_pkgs_unmatched:
        self._warn_about_unmeasured_code(pkg)

</t>
<t tx="ekr.20221020070914.305">def _warn_about_unmeasured_code(self, pkg):
    """Warn about a package or module that we never traced.

    `pkg` is a string, the name of the package or module.

    """
    mod = sys.modules.get(pkg)
    if mod is None:
        self.warn(f"Module {pkg} was never imported.", slug="module-not-imported")
        return

    if module_is_namespace(mod):
        # A namespace package. It's OK for this not to have been traced,
        # since there is no code directly in it.
        return

    if not module_has_file(mod):
        self.warn(f"Module {pkg} has no Python source.", slug="module-not-python")
        return

    # The module was in sys.modules, and seems like a module with code, but
    # we never measured it. I guess that means it was imported before
    # coverage even started.
    msg = f"Module {pkg} was previously imported, but not measured"
    self.warn(msg, slug="module-not-measured")

</t>
<t tx="ekr.20221020070914.306">def find_possibly_unexecuted_files(self):
    """Find files in the areas of interest that might be untraced.

    Yields pairs: file path, and responsible plug-in name.
    """
    for pkg in self.source_pkgs:
        if (not pkg in sys.modules or
            not module_has_file(sys.modules[pkg])):
            continue
        pkg_file = source_for_file(sys.modules[pkg].__file__)
        yield from self._find_executable_files(canonical_path(pkg_file))

    for src in self.source:
        yield from self._find_executable_files(src)

</t>
<t tx="ekr.20221020070914.307">def _find_plugin_files(self, src_dir):
    """Get executable files from the plugins."""
    for plugin in self.plugins.file_tracers:
        for x_file in plugin.find_executable_files(src_dir):
            yield x_file, plugin._coverage_plugin_name

</t>
<t tx="ekr.20221020070914.308">def _find_executable_files(self, src_dir):
    """Find executable files in `src_dir`.

    Search for files in `src_dir` that can be executed because they
    are probably importable. Don't include ones that have been omitted
    by the configuration.

    Yield the file path, and the plugin name that handles the file.

    """
    py_files = ((py_file, None) for py_file in find_python_files(src_dir))
    plugin_files = self._find_plugin_files(src_dir)

    for file_path, plugin_name in itertools.chain(py_files, plugin_files):
        file_path = canonical_filename(file_path)
        if self.omit_match and self.omit_match.match(file_path):
            # Turns out this file was omitted, so don't pull it back
            # in as unexecuted.
            continue
        yield file_path, plugin_name

</t>
<t tx="ekr.20221020070914.309">def sys_info(self):
    """Our information for Coverage.sys_info.

    Returns a list of (key, value) pairs.
    """
    info = [
        ("coverage_paths", self.cover_paths),
        ("stdlib_paths", self.pylib_paths),
        ("third_party_paths", self.third_paths),
    ]

    matcher_names = [
        'source_match', 'source_pkgs_match',
        'include_match', 'omit_match',
        'cover_match', 'pylib_match', 'third_match',
    ]

    for matcher_name in matcher_names:
        matcher = getattr(self, matcher_name)
        if matcher:
            matcher_info = matcher.info()
        else:
            matcher_info = '-none-'
        info.append((matcher_name, matcher_info))

    return info
</t>
<t tx="ekr.20221020070914.31">def do_run(self, options, args):
    """Implementation of 'coverage run'."""

    if not args:
        if options.module:
            # Specified -m with nothing else.
            show_help("No module specified for -m")
            return ERR
        command_line = self.coverage.get_option("run:command_line")
        if command_line is not None:
            args = shlex.split(command_line)
            if args and args[0] in {"-m", "--module"}:
                options.module = True
                args = args[1:]
    if not args:
        show_help("Nothing to do.")
        return ERR

    if options.append and self.coverage.get_option("run:parallel"):
        show_help("Can't append to data files in parallel mode.")
        return ERR

    if options.concurrency == "multiprocessing":
        # Can't set other run-affecting command line options with
        # multiprocessing.
        for opt_name in ['branch', 'include', 'omit', 'pylib', 'source', 'timid']:
            # As it happens, all of these options have no default, meaning
            # they will be None if they have not been specified.
            if getattr(options, opt_name) is not None:
                show_help(
                    "Options affecting multiprocessing must only be specified " +
                    "in a configuration file.\n" +
                    f"Remove --{opt_name} from the command line."
                )
                return ERR

    os.environ["COVERAGE_RUN"] = "true"

    runner = PyRunner(args, as_module=bool(options.module))
    runner.prepare()

    if options.append:
        self.coverage.load()

    # Run the script.
    self.coverage.start()
    code_ran = True
    try:
        runner.run()
    except NoSource:
        code_ran = False
        raise
    finally:
        self.coverage.stop()
        if code_ran:
            self.coverage.save()

    return OK

</t>
<t tx="ekr.20221020070914.310">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Json reporting for coverage.py"""

import datetime
import json
import sys

from coverage import __version__
from coverage.report import get_analysis_to_report
from coverage.results import Numbers


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.311">class JsonReporter:
    """A reporter for writing JSON coverage results."""

    report_type = "JSON report"

    @others
</t>
<t tx="ekr.20221020070914.312">def __init__(self, coverage):
    self.coverage = coverage
    self.config = self.coverage.config
    self.total = Numbers(self.config.precision)
    self.report_data = {}

</t>
<t tx="ekr.20221020070914.313">def report(self, morfs, outfile=None):
    """Generate a json report for `morfs`.

    `morfs` is a list of modules or file names.

    `outfile` is a file object to write the json to.

    """
    outfile = outfile or sys.stdout
    coverage_data = self.coverage.get_data()
    coverage_data.set_query_contexts(self.config.report_contexts)
    self.report_data["meta"] = {
        "version": __version__,
        "timestamp": datetime.datetime.now().isoformat(),
        "branch_coverage": coverage_data.has_arcs(),
        "show_contexts": self.config.json_show_contexts,
    }

    measured_files = {}
    for file_reporter, analysis in get_analysis_to_report(self.coverage, morfs):
        measured_files[file_reporter.relative_filename()] = self.report_one_file(
            coverage_data,
            analysis
        )

    self.report_data["files"] = measured_files

    self.report_data["totals"] = {
        'covered_lines': self.total.n_executed,
        'num_statements': self.total.n_statements,
        'percent_covered': self.total.pc_covered,
        'percent_covered_display': self.total.pc_covered_str,
        'missing_lines': self.total.n_missing,
        'excluded_lines': self.total.n_excluded,
    }

    if coverage_data.has_arcs():
        self.report_data["totals"].update({
            'num_branches': self.total.n_branches,
            'num_partial_branches': self.total.n_partial_branches,
            'covered_branches': self.total.n_executed_branches,
            'missing_branches': self.total.n_missing_branches,
        })

    json.dump(
        self.report_data,
        outfile,
        indent=(4 if self.config.json_pretty_print else None),
    )

    return self.total.n_statements and self.total.pc_covered

</t>
<t tx="ekr.20221020070914.314">def report_one_file(self, coverage_data, analysis):
    """Extract the relevant report data for a single file."""
    nums = analysis.numbers
    self.total += nums
    summary = {
        'covered_lines': nums.n_executed,
        'num_statements': nums.n_statements,
        'percent_covered': nums.pc_covered,
        'percent_covered_display': nums.pc_covered_str,
        'missing_lines': nums.n_missing,
        'excluded_lines': nums.n_excluded,
    }
    reported_file = {
        'executed_lines': sorted(analysis.executed),
        'summary': summary,
        'missing_lines': sorted(analysis.missing),
        'excluded_lines': sorted(analysis.excluded),
    }
    if self.config.json_show_contexts:
        reported_file['contexts'] = analysis.data.contexts_by_lineno(analysis.filename)
    if coverage_data.has_arcs():
        reported_file['summary'].update({
            'num_branches': nums.n_branches,
            'num_partial_branches': nums.n_partial_branches,
            'covered_branches': nums.n_executed_branches,
            'missing_branches': nums.n_missing_branches,
        })
        reported_file['executed_branches'] = list(
            _convert_branch_arcs(analysis.executed_branch_arcs())
        )
        reported_file['missing_branches'] = list(
            _convert_branch_arcs(analysis.missing_branch_arcs())
        )
    return reported_file


</t>
<t tx="ekr.20221020070914.315">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""LCOV reporting for coverage.py."""

import sys
import base64
from hashlib import md5

from coverage.report import get_analysis_to_report


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.316">class LcovReporter:
    """A reporter for writing LCOV coverage reports."""

    report_type = "LCOV report"

    @others
</t>
<t tx="ekr.20221020070914.317">def __init__(self, coverage):
    self.coverage = coverage
    self.config = self.coverage.config

</t>
<t tx="ekr.20221020070914.318">def report(self, morfs, outfile=None):
    """Renders the full lcov report.

    'morfs' is a list of modules or filenames

    outfile is the file object to write the file into.
    """

    self.coverage.get_data()
    outfile = outfile or sys.stdout

    for fr, analysis in get_analysis_to_report(self.coverage, morfs):
        self.get_lcov(fr, analysis, outfile)

</t>
<t tx="ekr.20221020070914.319">def get_lcov(self, fr, analysis, outfile=None):
    """Produces the lcov data for a single file.

    This currently supports both line and branch coverage,
    however function coverage is not supported.
    """
    outfile.write("TN:\n")
    outfile.write(f"SF:{fr.relative_filename()}\n")
    source_lines = fr.source().splitlines()

    for covered in sorted(analysis.executed):
        # Note: Coverage.py currently only supports checking *if* a line
        # has been executed, not how many times, so we set this to 1 for
        # nice output even if it's technically incorrect.

        # The lines below calculate a 64-bit encoded md5 hash of the line
        # corresponding to the DA lines in the lcov file, for either case
        # of the line being covered or missed in coverage.py. The final two
        # characters of the encoding ("==") are removed from the hash to
        # allow genhtml to run on the resulting lcov file.
        if source_lines:
            line = source_lines[covered-1].encode("utf-8")
        else:
            line = b""
        hashed = base64.b64encode(md5(line).digest()).decode().rstrip("=")
        outfile.write(f"DA:{covered},1,{hashed}\n")

    for missed in sorted(analysis.missing):
        assert source_lines
        line = source_lines[missed-1].encode("utf-8")
        hashed = base64.b64encode(md5(line).digest()).decode().rstrip("=")
        outfile.write(f"DA:{missed},0,{hashed}\n")

    outfile.write(f"LF:{len(analysis.statements)}\n")
    outfile.write(f"LH:{len(analysis.executed)}\n")

    # More information dense branch coverage data.
    missing_arcs = analysis.missing_branch_arcs()
    executed_arcs = analysis.executed_branch_arcs()
    for block_number, block_line_number in enumerate(
        sorted(analysis.branch_stats().keys())
    ):
        for branch_number, line_number in enumerate(
            sorted(missing_arcs[block_line_number])
        ):
            # The exit branches have a negative line number,
            # this will not produce valid lcov. Setting
            # the line number of the exit branch to 0 will allow
            # for valid lcov, while preserving the data.
            line_number = max(line_number, 0)
            outfile.write(f"BRDA:{line_number},{block_number},{branch_number},-\n")

        # The start value below allows for the block number to be
        # preserved between these two for loops (stopping the loop from
        # resetting the value of the block number to 0).
        for branch_number, line_number in enumerate(
            sorted(executed_arcs[block_line_number]),
            start=len(missing_arcs[block_line_number]),
        ):
            line_number = max(line_number, 0)
            outfile.write(f"BRDA:{line_number},{block_number},{branch_number},1\n")

    # Summary of the branch coverage.
    if analysis.has_arcs():
        branch_stats = analysis.branch_stats()
        brf = sum(t for t, k in branch_stats.values())
        brh = brf - sum(t - k for t, k in branch_stats.values())
        outfile.write(f"BRF:{brf}\n")
        outfile.write(f"BRH:{brh}\n")

    outfile.write("end_of_record\n")
</t>
<t tx="ekr.20221020070914.32">def do_debug(self, args):
    """Implementation of 'coverage debug'."""

    if not args:
        show_help("What information would you like: config, data, sys, premain, pybehave?")
        return ERR
    if args[1:]:
        show_help("Only one topic at a time, please")
        return ERR

    if args[0] == "sys":
        write_formatted_info(print, "sys", self.coverage.sys_info())
    elif args[0] == "data":
        print(info_header("data"))
        data_file = self.coverage.config.data_file
        debug_data_file(data_file)
        for filename in combinable_files(data_file):
            print("-----")
            debug_data_file(filename)
    elif args[0] == "config":
        write_formatted_info(print, "config", self.coverage.config.debug_info())
    elif args[0] == "premain":
        print(info_header("premain"))
        print(short_stack())
    elif args[0] == "pybehave":
        write_formatted_info(print, "pybehave", env.debug_info())
    else:
        show_help(f"Don't know what you mean by {args[0]!r}")
        return ERR

    return OK


</t>
<t tx="ekr.20221020070914.320">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Miscellaneous stuff for coverage.py."""

import contextlib
import errno
import hashlib
import importlib
import importlib.util
import inspect
import locale
import os
import os.path
import re
import sys
import types

from coverage import env
from coverage.exceptions import CoverageException

# In 6.0, the exceptions moved from misc.py to exceptions.py.  But a number of
# other packages were importing the exceptions from misc, so import them here.
# pylint: disable=unused-wildcard-import
from coverage.exceptions import *   # pylint: disable=wildcard-import

ISOLATED_MODULES = {}


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.321">def isolate_module(mod):
    """Copy a module so that we are isolated from aggressive mocking.

    If a test suite mocks os.path.exists (for example), and then we need to use
    it during the test, everything will get tangled up if we use their mock.
    Making a copy of the module when we import it will isolate coverage.py from
    those complications.
    """
    if mod not in ISOLATED_MODULES:
        new_mod = types.ModuleType(mod.__name__)
        ISOLATED_MODULES[mod] = new_mod
        for name in dir(mod):
            value = getattr(mod, name)
            if isinstance(value, types.ModuleType):
                value = isolate_module(value)
            setattr(new_mod, name, value)
    return ISOLATED_MODULES[mod]

</t>
<t tx="ekr.20221020070914.322">os = isolate_module(os)


</t>
<t tx="ekr.20221020070914.323">class SysModuleSaver:
    """Saves the contents of sys.modules, and removes new modules later."""
    @others
</t>
<t tx="ekr.20221020070914.324">def __init__(self):
    self.old_modules = set(sys.modules)

</t>
<t tx="ekr.20221020070914.325">def restore(self):
    """Remove any modules imported since this object started."""
    new_modules = set(sys.modules) - self.old_modules
    for m in new_modules:
        del sys.modules[m]


</t>
<t tx="ekr.20221020070914.326">@contextlib.contextmanager
def sys_modules_saved():
    """A context manager to remove any modules imported during a block."""
    saver = SysModuleSaver()
    try:
        yield
    finally:
        saver.restore()


</t>
<t tx="ekr.20221020070914.327">def import_third_party(modname):
    """Import a third-party module we need, but might not be installed.

    This also cleans out the module after the import, so that coverage won't
    appear to have imported it.  This lets the third party use coverage for
    their own tests.

    Arguments:
        modname (str): the name of the module to import.

    Returns:
        The imported module, or None if the module couldn't be imported.

    """
    with sys_modules_saved():
        try:
            return importlib.import_module(modname)
        except ImportError:
            return None


</t>
<t tx="ekr.20221020070914.328">def dummy_decorator_with_args(*args_unused, **kwargs_unused):
    """Dummy no-op implementation of a decorator with arguments."""
    def _decorator(func):
        return func
    return _decorator


</t>
<t tx="ekr.20221020070914.329"># Use PyContracts for assertion testing on parameters and returns, but only if
# we are running our own test suite.
if env.USE_CONTRACTS:
    from contracts import contract              # pylint: disable=unused-import
    from contracts import new_contract as raw_new_contract

    def new_contract(*args, **kwargs):
        """A proxy for contracts.new_contract that doesn't mind happening twice."""
        try:
            raw_new_contract(*args, **kwargs)
        except ValueError:
            # During meta-coverage, this module is imported twice, and
            # PyContracts doesn't like redefining contracts. It's OK.
            pass

    # Define contract words that PyContract doesn't have.
    new_contract('bytes', lambda v: isinstance(v, bytes))
    new_contract('unicode', lambda v: isinstance(v, str))

    def one_of(argnames):
        """Ensure that only one of the argnames is non-None."""
        def _decorator(func):
            argnameset = {name.strip() for name in argnames.split(",")}
            def _wrapper(*args, **kwargs):
                vals = [kwargs.get(name) for name in argnameset]
                assert sum(val is not None for val in vals) == 1
                return func(*args, **kwargs)
            return _wrapper
        return _decorator
else:                                           # pragma: not testing
    # We aren't using real PyContracts, so just define our decorators as
    # stunt-double no-ops.
    contract = dummy_decorator_with_args
    one_of = dummy_decorator_with_args

    def new_contract(*args_unused, **kwargs_unused):
        """Dummy no-op implementation of `new_contract`."""
        pass


</t>
<t tx="ekr.20221020070914.33">def unshell_list(s):
    """Turn a command-line argument into a list."""
    if not s:
        return None
    if env.WINDOWS:
        # When running coverage.py as coverage.exe, some of the behavior
        # of the shell is emulated: wildcards are expanded into a list of
        # file names.  So you have to single-quote patterns on the command
        # line, but (not) helpfully, the single quotes are included in the
        # argument, so we have to strip them off here.
        s = s.strip("'")
    return s.split(',')


</t>
<t tx="ekr.20221020070914.330">def nice_pair(pair):
    """Make a nice string representation of a pair of numbers.

    If the numbers are equal, just return the number, otherwise return the pair
    with a dash between them, indicating the range.

    """
    start, end = pair
    if start == end:
        return "%d" % start
    else:
        return "%d-%d" % (start, end)


</t>
<t tx="ekr.20221020070914.331">def expensive(fn):
    """A decorator to indicate that a method shouldn't be called more than once.

    Normally, this does nothing.  During testing, this raises an exception if
    called more than once.

    """
    if env.TESTING:
        attr = "_once_" + fn.__name__

        def _wrapper(self):
            if hasattr(self, attr):
                raise AssertionError(f"Shouldn't have called {fn.__name__} more than once")
            setattr(self, attr, True)
            return fn(self)
        return _wrapper
    else:
        return fn                   # pragma: not testing


</t>
<t tx="ekr.20221020070914.332">def bool_or_none(b):
    """Return bool(b), but preserve None."""
    if b is None:
        return None
    else:
        return bool(b)


</t>
<t tx="ekr.20221020070914.333">def join_regex(regexes):
    """Combine a list of regexes into one that matches any of them."""
    return "|".join(f"(?:{r})" for r in regexes)


</t>
<t tx="ekr.20221020070914.334">def file_be_gone(path):
    """Remove a file, and don't get annoyed if it doesn't exist."""
    try:
        os.remove(path)
    except OSError as e:
        if e.errno != errno.ENOENT:
            raise


</t>
<t tx="ekr.20221020070914.335">def ensure_dir(directory):
    """Make sure the directory exists.

    If `directory` is None or empty, do nothing.
    """
    if directory:
        os.makedirs(directory, exist_ok=True)


</t>
<t tx="ekr.20221020070914.336">def ensure_dir_for_file(path):
    """Make sure the directory for the path exists."""
    ensure_dir(os.path.dirname(path))


</t>
<t tx="ekr.20221020070914.337">def output_encoding(outfile=None):
    """Determine the encoding to use for output written to `outfile` or stdout."""
    if outfile is None:
        outfile = sys.stdout
    encoding = (
        getattr(outfile, "encoding", None) or
        getattr(sys.__stdout__, "encoding", None) or
        locale.getpreferredencoding()
    )
    return encoding


</t>
<t tx="ekr.20221020070914.338">class Hasher:
    """Hashes Python data for fingerprinting."""
    @others
</t>
<t tx="ekr.20221020070914.339">def __init__(self):
    self.hash = hashlib.new("sha3_256")

</t>
<t tx="ekr.20221020070914.34">def unglob_args(args):
    """Interpret shell wildcards for platforms that need it."""
    if env.WINDOWS:
        globbed = []
        for arg in args:
            if '?' in arg or '*' in arg:
                globbed.extend(glob.glob(arg))
            else:
                globbed.append(arg)
        args = globbed
    return args


</t>
<t tx="ekr.20221020070914.340">def update(self, v):
    """Add `v` to the hash, recursively if needed."""
    self.hash.update(str(type(v)).encode("utf-8"))
    if isinstance(v, str):
        self.hash.update(v.encode("utf-8"))
    elif isinstance(v, bytes):
        self.hash.update(v)
    elif v is None:
        pass
    elif isinstance(v, (int, float)):
        self.hash.update(str(v).encode("utf-8"))
    elif isinstance(v, (tuple, list)):
        for e in v:
            self.update(e)
    elif isinstance(v, dict):
        keys = v.keys()
        for k in sorted(keys):
            self.update(k)
            self.update(v[k])
    else:
        for k in dir(v):
            if k.startswith('__'):
                continue
            a = getattr(v, k)
            if inspect.isroutine(a):
                continue
            self.update(k)
            self.update(a)
    self.hash.update(b'.')

</t>
<t tx="ekr.20221020070914.341">def hexdigest(self):
    """Retrieve the hex digest of the hash."""
    return self.hash.hexdigest()[:32]


</t>
<t tx="ekr.20221020070914.342">def _needs_to_implement(that, func_name):
    """Helper to raise NotImplementedError in interface stubs."""
    if hasattr(that, "_coverage_plugin_name"):
        thing = "Plugin"
        name = that._coverage_plugin_name
    else:
        thing = "Class"
        klass = that.__class__
        name = f"{klass.__module__}.{klass.__name__}"

    raise NotImplementedError(
        f"{thing} {name!r} needs to implement {func_name}()"
    )


</t>
<t tx="ekr.20221020070914.343">class DefaultValue:
    """A sentinel object to use for unusual default-value needs.

    Construct with a string that will be used as the repr, for display in help
    and Sphinx output.

    """
    @others
</t>
<t tx="ekr.20221020070914.344">def __init__(self, display_as):
    self.display_as = display_as

</t>
<t tx="ekr.20221020070914.345">def __repr__(self):
    return self.display_as


</t>
<t tx="ekr.20221020070914.346">def substitute_variables(text, variables):
    """Substitute ``${VAR}`` variables in `text` with their values.

    Variables in the text can take a number of shell-inspired forms::

        $VAR
        ${VAR}
        ${VAR?}             strict: an error if VAR isn't defined.
        ${VAR-missing}      defaulted: "missing" if VAR isn't defined.
        $$                  just a dollar sign.

    `variables` is a dictionary of variable values.

    Returns the resulting text with values substituted.

    """
    dollar_pattern = r"""(?x)   # Use extended regex syntax
        \$                      # A dollar sign,
        (?:                     # then
            (?P&lt;dollar&gt;\$) |        # a dollar sign, or
            (?P&lt;word1&gt;\w+) |        # a plain word, or
            {                       # a {-wrapped
                (?P&lt;word2&gt;\w+)          # word,
                (?:
                    (?P&lt;strict&gt;\?) |        # with a strict marker
                    -(?P&lt;defval&gt;[^}]*)      # or a default value
                )?                      # maybe.
            }
        )
        """

    dollar_groups = ('dollar', 'word1', 'word2')

    @others
    text = re.sub(dollar_pattern, dollar_replace, text)
    return text


</t>
<t tx="ekr.20221020070914.347">def dollar_replace(match):
    """Called for each $replacement."""
    # Only one of the dollar_groups will have matched, just get its text.
    word = next(g for g in match.group(*dollar_groups) if g)    # pragma: always breaks
    if word == "$":
        return "$"
    elif word in variables:
        return variables[word]
    elif match['strict']:
        msg = f"Variable {word} is undefined: {text!r}"
        raise CoverageException(msg)
    else:
        return match['defval']

</t>
<t tx="ekr.20221020070914.348">def format_local_datetime(dt):
    """Return a string with local timezone representing the date.
    """
    return dt.astimezone().strftime('%Y-%m-%d %H:%M %z')


</t>
<t tx="ekr.20221020070914.349">def import_local_file(modname, modfile=None):
    """Import a local file as a module.

    Opens a file in the current directory named `modname`.py, imports it
    as `modname`, and returns the module object.  `modfile` is the file to
    import if it isn't in the current directory.

    """
    if modfile is None:
        modfile = modname + '.py'
    spec = importlib.util.spec_from_file_location(modname, modfile)
    mod = importlib.util.module_from_spec(spec)
    sys.modules[modname] = mod
    spec.loader.exec_module(mod)

    return mod


</t>
<t tx="ekr.20221020070914.35">HELP_TOPICS = {
    'help': """\
        Coverage.py, version {__version__} {extension_modifier}
        Measure, collect, and report on code coverage in Python programs.

        usage: {program_name} &lt;command&gt; [options] [args]

        Commands:
            annotate    Annotate source files with execution information.
            combine     Combine a number of data files.
            debug       Display information about the internals of coverage.py
            erase       Erase previously collected coverage data.
            help        Get help on using coverage.py.
            html        Create an HTML report.
            json        Create a JSON report of coverage results.
            lcov        Create an LCOV report of coverage results.
            report      Report coverage stats on modules.
            run         Run a Python program and measure code execution.
            xml         Create an XML report of coverage results.

        Use "{program_name} help &lt;command&gt;" for detailed help on any command.
    """,

    'minimum_help': """\
        Code coverage for Python, version {__version__} {extension_modifier}.  Use '{program_name} help' for help.
    """,

    'version': """\
        Coverage.py, version {__version__} {extension_modifier}
    """,
}


</t>
<t tx="ekr.20221020070914.350">def human_key(s):
    """Turn a string into a list of string and number chunks.
        "z23a" -&gt; ["z", 23, "a"]
    """
    @others
    return [tryint(c) for c in re.split(r"(\d+)", s)]

</t>
<t tx="ekr.20221020070914.351">def tryint(s):
    """If `s` is a number, return an int, else `s` unchanged."""
    try:
        return int(s)
    except ValueError:
        return s

</t>
<t tx="ekr.20221020070914.352">def human_sorted(strings):
    """Sort the given iterable of strings the way that humans expect.

    Numeric components in the strings are sorted as numbers.

    Returns the sorted list.

    """
    return sorted(strings, key=human_key)

</t>
<t tx="ekr.20221020070914.353">def human_sorted_items(items, reverse=False):
    """Sort the (string, value) items the way humans expect.

    Returns the sorted list of items.
    """
    return sorted(items, key=lambda pair: (human_key(pair[0]), pair[1]), reverse=reverse)


</t>
<t tx="ekr.20221020070914.354">def plural(n, thing="", things=""):
    """Pluralize a word.

    If n is 1, return thing.  Otherwise return things, or thing+s.
    """
    if n == 1:
        return thing
    else:
        return things or (thing + "s")
</t>
<t tx="ekr.20221020070914.355">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Monkey-patching to add multiprocessing support for coverage.py"""

import multiprocessing
import multiprocessing.process
import os
import os.path
import sys
import traceback

from coverage.misc import contract

# An attribute that will be set on the module to indicate that it has been
# monkey-patched.
PATCHED_MARKER = "_coverage$patched"


OriginalProcess = multiprocessing.process.BaseProcess
original_bootstrap = OriginalProcess._bootstrap

@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.356">class ProcessWithCoverage(OriginalProcess):         # pylint: disable=abstract-method
    """A replacement for multiprocess.Process that starts coverage."""

    @others
</t>
<t tx="ekr.20221020070914.357">def _bootstrap(self, *args, **kwargs):
    """Wrapper around _bootstrap to start coverage."""
    try:
        from coverage import Coverage       # avoid circular import
        cov = Coverage(data_suffix=True, auto_data=True)
        cov._warn_preimported_source = False
        cov.start()
        debug = cov._debug
        if debug.should("multiproc"):
            debug.write("Calling multiprocessing bootstrap")
    except Exception:
        print("Exception during multiprocessing bootstrap init:")
        traceback.print_exc(file=sys.stdout)
        sys.stdout.flush()
        raise
    try:
        return original_bootstrap(self, *args, **kwargs)
    finally:
        if debug.should("multiproc"):
            debug.write("Finished multiprocessing bootstrap")
        cov.stop()
        cov.save()
        if debug.should("multiproc"):
            debug.write("Saved multiprocessing data")

</t>
<t tx="ekr.20221020070914.358">class Stowaway:
    """An object to pickle, so when it is unpickled, it can apply the monkey-patch."""
    @others
</t>
<t tx="ekr.20221020070914.359">def __init__(self, rcfile):
    self.rcfile = rcfile

</t>
<t tx="ekr.20221020070914.36">def main(argv=None):
    """The main entry point to coverage.py.

    This is installed as the script entry point.

    """
    if argv is None:
        argv = sys.argv[1:]
    try:
        status = CoverageScript().command_line(argv)
    except _ExceptionDuringRun as err:
        # An exception was caught while running the product code.  The
        # sys.exc_info() return tuple is packed into an _ExceptionDuringRun
        # exception.
        traceback.print_exception(*err.args)    # pylint: disable=no-value-for-parameter
        status = ERR
    except _BaseCoverageException as err:
        # A controlled error inside coverage.py: print the message to the user.
        msg = err.args[0]
        print(msg)
        status = ERR
    except SystemExit as err:
        # The user called `sys.exit()`.  Exit with their argument, if any.
        if err.args:
            status = err.args[0]
        else:
            status = None
    return status

</t>
<t tx="ekr.20221020070914.360">def __getstate__(self):
    return {'rcfile': self.rcfile}

</t>
<t tx="ekr.20221020070914.361">def __setstate__(self, state):
    patch_multiprocessing(state['rcfile'])


</t>
<t tx="ekr.20221020070914.362">@contract(rcfile=str)
def patch_multiprocessing(rcfile):
    """Monkey-patch the multiprocessing module.

    This enables coverage measurement of processes started by multiprocessing.
    This involves aggressive monkey-patching.

    `rcfile` is the path to the rcfile being used.

    """

    if hasattr(multiprocessing, PATCHED_MARKER):
        return

    OriginalProcess._bootstrap = ProcessWithCoverage._bootstrap

    # Set the value in ProcessWithCoverage that will be pickled into the child
    # process.
    os.environ["COVERAGE_RCFILE"] = os.path.abspath(rcfile)

    # When spawning processes rather than forking them, we have no state in the
    # new process.  We sneak in there with a Stowaway: we stuff one of our own
    # objects into the data that gets pickled and sent to the sub-process. When
    # the Stowaway is unpickled, it's __setstate__ method is called, which
    # re-applies the monkey-patch.
    # Windows only spawns, so this is needed to keep Windows working.
    try:
        from multiprocessing import spawn
        original_get_preparation_data = spawn.get_preparation_data
    except (ImportError, AttributeError):
        pass
    else:
        def get_preparation_data_with_stowaway(name):
            """Get the original preparation data, and also insert our stowaway."""
            d = original_get_preparation_data(name)
            d['stowaway'] = Stowaway(rcfile)
            return d

        spawn.get_preparation_data = get_preparation_data_with_stowaway

    setattr(multiprocessing, PATCHED_MARKER, True)
</t>
<t tx="ekr.20221020070914.363">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""
Functions to manipulate packed binary representations of number sets.

To save space, coverage stores sets of line numbers in SQLite using a packed
binary representation called a numbits.  A numbits is a set of positive
integers.

A numbits is stored as a blob in the database.  The exact meaning of the bytes
in the blobs should be considered an implementation detail that might change in
the future.  Use these functions to work with those binary blobs of data.

"""
import json

from itertools import zip_longest

from coverage.misc import contract, new_contract

@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.364">def _to_blob(b):
    """Convert a bytestring into a type SQLite will accept for a blob."""
    return b

</t>
<t tx="ekr.20221020070914.365">new_contract('blob', lambda v: isinstance(v, bytes))


</t>
<t tx="ekr.20221020070914.366">@contract(nums='Iterable', returns='blob')
def nums_to_numbits(nums):
    """Convert `nums` into a numbits.

    Arguments:
        nums: a reusable iterable of integers, the line numbers to store.

    Returns:
        A binary blob.
    """
    try:
        nbytes = max(nums) // 8 + 1
    except ValueError:
        # nums was empty.
        return _to_blob(b'')
    b = bytearray(nbytes)
    for num in nums:
        b[num//8] |= 1 &lt;&lt; num % 8
    return _to_blob(bytes(b))


</t>
<t tx="ekr.20221020070914.367">@contract(numbits='blob', returns='list[int]')
def numbits_to_nums(numbits):
    """Convert a numbits into a list of numbers.

    Arguments:
        numbits: a binary blob, the packed number set.

    Returns:
        A list of ints.

    When registered as a SQLite function by :func:`register_sqlite_functions`,
    this returns a string, a JSON-encoded list of ints.

    """
    nums = []
    for byte_i, byte in enumerate(numbits):
        for bit_i in range(8):
            if (byte &amp; (1 &lt;&lt; bit_i)):
                nums.append(byte_i * 8 + bit_i)
    return nums


</t>
<t tx="ekr.20221020070914.368">@contract(numbits1='blob', numbits2='blob', returns='blob')
def numbits_union(numbits1, numbits2):
    """Compute the union of two numbits.

    Returns:
        A new numbits, the union of `numbits1` and `numbits2`.
    """
    byte_pairs = zip_longest(numbits1, numbits2, fillvalue=0)
    return _to_blob(bytes(b1 | b2 for b1, b2 in byte_pairs))


</t>
<t tx="ekr.20221020070914.369">@contract(numbits1='blob', numbits2='blob', returns='blob')
def numbits_intersection(numbits1, numbits2):
    """Compute the intersection of two numbits.

    Returns:
        A new numbits, the intersection `numbits1` and `numbits2`.
    """
    byte_pairs = zip_longest(numbits1, numbits2, fillvalue=0)
    intersection_bytes = bytes(b1 &amp; b2 for b1, b2 in byte_pairs)
    return _to_blob(intersection_bytes.rstrip(b'\0'))


</t>
<t tx="ekr.20221020070914.37">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Raw data collector for coverage.py."""

import os
import sys

from coverage import env
from coverage.config import CoverageConfig
from coverage.debug import short_stack
from coverage.disposition import FileDisposition
from coverage.exceptions import ConfigError
from coverage.misc import human_sorted, isolate_module
from coverage.pytracer import PyTracer

os = isolate_module(os)


try:
    # Use the C extension code when we can, for speed.
    from coverage.tracer import CTracer, CFileDisposition
except ImportError:
    # Couldn't import the C extension, maybe it isn't built.
    if os.getenv('COVERAGE_TEST_TRACER') == 'c':        # pragma: part covered
        # During testing, we use the COVERAGE_TEST_TRACER environment variable
        # to indicate that we've fiddled with the environment to test this
        # fallback code.  If we thought we had a C tracer, but couldn't import
        # it, then exit quickly and clearly instead of dribbling confusing
        # errors. I'm using sys.exit here instead of an exception because an
        # exception here causes all sorts of other noise in unittest.
        sys.stderr.write("*** COVERAGE_TEST_TRACER is 'c' but can't import CTracer!\n")
        sys.exit(1)
    CTracer = None


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.370">@contract(numbits1='blob', numbits2='blob', returns='bool')
def numbits_any_intersection(numbits1, numbits2):
    """Is there any number that appears in both numbits?

    Determine whether two number sets have a non-empty intersection. This is
    faster than computing the intersection.

    Returns:
        A bool, True if there is any number in both `numbits1` and `numbits2`.
    """
    byte_pairs = zip_longest(numbits1, numbits2, fillvalue=0)
    return any(b1 &amp; b2 for b1, b2 in byte_pairs)


</t>
<t tx="ekr.20221020070914.371">@contract(num='int', numbits='blob', returns='bool')
def num_in_numbits(num, numbits):
    """Does the integer `num` appear in `numbits`?

    Returns:
        A bool, True if `num` is a member of `numbits`.
    """
    nbyte, nbit = divmod(num, 8)
    if nbyte &gt;= len(numbits):
        return False
    return bool(numbits[nbyte] &amp; (1 &lt;&lt; nbit))


</t>
<t tx="ekr.20221020070914.372">def register_sqlite_functions(connection):
    """
    Define numbits functions in a SQLite connection.

    This defines these functions for use in SQLite statements:

    * :func:`numbits_union`
    * :func:`numbits_intersection`
    * :func:`numbits_any_intersection`
    * :func:`num_in_numbits`
    * :func:`numbits_to_nums`

    `connection` is a :class:`sqlite3.Connection &lt;python:sqlite3.Connection&gt;`
    object.  After creating the connection, pass it to this function to
    register the numbits functions.  Then you can use numbits functions in your
    queries::

        import sqlite3
        from coverage.numbits import register_sqlite_functions

        conn = sqlite3.connect('example.db')
        register_sqlite_functions(conn)
        c = conn.cursor()
        # Kind of a nonsense query:
        # Find all the files and contexts that executed line 47 in any file:
        c.execute(
            "select file_id, context_id from line_bits where num_in_numbits(?, numbits)",
            (47,)
        )
    """
    connection.create_function("numbits_union", 2, numbits_union)
    connection.create_function("numbits_intersection", 2, numbits_intersection)
    connection.create_function("numbits_any_intersection", 2, numbits_any_intersection)
    connection.create_function("num_in_numbits", 2, num_in_numbits)
    connection.create_function("numbits_to_nums", 1, lambda b: json.dumps(numbits_to_nums(b)))
</t>
<t tx="ekr.20221020070914.373">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Code parsing for coverage.py."""

import ast
import collections
import os
import re
import token
import tokenize

from coverage import env
from coverage.bytecode import code_objects
from coverage.debug import short_stack
from coverage.exceptions import NoSource, NotPython, _StopEverything
from coverage.misc import contract, join_regex, new_contract, nice_pair, one_of
from coverage.phystokens import compile_unicode, generate_tokens, neuter_encoding_declaration


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.374">class PythonParser:
    """Parse code to find executable lines, excluded lines, etc.

    This information is all based on static analysis: no code execution is
    involved.

    """
    @others
</t>
<t tx="ekr.20221020070914.375">@contract(text='unicode|None')
def __init__(self, text=None, filename=None, exclude=None):
    """
    Source can be provided as `text`, the text itself, or `filename`, from
    which the text will be read.  Excluded lines are those that match
    `exclude`, a regex.

    """
    assert text or filename, "PythonParser needs either text or filename"
    self.filename = filename or "&lt;code&gt;"
    self.text = text
    if not self.text:
        from coverage.python import get_python_source
        try:
            self.text = get_python_source(self.filename)
        except OSError as err:
            raise NoSource(f"No source for code: '{self.filename}': {err}") from err

    self.exclude = exclude

    # The text lines of the parsed code.
    self.lines = self.text.split('\n')

    # The normalized line numbers of the statements in the code. Exclusions
    # are taken into account, and statements are adjusted to their first
    # lines.
    self.statements = set()

    # The normalized line numbers of the excluded lines in the code,
    # adjusted to their first lines.
    self.excluded = set()

    # The raw_* attributes are only used in this class, and in
    # lab/parser.py to show how this class is working.

    # The line numbers that start statements, as reported by the line
    # number table in the bytecode.
    self.raw_statements = set()

    # The raw line numbers of excluded lines of code, as marked by pragmas.
    self.raw_excluded = set()

    # The line numbers of class definitions.
    self.raw_classdefs = set()

    # The line numbers of docstring lines.
    self.raw_docstrings = set()

    # Internal detail, used by lab/parser.py.
    self.show_tokens = False

    # A dict mapping line numbers to lexical statement starts for
    # multi-line statements.
    self._multiline = {}

    # Lazily-created arc data, and missing arc descriptions.
    self._all_arcs = None
    self._missing_arc_fragments = None

</t>
<t tx="ekr.20221020070914.376">def lines_matching(self, *regexes):
    """Find the lines matching one of a list of regexes.

    Returns a set of line numbers, the lines that contain a match for one
    of the regexes in `regexes`.  The entire line needn't match, just a
    part of it.

    """
    combined = join_regex(regexes)
    regex_c = re.compile(combined)
    matches = set()
    for i, ltext in enumerate(self.lines, start=1):
        if regex_c.search(ltext):
            matches.add(i)
    return matches

</t>
<t tx="ekr.20221020070914.377">def _raw_parse(self):
    """Parse the source to find the interesting facts about its lines.

    A handful of attributes are updated.

    """
    # Find lines which match an exclusion pattern.
    if self.exclude:
        self.raw_excluded = self.lines_matching(self.exclude)

    # Tokenize, to find excluded suites, to find docstrings, and to find
    # multi-line statements.
    indent = 0
    exclude_indent = 0
    excluding = False
    excluding_decorators = False
    prev_toktype = token.INDENT
    first_line = None
    empty = True
    first_on_line = True
    nesting = 0

    tokgen = generate_tokens(self.text)
    for toktype, ttext, (slineno, _), (elineno, _), ltext in tokgen:
        if self.show_tokens:                # pragma: debugging
            print("%10s %5s %-20r %r" % (
                tokenize.tok_name.get(toktype, toktype),
                nice_pair((slineno, elineno)), ttext, ltext
            ))
        if toktype == token.INDENT:
            indent += 1
        elif toktype == token.DEDENT:
            indent -= 1
        elif toktype == token.NAME:
            if ttext == 'class':
                # Class definitions look like branches in the bytecode, so
                # we need to exclude them.  The simplest way is to note the
                # lines with the 'class' keyword.
                self.raw_classdefs.add(slineno)
        elif toktype == token.OP:
            if ttext == ':' and nesting == 0:
                should_exclude = (elineno in self.raw_excluded) or excluding_decorators
                if not excluding and should_exclude:
                    # Start excluding a suite.  We trigger off of the colon
                    # token so that the #pragma comment will be recognized on
                    # the same line as the colon.
                    self.raw_excluded.add(elineno)
                    exclude_indent = indent
                    excluding = True
                    excluding_decorators = False
            elif ttext == '@' and first_on_line:
                # A decorator.
                if elineno in self.raw_excluded:
                    excluding_decorators = True
                if excluding_decorators:
                    self.raw_excluded.add(elineno)
            elif ttext in "([{":
                nesting += 1
            elif ttext in ")]}":
                nesting -= 1
        elif toktype == token.STRING and prev_toktype == token.INDENT:
            # Strings that are first on an indented line are docstrings.
            # (a trick from trace.py in the stdlib.) This works for
            # 99.9999% of cases.  For the rest (!) see:
            # http://stackoverflow.com/questions/1769332/x/1769794#1769794
            self.raw_docstrings.update(range(slineno, elineno+1))
        elif toktype == token.NEWLINE:
            if first_line is not None and elineno != first_line:
                # We're at the end of a line, and we've ended on a
                # different line than the first line of the statement,
                # so record a multi-line range.
                for l in range(first_line, elineno+1):
                    self._multiline[l] = first_line
            first_line = None
            first_on_line = True

        if ttext.strip() and toktype != tokenize.COMMENT:
            # A non-whitespace token.
            empty = False
            if first_line is None:
                # The token is not whitespace, and is the first in a
                # statement.
                first_line = slineno
                # Check whether to end an excluded suite.
                if excluding and indent &lt;= exclude_indent:
                    excluding = False
                if excluding:
                    self.raw_excluded.add(elineno)
                first_on_line = False

        prev_toktype = toktype

    # Find the starts of the executable statements.
    if not empty:
        byte_parser = ByteParser(self.text, filename=self.filename)
        self.raw_statements.update(byte_parser._find_statements())

    # The first line of modules can lie and say 1 always, even if the first
    # line of code is later. If so, map 1 to the actual first line of the
    # module.
    if env.PYBEHAVIOR.module_firstline_1 and self._multiline:
        self._multiline[1] = min(self.raw_statements)

</t>
<t tx="ekr.20221020070914.378">def first_line(self, line):
    """Return the first line number of the statement including `line`."""
    if line &lt; 0:
        line = -self._multiline.get(-line, -line)
    else:
        line = self._multiline.get(line, line)
    return line

</t>
<t tx="ekr.20221020070914.379">def first_lines(self, lines):
    """Map the line numbers in `lines` to the correct first line of the
    statement.

    Returns a set of the first lines.

    """
    return {self.first_line(l) for l in lines}

</t>
<t tx="ekr.20221020070914.38">class Collector:
    """Collects trace data.

    Creates a Tracer object for each thread, since they track stack
    information.  Each Tracer points to the same shared data, contributing
    traced data points.

    When the Collector is started, it creates a Tracer for the current thread,
    and installs a function to create Tracers for each new thread started.
    When the Collector is stopped, all active Tracers are stopped.

    Threads started while the Collector is stopped will never have Tracers
    associated with them.

    """

    # The stack of active Collectors.  Collectors are added here when started,
    # and popped when stopped.  Collectors on the stack are paused when not
    # the top, and resumed when they become the top again.
    _collectors = []

    # The concurrency settings we support here.
    LIGHT_THREADS = {"greenlet", "eventlet", "gevent"}

    @others
</t>
<t tx="ekr.20221020070914.380">def translate_lines(self, lines):
    """Implement `FileReporter.translate_lines`."""
    return self.first_lines(lines)

</t>
<t tx="ekr.20221020070914.381">def translate_arcs(self, arcs):
    """Implement `FileReporter.translate_arcs`."""
    return [(self.first_line(a), self.first_line(b)) for (a, b) in arcs]

</t>
<t tx="ekr.20221020070914.382">def parse_source(self):
    """Parse source text to find executable lines, excluded lines, etc.

    Sets the .excluded and .statements attributes, normalized to the first
    line of multi-line statements.

    """
    try:
        self._raw_parse()
    except (tokenize.TokenError, IndentationError) as err:
        if hasattr(err, "lineno"):
            lineno = err.lineno         # IndentationError
        else:
            lineno = err.args[1][0]     # TokenError
        raise NotPython(
            f"Couldn't parse '{self.filename}' as Python source: " +
            f"{err.args[0]!r} at line {lineno}"
        ) from err

    self.excluded = self.first_lines(self.raw_excluded)

    ignore = self.excluded | self.raw_docstrings
    starts = self.raw_statements - ignore
    self.statements = self.first_lines(starts) - ignore

</t>
<t tx="ekr.20221020070914.383">def arcs(self):
    """Get information about the arcs available in the code.

    Returns a set of line number pairs.  Line numbers have been normalized
    to the first line of multi-line statements.

    """
    if self._all_arcs is None:
        self._analyze_ast()
    return self._all_arcs

</t>
<t tx="ekr.20221020070914.384">def _analyze_ast(self):
    """Run the AstArcAnalyzer and save its results.

    `_all_arcs` is the set of arcs in the code.

    """
    aaa = AstArcAnalyzer(self.text, self.raw_statements, self._multiline)
    aaa.analyze()

    self._all_arcs = set()
    for l1, l2 in aaa.arcs:
        fl1 = self.first_line(l1)
        fl2 = self.first_line(l2)
        if fl1 != fl2:
            self._all_arcs.add((fl1, fl2))

    self._missing_arc_fragments = aaa.missing_arc_fragments

</t>
<t tx="ekr.20221020070914.385">def exit_counts(self):
    """Get a count of exits from that each line.

    Excluded lines are excluded.

    """
    exit_counts = collections.defaultdict(int)
    for l1, l2 in self.arcs():
        if l1 &lt; 0:
            # Don't ever report -1 as a line number
            continue
        if l1 in self.excluded:
            # Don't report excluded lines as line numbers.
            continue
        if l2 in self.excluded:
            # Arcs to excluded lines shouldn't count.
            continue
        exit_counts[l1] += 1

    # Class definitions have one extra exit, so remove one for each:
    for l in self.raw_classdefs:
        # Ensure key is there: class definitions can include excluded lines.
        if l in exit_counts:
            exit_counts[l] -= 1

    return exit_counts

</t>
<t tx="ekr.20221020070914.386">def missing_arc_description(self, start, end, executed_arcs=None):
    """Provide an English sentence describing a missing arc."""
    if self._missing_arc_fragments is None:
        self._analyze_ast()

    actual_start = start

    if (
        executed_arcs and
        end &lt; 0 and end == -start and
        (end, start) not in executed_arcs and
        (end, start) in self._missing_arc_fragments
    ):
        # It's a one-line callable, and we never even started it,
        # and we have a message about not starting it.
        start, end = end, start

    fragment_pairs = self._missing_arc_fragments.get((start, end), [(None, None)])

    msgs = []
    for smsg, emsg in fragment_pairs:
        if emsg is None:
            if end &lt; 0:
                # Hmm, maybe we have a one-line callable, let's check.
                if (-end, end) in self._missing_arc_fragments:
                    return self.missing_arc_description(-end, end)
                emsg = "didn't jump to the function exit"
            else:
                emsg = "didn't jump to line {lineno}"
        emsg = emsg.format(lineno=end)

        msg = f"line {actual_start} {emsg}"
        if smsg is not None:
            msg += f", because {smsg.format(lineno=actual_start)}"

        msgs.append(msg)

    return " or ".join(msgs)


</t>
<t tx="ekr.20221020070914.387">class ByteParser:
    """Parse bytecode to understand the structure of code."""

    @others
</t>
<t tx="ekr.20221020070914.388">@contract(text='unicode')
def __init__(self, text, code=None, filename=None):
    self.text = text
    if code:
        self.code = code
    else:
        try:
            self.code = compile_unicode(text, filename, "exec")
        except SyntaxError as synerr:
            raise NotPython(
                "Couldn't parse '%s' as Python source: '%s' at line %d" % (
                    filename, synerr.msg, synerr.lineno
                )
            ) from synerr

    # Alternative Python implementations don't always provide all the
    # attributes on code objects that we need to do the analysis.
    for attr in ['co_lnotab', 'co_firstlineno']:
        if not hasattr(self.code, attr):
            raise _StopEverything(                  # pragma: only jython
                "This implementation of Python doesn't support code analysis.\n" +
                "Run coverage.py under another Python for this command."
            )

</t>
<t tx="ekr.20221020070914.389">def child_parsers(self):
    """Iterate over all the code objects nested within this one.

    The iteration includes `self` as its first value.

    """
    return (ByteParser(self.text, code=c) for c in code_objects(self.code))

</t>
<t tx="ekr.20221020070914.39">def __init__(
    self, should_trace, check_include, should_start_context, file_mapper,
    timid, branch, warn, concurrency,
):
    """Create a collector.

    `should_trace` is a function, taking a file name and a frame, and
    returning a `coverage.FileDisposition object`.

    `check_include` is a function taking a file name and a frame. It returns
    a boolean: True if the file should be traced, False if not.

    `should_start_context` is a function taking a frame, and returning a
    string. If the frame should be the start of a new context, the string
    is the new context. If the frame should not be the start of a new
    context, return None.

    `file_mapper` is a function taking a filename, and returning a Unicode
    filename.  The result is the name that will be recorded in the data
    file.

    If `timid` is true, then a slower simpler trace function will be
    used.  This is important for some environments where manipulation of
    tracing functions make the faster more sophisticated trace function not
    operate properly.

    If `branch` is true, then branches will be measured.  This involves
    collecting data on which statements followed each other (arcs).  Use
    `get_arc_data` to get the arc data.

    `warn` is a warning function, taking a single string message argument
    and an optional slug argument which will be a string or None, to be
    used if a warning needs to be issued.

    `concurrency` is a list of strings indicating the concurrency libraries
    in use.  Valid values are "greenlet", "eventlet", "gevent", or "thread"
    (the default).  "thread" can be combined with one of the other three.
    Other values are ignored.

    """
    self.should_trace = should_trace
    self.check_include = check_include
    self.should_start_context = should_start_context
    self.file_mapper = file_mapper
    self.branch = branch
    self.warn = warn
    self.concurrency = concurrency
    assert isinstance(self.concurrency, list), f"Expected a list: {self.concurrency!r}"

    self.threading = None
    self.covdata = None
    self.static_context = None

    self.origin = short_stack()

    self.concur_id_func = None
    self.mapped_file_cache = {}

    if timid:
        # Being timid: use the simple Python trace function.
        self._trace_class = PyTracer
    else:
        # Being fast: use the C Tracer if it is available, else the Python
        # trace function.
        self._trace_class = CTracer or PyTracer

    if self._trace_class is CTracer:
        self.file_disposition_class = CFileDisposition
        self.supports_plugins = True
        self.packed_arcs = True
    else:
        self.file_disposition_class = FileDisposition
        self.supports_plugins = False
        self.packed_arcs = False

    # We can handle a few concurrency options here, but only one at a time.
    concurrencies = set(self.concurrency)
    unknown = concurrencies - CoverageConfig.CONCURRENCY_CHOICES
    if unknown:
        show = ", ".join(sorted(unknown))
        raise ConfigError(f"Unknown concurrency choices: {show}")
    light_threads = concurrencies &amp; self.LIGHT_THREADS
    if len(light_threads) &gt; 1:
        show = ", ".join(sorted(light_threads))
        raise ConfigError(f"Conflicting concurrency settings: {show}")
    do_threading = False

    tried = "nothing"  # to satisfy pylint
    try:
        if "greenlet" in concurrencies:
            tried = "greenlet"
            import greenlet
            self.concur_id_func = greenlet.getcurrent
        elif "eventlet" in concurrencies:
            tried = "eventlet"
            import eventlet.greenthread     # pylint: disable=import-error,useless-suppression
            self.concur_id_func = eventlet.greenthread.getcurrent
        elif "gevent" in concurrencies:
            tried = "gevent"
            import gevent                   # pylint: disable=import-error,useless-suppression
            self.concur_id_func = gevent.getcurrent

        if "thread" in concurrencies:
            do_threading = True
    except ImportError as ex:
        msg = f"Couldn't trace with concurrency={tried}, the module isn't installed."
        raise ConfigError(msg) from ex

    if self.concur_id_func and not hasattr(self._trace_class, "concur_id_func"):
        raise ConfigError(
            "Can't support concurrency={} with {}, only threads are supported.".format(
                tried, self.tracer_name(),
            )
        )

    if do_threading or not concurrencies:
        # It's important to import threading only if we need it.  If
        # it's imported early, and the program being measured uses
        # gevent, then gevent's monkey-patching won't work properly.
        import threading
        self.threading = threading

    self.reset()

</t>
<t tx="ekr.20221020070914.390">def _line_numbers(self):
    """Yield the line numbers possible in this code object.

    Uses co_lnotab described in Python/compile.c to find the
    line numbers.  Produces a sequence: l0, l1, ...
    """
    if hasattr(self.code, "co_lines"):
        for _, _, line in self.code.co_lines():
            if line:
                yield line
    else:
        # Adapted from dis.py in the standard library.
        byte_increments = self.code.co_lnotab[0::2]
        line_increments = self.code.co_lnotab[1::2]

        last_line_num = None
        line_num = self.code.co_firstlineno
        byte_num = 0
        for byte_incr, line_incr in zip(byte_increments, line_increments):
            if byte_incr:
                if line_num != last_line_num:
                    yield line_num
                    last_line_num = line_num
                byte_num += byte_incr
            if env.PYBEHAVIOR.negative_lnotab and line_incr &gt;= 0x80:
                line_incr -= 0x100
            line_num += line_incr
        if line_num != last_line_num:
            yield line_num

</t>
<t tx="ekr.20221020070914.391">def _find_statements(self):
    """Find the statements in `self.code`.

    Produce a sequence of line numbers that start statements.  Recurses
    into all code objects reachable from `self.code`.

    """
    for bp in self.child_parsers():
        # Get all of the lineno information from this code.
        yield from bp._line_numbers()


</t>
<t tx="ekr.20221020070914.392">#
# AST analysis
#

</t>
<t tx="ekr.20221020070914.393">class BlockBase:
    """
    Blocks need to handle various exiting statements in their own ways.

    All of these methods take a list of exits, and a callable `add_arc`
    function that they can use to add arcs if needed.  They return True if the
    exits are handled, or False if the search should continue up the block
    stack.
    """
    @others
</t>
<t tx="ekr.20221020070914.394"># pylint: disable=unused-argument
def process_break_exits(self, exits, add_arc):
    """Process break exits."""
    # Because break can only appear in loops, and most subclasses
    # implement process_break_exits, this function is never reached.
    raise AssertionError

</t>
<t tx="ekr.20221020070914.395">def process_continue_exits(self, exits, add_arc):
    """Process continue exits."""
    # Because continue can only appear in loops, and most subclasses
    # implement process_continue_exits, this function is never reached.
    raise AssertionError

</t>
<t tx="ekr.20221020070914.396">def process_raise_exits(self, exits, add_arc):
    """Process raise exits."""
    return False

</t>
<t tx="ekr.20221020070914.397">def process_return_exits(self, exits, add_arc):
    """Process return exits."""
    return False


</t>
<t tx="ekr.20221020070914.398">class LoopBlock(BlockBase):
    """A block on the block stack representing a `for` or `while` loop."""
    @others
</t>
<t tx="ekr.20221020070914.399">@contract(start=int)
def __init__(self, start):
    # The line number where the loop starts.
    self.start = start
    # A set of ArcStarts, the arcs from break statements exiting this loop.
    self.break_exits = set()

</t>
<t tx="ekr.20221020070914.4">def __init__(self, coverage):
    self.coverage = coverage
    self.config = self.coverage.config
    self.directory = None

</t>
<t tx="ekr.20221020070914.40">def __repr__(self):
    return f"&lt;Collector at 0x{id(self):x}: {self.tracer_name()}&gt;"

</t>
<t tx="ekr.20221020070914.400">def process_break_exits(self, exits, add_arc):
    self.break_exits.update(exits)
    return True

</t>
<t tx="ekr.20221020070914.401">def process_continue_exits(self, exits, add_arc):
    for xit in exits:
        add_arc(xit.lineno, self.start, xit.cause)
    return True


</t>
<t tx="ekr.20221020070914.402">class FunctionBlock(BlockBase):
    """A block on the block stack representing a function definition."""
    @others
</t>
<t tx="ekr.20221020070914.403">@contract(start=int, name=str)
def __init__(self, start, name):
    # The line number where the function starts.
    self.start = start
    # The name of the function.
    self.name = name

</t>
<t tx="ekr.20221020070914.404">def process_raise_exits(self, exits, add_arc):
    for xit in exits:
        add_arc(
            xit.lineno, -self.start, xit.cause,
            f"didn't except from function {self.name!r}",
        )
    return True

</t>
<t tx="ekr.20221020070914.405">def process_return_exits(self, exits, add_arc):
    for xit in exits:
        add_arc(
            xit.lineno, -self.start, xit.cause,
            f"didn't return from function {self.name!r}",
        )
    return True


</t>
<t tx="ekr.20221020070914.406">class TryBlock(BlockBase):
    """A block on the block stack representing a `try` block."""
    @others
</t>
<t tx="ekr.20221020070914.407">@contract(handler_start='int|None', final_start='int|None')
def __init__(self, handler_start, final_start):
    # The line number of the first "except" handler, if any.
    self.handler_start = handler_start
    # The line number of the "finally:" clause, if any.
    self.final_start = final_start

    # The ArcStarts for breaks/continues/returns/raises inside the "try:"
    # that need to route through the "finally:" clause.
    self.break_from = set()
    self.continue_from = set()
    self.raise_from = set()
    self.return_from = set()

</t>
<t tx="ekr.20221020070914.408">def process_break_exits(self, exits, add_arc):
    if self.final_start is not None:
        self.break_from.update(exits)
        return True
    return False

</t>
<t tx="ekr.20221020070914.409">def process_continue_exits(self, exits, add_arc):
    if self.final_start is not None:
        self.continue_from.update(exits)
        return True
    return False

</t>
<t tx="ekr.20221020070914.41">def use_data(self, covdata, context):
    """Use `covdata` for recording data."""
    self.covdata = covdata
    self.static_context = context
    self.covdata.set_context(self.static_context)

</t>
<t tx="ekr.20221020070914.410">def process_raise_exits(self, exits, add_arc):
    if self.handler_start is not None:
        for xit in exits:
            add_arc(xit.lineno, self.handler_start, xit.cause)
    else:
        assert self.final_start is not None
        self.raise_from.update(exits)
    return True

</t>
<t tx="ekr.20221020070914.411">def process_return_exits(self, exits, add_arc):
    if self.final_start is not None:
        self.return_from.update(exits)
        return True
    return False


</t>
<t tx="ekr.20221020070914.412">class WithBlock(BlockBase):
    """A block on the block stack representing a `with` block."""
    @others
</t>
<t tx="ekr.20221020070914.413">@contract(start=int)
def __init__(self, start):
    # We only ever use this block if it is needed, so that we don't have to
    # check this setting in all the methods.
    assert env.PYBEHAVIOR.exit_through_with

    # The line number of the with statement.
    self.start = start

    # The ArcStarts for breaks/continues/returns/raises inside the "with:"
    # that need to go through the with-statement while exiting.
    self.break_from = set()
    self.continue_from = set()
    self.return_from = set()

</t>
<t tx="ekr.20221020070914.414">def _process_exits(self, exits, add_arc, from_set=None):
    """Helper to process the four kinds of exits."""
    for xit in exits:
        add_arc(xit.lineno, self.start, xit.cause)
    if from_set is not None:
        from_set.update(exits)
    return True

</t>
<t tx="ekr.20221020070914.415">def process_break_exits(self, exits, add_arc):
    return self._process_exits(exits, add_arc, self.break_from)

</t>
<t tx="ekr.20221020070914.416">def process_continue_exits(self, exits, add_arc):
    return self._process_exits(exits, add_arc, self.continue_from)

</t>
<t tx="ekr.20221020070914.417">def process_raise_exits(self, exits, add_arc):
    return self._process_exits(exits, add_arc)

</t>
<t tx="ekr.20221020070914.418">def process_return_exits(self, exits, add_arc):
    return self._process_exits(exits, add_arc, self.return_from)


</t>
<t tx="ekr.20221020070914.419">class ArcStart(collections.namedtuple("Arc", "lineno, cause")):
    """The information needed to start an arc.

    `lineno` is the line number the arc starts from.

    `cause` is an English text fragment used as the `startmsg` for
    AstArcAnalyzer.missing_arc_fragments.  It will be used to describe why an
    arc wasn't executed, so should fit well into a sentence of the form,
    "Line 17 didn't run because {cause}."  The fragment can include "{lineno}"
    to have `lineno` interpolated into it.

    """
    @others
</t>
<t tx="ekr.20221020070914.42">def tracer_name(self):
    """Return the class name of the tracer we're using."""
    return self._trace_class.__name__

</t>
<t tx="ekr.20221020070914.420">def __new__(cls, lineno, cause=None):
    return super().__new__(cls, lineno, cause)


</t>
<t tx="ekr.20221020070914.421"># Define contract words that PyContract doesn't have.
# ArcStarts is for a list or set of ArcStart's.
new_contract('ArcStarts', lambda seq: all(isinstance(x, ArcStart) for x in seq))


</t>
<t tx="ekr.20221020070914.422">class NodeList:
    """A synthetic fictitious node, containing a sequence of nodes.

    This is used when collapsing optimized if-statements, to represent the
    unconditional execution of one of the clauses.

    """
    @others
</t>
<t tx="ekr.20221020070914.423">def __init__(self, body):
    self.body = body
    self.lineno = body[0].lineno

</t>
<t tx="ekr.20221020070914.424"># TODO: some add_arcs methods here don't add arcs, they return them. Rename them.
# TODO: the cause messages have too many commas.
# TODO: Shouldn't the cause messages join with "and" instead of "or"?

</t>
<t tx="ekr.20221020070914.425">def ast_parse(text):
    """How we create an AST parse."""
    return ast.parse(neuter_encoding_declaration(text))


</t>
<t tx="ekr.20221020070914.426">class AstArcAnalyzer:
    """Analyze source text with an AST to find executable code paths."""

    @others
    _code_object__Lambda = _make_expression_code_method("lambda")
    _code_object__GeneratorExp = _make_expression_code_method("generator expression")
    _code_object__DictComp = _make_expression_code_method("dictionary comprehension")
    _code_object__SetComp = _make_expression_code_method("set comprehension")
    _code_object__ListComp = _make_expression_code_method("list comprehension")


</t>
<t tx="ekr.20221020070914.427">@contract(text='unicode', statements=set)
def __init__(self, text, statements, multiline):
    self.root_node = ast_parse(text)
    # TODO: I think this is happening in too many places.
    self.statements = {multiline.get(l, l) for l in statements}
    self.multiline = multiline

    # Turn on AST dumps with an environment variable.
    # $set_env.py: COVERAGE_AST_DUMP - Dump the AST nodes when parsing code.
    dump_ast = bool(int(os.environ.get("COVERAGE_AST_DUMP", 0)))

    if dump_ast:                                # pragma: debugging
        # Dump the AST so that failing tests have helpful output.
        print(f"Statements: {self.statements}")
        print(f"Multiline map: {self.multiline}")
        ast_dump(self.root_node)

    self.arcs = set()

    # A map from arc pairs to a list of pairs of sentence fragments:
    #   { (start, end): [(startmsg, endmsg), ...], }
    #
    # For an arc from line 17, they should be usable like:
    #    "Line 17 {endmsg}, because {startmsg}"
    self.missing_arc_fragments = collections.defaultdict(list)
    self.block_stack = []

    # $set_env.py: COVERAGE_TRACK_ARCS - Trace possible arcs added while parsing code.
    self.debug = bool(int(os.environ.get("COVERAGE_TRACK_ARCS", 0)))

</t>
<t tx="ekr.20221020070914.428">def analyze(self):
    """Examine the AST tree from `root_node` to determine possible arcs.

    This sets the `arcs` attribute to be a set of (from, to) line number
    pairs.

    """
    for node in ast.walk(self.root_node):
        node_name = node.__class__.__name__
        code_object_handler = getattr(self, "_code_object__" + node_name, None)
        if code_object_handler is not None:
            code_object_handler(node)

</t>
<t tx="ekr.20221020070914.429">@contract(start=int, end=int)
def add_arc(self, start, end, smsg=None, emsg=None):
    """Add an arc, including message fragments to use if it is missing."""
    if self.debug:                      # pragma: debugging
        print(f"\nAdding possible arc: ({start}, {end}): {smsg!r}, {emsg!r}")
        print(short_stack(limit=10))
    self.arcs.add((start, end))

    if smsg is not None or emsg is not None:
        self.missing_arc_fragments[(start, end)].append((smsg, emsg))

</t>
<t tx="ekr.20221020070914.43">def _clear_data(self):
    """Clear out existing data, but stay ready for more collection."""
    # We used to used self.data.clear(), but that would remove filename
    # keys and data values that were still in use higher up the stack
    # when we are called as part of switch_context.
    for d in self.data.values():
        d.clear()

    for tracer in self.tracers:
        tracer.reset_activity()

</t>
<t tx="ekr.20221020070914.430">def nearest_blocks(self):
    """Yield the blocks in nearest-to-farthest order."""
    return reversed(self.block_stack)

</t>
<t tx="ekr.20221020070914.431">@contract(returns=int)
def line_for_node(self, node):
    """What is the right line number to use for this node?

    This dispatches to _line__Node functions where needed.

    """
    node_name = node.__class__.__name__
    handler = getattr(self, "_line__" + node_name, None)
    if handler is not None:
        return handler(node)
    else:
        return node.lineno

</t>
<t tx="ekr.20221020070914.432">def _line_decorated(self, node):
    """Compute first line number for things that can be decorated (classes and functions)."""
    lineno = node.lineno
    if env.PYBEHAVIOR.trace_decorated_def or env.PYBEHAVIOR.def_ast_no_decorator:
        if node.decorator_list:
            lineno = node.decorator_list[0].lineno
    return lineno

</t>
<t tx="ekr.20221020070914.433">def _line__Assign(self, node):
    return self.line_for_node(node.value)

</t>
<t tx="ekr.20221020070914.434">_line__ClassDef = _line_decorated

</t>
<t tx="ekr.20221020070914.435">def _line__Dict(self, node):
    if node.keys:
        if node.keys[0] is not None:
            return node.keys[0].lineno
        else:
            # Unpacked dict literals `{**{'a':1}}` have None as the key,
            # use the value in that case.
            return node.values[0].lineno
    else:
        return node.lineno

</t>
<t tx="ekr.20221020070914.436">_line__FunctionDef = _line_decorated
_line__AsyncFunctionDef = _line_decorated

</t>
<t tx="ekr.20221020070914.437">def _line__List(self, node):
    if node.elts:
        return self.line_for_node(node.elts[0])
    else:
        return node.lineno

</t>
<t tx="ekr.20221020070914.438">def _line__Module(self, node):
    if env.PYBEHAVIOR.module_firstline_1:
        return 1
    elif node.body:
        return self.line_for_node(node.body[0])
    else:
        # Empty modules have no line number, they always start at 1.
        return 1

</t>
<t tx="ekr.20221020070914.439"># The node types that just flow to the next node with no complications.
OK_TO_DEFAULT = {
    "AnnAssign", "Assign", "Assert", "AugAssign", "Delete", "Expr", "Global",
    "Import", "ImportFrom", "Nonlocal", "Pass",
}

</t>
<t tx="ekr.20221020070914.44">def reset(self):
    """Clear collected data, and prepare to collect more."""
    # A dictionary mapping file names to dicts with line number keys (if not
    # branch coverage), or mapping file names to dicts with line number
    # pairs as keys (if branch coverage).
    self.data = {}

    # A dictionary mapping file names to file tracer plugin names that will
    # handle them.
    self.file_tracers = {}

    self.disabled_plugins = set()

    # The .should_trace_cache attribute is a cache from file names to
    # coverage.FileDisposition objects, or None.  When a file is first
    # considered for tracing, a FileDisposition is obtained from
    # Coverage.should_trace.  Its .trace attribute indicates whether the
    # file should be traced or not.  If it should be, a plugin with dynamic
    # file names can decide not to trace it based on the dynamic file name
    # being excluded by the inclusion rules, in which case the
    # FileDisposition will be replaced by None in the cache.
    if env.PYPY:
        import __pypy__                     # pylint: disable=import-error
        # Alex Gaynor said:
        # should_trace_cache is a strictly growing key: once a key is in
        # it, it never changes.  Further, the keys used to access it are
        # generally constant, given sufficient context. That is to say, at
        # any given point _trace() is called, pypy is able to know the key.
        # This is because the key is determined by the physical source code
        # line, and that's invariant with the call site.
        #
        # This property of a dict with immutable keys, combined with
        # call-site-constant keys is a match for PyPy's module dict,
        # which is optimized for such workloads.
        #
        # This gives a 20% benefit on the workload described at
        # https://bitbucket.org/pypy/pypy/issue/1871/10x-slower-than-cpython-under-coverage
        self.should_trace_cache = __pypy__.newdict("module")
    else:
        self.should_trace_cache = {}

    # Our active Tracers.
    self.tracers = []

    self._clear_data()

</t>
<t tx="ekr.20221020070914.440">@contract(returns='ArcStarts')
def add_arcs(self, node):
    """Add the arcs for `node`.

    Return a set of ArcStarts, exits from this node to the next. Because a
    node represents an entire sub-tree (including its children), the exits
    from a node can be arbitrarily complex::

        if something(1):
            if other(2):
                doit(3)
            else:
                doit(5)

    There are two exits from line 1: they start at line 3 and line 5.

    """
    node_name = node.__class__.__name__
    handler = getattr(self, "_handle__" + node_name, None)
    if handler is not None:
        return handler(node)
    else:
        # No handler: either it's something that's ok to default (a simple
        # statement), or it's something we overlooked.
        if env.TESTING:
            if node_name not in self.OK_TO_DEFAULT:
                raise Exception(f"*** Unhandled: {node}")       # pragma: only failure

        # Default for simple statements: one exit from this node.
        return {ArcStart(self.line_for_node(node))}

</t>
<t tx="ekr.20221020070914.441">@one_of("from_start, prev_starts")
@contract(returns='ArcStarts')
def add_body_arcs(self, body, from_start=None, prev_starts=None):
    """Add arcs for the body of a compound statement.

    `body` is the body node.  `from_start` is a single `ArcStart` that can
    be the previous line in flow before this body.  `prev_starts` is a set
    of ArcStarts that can be the previous line.  Only one of them should be
    given.

    Returns a set of ArcStarts, the exits from this body.

    """
    if prev_starts is None:
        prev_starts = {from_start}
    for body_node in body:
        lineno = self.line_for_node(body_node)
        first_line = self.multiline.get(lineno, lineno)
        if first_line not in self.statements:
            body_node = self.find_non_missing_node(body_node)
            if body_node is None:
                continue
            lineno = self.line_for_node(body_node)
        for prev_start in prev_starts:
            self.add_arc(prev_start.lineno, lineno, prev_start.cause)
        prev_starts = self.add_arcs(body_node)
    return prev_starts

</t>
<t tx="ekr.20221020070914.442">def find_non_missing_node(self, node):
    """Search `node` looking for a child that has not been optimized away.

    This might return the node you started with, or it will work recursively
    to find a child node in self.statements.

    Returns a node, or None if none of the node remains.

    """
    # This repeats work just done in add_body_arcs, but this duplication
    # means we can avoid a function call in the 99.9999% case of not
    # optimizing away statements.
    lineno = self.line_for_node(node)
    first_line = self.multiline.get(lineno, lineno)
    if first_line in self.statements:
        return node

    missing_fn = getattr(self, "_missing__" + node.__class__.__name__, None)
    if missing_fn:
        node = missing_fn(node)
    else:
        node = None
    return node

</t>
<t tx="ekr.20221020070914.443"># Missing nodes: _missing__*
#
# Entire statements can be optimized away by Python. They will appear in
# the AST, but not the bytecode.  These functions are called (by
# find_non_missing_node) to find a node to use instead of the missing
# node.  They can return None if the node should truly be gone.

</t>
<t tx="ekr.20221020070914.444">def _missing__If(self, node):
    # If the if-node is missing, then one of its children might still be
    # here, but not both. So return the first of the two that isn't missing.
    # Use a NodeList to hold the clauses as a single node.
    non_missing = self.find_non_missing_node(NodeList(node.body))
    if non_missing:
        return non_missing
    if node.orelse:
        return self.find_non_missing_node(NodeList(node.orelse))
    return None

</t>
<t tx="ekr.20221020070914.445">def _missing__NodeList(self, node):
    # A NodeList might be a mixture of missing and present nodes. Find the
    # ones that are present.
    non_missing_children = []
    for child in node.body:
        child = self.find_non_missing_node(child)
        if child is not None:
            non_missing_children.append(child)

    # Return the simplest representation of the present children.
    if not non_missing_children:
        return None
    if len(non_missing_children) == 1:
        return non_missing_children[0]
    return NodeList(non_missing_children)

</t>
<t tx="ekr.20221020070914.446">def _missing__While(self, node):
    body_nodes = self.find_non_missing_node(NodeList(node.body))
    if not body_nodes:
        return None
    # Make a synthetic While-true node.
    new_while = ast.While()
    new_while.lineno = body_nodes.lineno
    new_while.test = ast.Name()
    new_while.test.lineno = body_nodes.lineno
    new_while.test.id = "True"
    new_while.body = body_nodes.body
    new_while.orelse = None
    return new_while

</t>
<t tx="ekr.20221020070914.447">def is_constant_expr(self, node):
    """Is this a compile-time constant?"""
    node_name = node.__class__.__name__
    if node_name in ["Constant", "NameConstant", "Num"]:
        return "Num"
    elif node_name == "Name":
        if node.id in ["True", "False", "None", "__debug__"]:
            return "Name"
    return None

</t>
<t tx="ekr.20221020070914.448"># In the fullness of time, these might be good tests to write:
#   while EXPR:
#   while False:
#   listcomps hidden deep in other expressions
#   listcomps hidden in lists: x = [[i for i in range(10)]]
#   nested function definitions


# Exit processing: process_*_exits
#
# These functions process the four kinds of jump exits: break, continue,
# raise, and return.  To figure out where an exit goes, we have to look at
# the block stack context.  For example, a break will jump to the nearest
# enclosing loop block, or the nearest enclosing finally block, whichever
# is nearer.

</t>
<t tx="ekr.20221020070914.449">@contract(exits='ArcStarts')
def process_break_exits(self, exits):
    """Add arcs due to jumps from `exits` being breaks."""
    for block in self.nearest_blocks():                         # pragma: always breaks
        if block.process_break_exits(exits, self.add_arc):
            break

</t>
<t tx="ekr.20221020070914.45">def _start_tracer(self):
    """Start a new Tracer object, and store it in self.tracers."""
    tracer = self._trace_class()
    tracer.data = self.data
    tracer.trace_arcs = self.branch
    tracer.should_trace = self.should_trace
    tracer.should_trace_cache = self.should_trace_cache
    tracer.warn = self.warn

    if hasattr(tracer, 'concur_id_func'):
        tracer.concur_id_func = self.concur_id_func
    if hasattr(tracer, 'file_tracers'):
        tracer.file_tracers = self.file_tracers
    if hasattr(tracer, 'threading'):
        tracer.threading = self.threading
    if hasattr(tracer, 'check_include'):
        tracer.check_include = self.check_include
    if hasattr(tracer, 'should_start_context'):
        tracer.should_start_context = self.should_start_context
        tracer.switch_context = self.switch_context
    if hasattr(tracer, 'disable_plugin'):
        tracer.disable_plugin = self.disable_plugin

    fn = tracer.start()
    self.tracers.append(tracer)

    return fn

</t>
<t tx="ekr.20221020070914.450">@contract(exits='ArcStarts')
def process_continue_exits(self, exits):
    """Add arcs due to jumps from `exits` being continues."""
    for block in self.nearest_blocks():                         # pragma: always breaks
        if block.process_continue_exits(exits, self.add_arc):
            break

</t>
<t tx="ekr.20221020070914.451">@contract(exits='ArcStarts')
def process_raise_exits(self, exits):
    """Add arcs due to jumps from `exits` being raises."""
    for block in self.nearest_blocks():
        if block.process_raise_exits(exits, self.add_arc):
            break

</t>
<t tx="ekr.20221020070914.452">@contract(exits='ArcStarts')
def process_return_exits(self, exits):
    """Add arcs due to jumps from `exits` being returns."""
    for block in self.nearest_blocks():                         # pragma: always breaks
        if block.process_return_exits(exits, self.add_arc):
            break

</t>
<t tx="ekr.20221020070914.453"># Handlers: _handle__*
#
# Each handler deals with a specific AST node type, dispatched from
# add_arcs.  Handlers return the set of exits from that node, and can
# also call self.add_arc to record arcs they find.  These functions mirror
# the Python semantics of each syntactic construct.  See the docstring
# for add_arcs to understand the concept of exits from a node.
#
# Every node type that represents a statement should have a handler, or it
# should be listed in OK_TO_DEFAULT.

</t>
<t tx="ekr.20221020070914.454">@contract(returns='ArcStarts')
def _handle__Break(self, node):
    here = self.line_for_node(node)
    break_start = ArcStart(here, cause="the break on line {lineno} wasn't executed")
    self.process_break_exits([break_start])
    return set()

</t>
<t tx="ekr.20221020070914.455">@contract(returns='ArcStarts')
def _handle_decorated(self, node):
    """Add arcs for things that can be decorated (classes and functions)."""
    main_line = last = node.lineno
    decs = node.decorator_list
    if decs:
        if env.PYBEHAVIOR.trace_decorated_def or env.PYBEHAVIOR.def_ast_no_decorator:
            last = None
        for dec_node in decs:
            dec_start = self.line_for_node(dec_node)
            if last is not None and dec_start != last:
                self.add_arc(last, dec_start)
            last = dec_start
        if env.PYBEHAVIOR.trace_decorated_def:
            self.add_arc(last, main_line)
            last = main_line
        if env.PYBEHAVIOR.trace_decorator_line_again:
            for top, bot in zip(decs, decs[1:]):
                self.add_arc(self.line_for_node(bot), self.line_for_node(top))
            self.add_arc(self.line_for_node(decs[0]), main_line)
            self.add_arc(main_line, self.line_for_node(decs[-1]))
        # The definition line may have been missed, but we should have it
        # in `self.statements`.  For some constructs, `line_for_node` is
        # not what we'd think of as the first line in the statement, so map
        # it to the first one.
        if node.body:
            body_start = self.line_for_node(node.body[0])
            body_start = self.multiline.get(body_start, body_start)
            for lineno in range(last+1, body_start):
                if lineno in self.statements:
                    self.add_arc(last, lineno)
                    last = lineno
    # The body is handled in collect_arcs.
    return {ArcStart(last)}

</t>
<t tx="ekr.20221020070914.456">_handle__ClassDef = _handle_decorated

</t>
<t tx="ekr.20221020070914.457">@contract(returns='ArcStarts')
def _handle__Continue(self, node):
    here = self.line_for_node(node)
    continue_start = ArcStart(here, cause="the continue on line {lineno} wasn't executed")
    self.process_continue_exits([continue_start])
    return set()

</t>
<t tx="ekr.20221020070914.458">@contract(returns='ArcStarts')
def _handle__For(self, node):
    start = self.line_for_node(node.iter)
    self.block_stack.append(LoopBlock(start=start))
    from_start = ArcStart(start, cause="the loop on line {lineno} never started")
    exits = self.add_body_arcs(node.body, from_start=from_start)
    # Any exit from the body will go back to the top of the loop.
    for xit in exits:
        self.add_arc(xit.lineno, start, xit.cause)
    my_block = self.block_stack.pop()
    exits = my_block.break_exits
    from_start = ArcStart(start, cause="the loop on line {lineno} didn't complete")
    if node.orelse:
        else_exits = self.add_body_arcs(node.orelse, from_start=from_start)
        exits |= else_exits
    else:
        # No else clause: exit from the for line.
        exits.add(from_start)
    return exits

</t>
<t tx="ekr.20221020070914.459">_handle__AsyncFor = _handle__For

_handle__FunctionDef = _handle_decorated
_handle__AsyncFunctionDef = _handle_decorated

</t>
<t tx="ekr.20221020070914.46"># The trace function has to be set individually on each thread before
# execution begins.  Ironically, the only support the threading module has
# for running code before the thread main is the tracing function.  So we
# install this as a trace function, and the first time it's called, it does
# the real trace installation.
#
# New in 3.12: threading.settrace_all_threads: https://github.com/python/cpython/pull/96681

</t>
<t tx="ekr.20221020070914.460">@contract(returns='ArcStarts')
def _handle__If(self, node):
    start = self.line_for_node(node.test)
    from_start = ArcStart(start, cause="the condition on line {lineno} was never true")
    exits = self.add_body_arcs(node.body, from_start=from_start)
    from_start = ArcStart(start, cause="the condition on line {lineno} was never false")
    exits |= self.add_body_arcs(node.orelse, from_start=from_start)
    return exits

</t>
<t tx="ekr.20221020070914.461">@contract(returns='ArcStarts')
def _handle__Match(self, node):
    start = self.line_for_node(node)
    last_start = start
    exits = set()
    had_wildcard = False
    for case in node.cases:
        case_start = self.line_for_node(case.pattern)
        if isinstance(case.pattern, ast.MatchAs):
            had_wildcard = True
        self.add_arc(last_start, case_start, "the pattern on line {lineno} always matched")
        from_start = ArcStart(case_start, cause="the pattern on line {lineno} never matched")
        exits |= self.add_body_arcs(case.body, from_start=from_start)
        last_start = case_start
    if not had_wildcard:
        exits.add(from_start)
    return exits

</t>
<t tx="ekr.20221020070914.462">@contract(returns='ArcStarts')
def _handle__NodeList(self, node):
    start = self.line_for_node(node)
    exits = self.add_body_arcs(node.body, from_start=ArcStart(start))
    return exits

</t>
<t tx="ekr.20221020070914.463">@contract(returns='ArcStarts')
def _handle__Raise(self, node):
    here = self.line_for_node(node)
    raise_start = ArcStart(here, cause="the raise on line {lineno} wasn't executed")
    self.process_raise_exits([raise_start])
    # `raise` statement jumps away, no exits from here.
    return set()

</t>
<t tx="ekr.20221020070914.464">@contract(returns='ArcStarts')
def _handle__Return(self, node):
    here = self.line_for_node(node)
    return_start = ArcStart(here, cause="the return on line {lineno} wasn't executed")
    self.process_return_exits([return_start])
    # `return` statement jumps away, no exits from here.
    return set()

</t>
<t tx="ekr.20221020070914.465">@contract(returns='ArcStarts')
def _handle__Try(self, node):
    if node.handlers:
        handler_start = self.line_for_node(node.handlers[0])
    else:
        handler_start = None

    if node.finalbody:
        final_start = self.line_for_node(node.finalbody[0])
    else:
        final_start = None

    # This is true by virtue of Python syntax: have to have either except
    # or finally, or both.
    assert handler_start is not None or final_start is not None
    try_block = TryBlock(handler_start, final_start)
    self.block_stack.append(try_block)

    start = self.line_for_node(node)
    exits = self.add_body_arcs(node.body, from_start=ArcStart(start))

    # We're done with the `try` body, so this block no longer handles
    # exceptions. We keep the block so the `finally` clause can pick up
    # flows from the handlers and `else` clause.
    if node.finalbody:
        try_block.handler_start = None
        if node.handlers:
            # If there are `except` clauses, then raises in the try body
            # will already jump to them.  Start this set over for raises in
            # `except` and `else`.
            try_block.raise_from = set()
    else:
        self.block_stack.pop()

    handler_exits = set()

    if node.handlers:
        last_handler_start = None
        for handler_node in node.handlers:
            handler_start = self.line_for_node(handler_node)
            if last_handler_start is not None:
                self.add_arc(last_handler_start, handler_start)
            last_handler_start = handler_start
            from_cause = "the exception caught by line {lineno} didn't happen"
            from_start = ArcStart(handler_start, cause=from_cause)
            handler_exits |= self.add_body_arcs(handler_node.body, from_start=from_start)

    if node.orelse:
        exits = self.add_body_arcs(node.orelse, prev_starts=exits)

    exits |= handler_exits

    if node.finalbody:
        self.block_stack.pop()
        final_from = (                  # You can get to the `finally` clause from:
            exits |                         # the exits of the body or `else` clause,
            try_block.break_from |          # or a `break`,
            try_block.continue_from |       # or a `continue`,
            try_block.raise_from |          # or a `raise`,
            try_block.return_from           # or a `return`.
        )

        final_exits = self.add_body_arcs(node.finalbody, prev_starts=final_from)

        if try_block.break_from:
            if env.PYBEHAVIOR.finally_jumps_back:
                for break_line in try_block.break_from:
                    lineno = break_line.lineno
                    cause = break_line.cause.format(lineno=lineno)
                    for final_exit in final_exits:
                        self.add_arc(final_exit.lineno, lineno, cause)
                breaks = try_block.break_from
            else:
                breaks = self._combine_finally_starts(try_block.break_from, final_exits)
            self.process_break_exits(breaks)

        if try_block.continue_from:
            if env.PYBEHAVIOR.finally_jumps_back:
                for continue_line in try_block.continue_from:
                    lineno = continue_line.lineno
                    cause = continue_line.cause.format(lineno=lineno)
                    for final_exit in final_exits:
                        self.add_arc(final_exit.lineno, lineno, cause)
                continues = try_block.continue_from
            else:
                continues = self._combine_finally_starts(try_block.continue_from, final_exits)
            self.process_continue_exits(continues)

        if try_block.raise_from:
            self.process_raise_exits(
                self._combine_finally_starts(try_block.raise_from, final_exits)
            )

        if try_block.return_from:
            if env.PYBEHAVIOR.finally_jumps_back:
                for return_line in try_block.return_from:
                    lineno = return_line.lineno
                    cause = return_line.cause.format(lineno=lineno)
                    for final_exit in final_exits:
                        self.add_arc(final_exit.lineno, lineno, cause)
                returns = try_block.return_from
            else:
                returns = self._combine_finally_starts(try_block.return_from, final_exits)
            self.process_return_exits(returns)

        if exits:
            # The finally clause's exits are only exits for the try block
            # as a whole if the try block had some exits to begin with.
            exits = final_exits

    return exits

</t>
<t tx="ekr.20221020070914.466">@contract(starts='ArcStarts', exits='ArcStarts', returns='ArcStarts')
def _combine_finally_starts(self, starts, exits):
    """Helper for building the cause of `finally` branches.

    "finally" clauses might not execute their exits, and the causes could
    be due to a failure to execute any of the exits in the try block. So
    we use the causes from `starts` as the causes for `exits`.
    """
    causes = []
    for start in sorted(starts):
        if start.cause is not None:
            causes.append(start.cause.format(lineno=start.lineno))
    cause = " or ".join(causes)
    exits = {ArcStart(xit.lineno, cause) for xit in exits}
    return exits

</t>
<t tx="ekr.20221020070914.467">@contract(returns='ArcStarts')
def _handle__While(self, node):
    start = to_top = self.line_for_node(node.test)
    constant_test = self.is_constant_expr(node.test)
    top_is_body0 = False
    if constant_test:
        top_is_body0 = True
    if env.PYBEHAVIOR.keep_constant_test:
        top_is_body0 = False
    if top_is_body0:
        to_top = self.line_for_node(node.body[0])
    self.block_stack.append(LoopBlock(start=to_top))
    from_start = ArcStart(start, cause="the condition on line {lineno} was never true")
    exits = self.add_body_arcs(node.body, from_start=from_start)
    for xit in exits:
        self.add_arc(xit.lineno, to_top, xit.cause)
    exits = set()
    my_block = self.block_stack.pop()
    exits.update(my_block.break_exits)
    from_start = ArcStart(start, cause="the condition on line {lineno} was never false")
    if node.orelse:
        else_exits = self.add_body_arcs(node.orelse, from_start=from_start)
        exits |= else_exits
    else:
        # No `else` clause: you can exit from the start.
        if not constant_test:
            exits.add(from_start)
    return exits

</t>
<t tx="ekr.20221020070914.468">@contract(returns='ArcStarts')
def _handle__With(self, node):
    start = self.line_for_node(node)
    if env.PYBEHAVIOR.exit_through_with:
        self.block_stack.append(WithBlock(start=start))
    exits = self.add_body_arcs(node.body, from_start=ArcStart(start))
    if env.PYBEHAVIOR.exit_through_with:
        with_block = self.block_stack.pop()
        with_exit = {ArcStart(start)}
        if exits:
            for xit in exits:
                self.add_arc(xit.lineno, start)
            exits = with_exit
        if with_block.break_from:
            self.process_break_exits(
                self._combine_finally_starts(with_block.break_from, with_exit)
            )
        if with_block.continue_from:
            self.process_continue_exits(
                self._combine_finally_starts(with_block.continue_from, with_exit)
            )
        if with_block.return_from:
            self.process_return_exits(
                self._combine_finally_starts(with_block.return_from, with_exit)
            )
    return exits

</t>
<t tx="ekr.20221020070914.469">_handle__AsyncWith = _handle__With

# Code object dispatchers: _code_object__*
#
# These methods are used by analyze() as the start of the analysis.
# There is one for each construct with a code object.

</t>
<t tx="ekr.20221020070914.47">def _installation_trace(self, frame, event, arg):
    """Called on new threads, installs the real tracer."""
    # Remove ourselves as the trace function.
    sys.settrace(None)
    # Install the real tracer.
    fn = self._start_tracer()
    # Invoke the real trace function with the current event, to be sure
    # not to lose an event.
    if fn:
        fn = fn(frame, event, arg)
    # Return the new trace function to continue tracing in this scope.
    return fn

</t>
<t tx="ekr.20221020070914.470">def _code_object__Module(self, node):
    start = self.line_for_node(node)
    if node.body:
        exits = self.add_body_arcs(node.body, from_start=ArcStart(-start))
        for xit in exits:
            self.add_arc(xit.lineno, -start, xit.cause, "didn't exit the module")
    else:
        # Empty module.
        self.add_arc(-start, start)
        self.add_arc(start, -start)

</t>
<t tx="ekr.20221020070914.471">def _code_object__FunctionDef(self, node):
    start = self.line_for_node(node)
    self.block_stack.append(FunctionBlock(start=start, name=node.name))
    exits = self.add_body_arcs(node.body, from_start=ArcStart(-start))
    self.process_return_exits(exits)
    self.block_stack.pop()

</t>
<t tx="ekr.20221020070914.472">_code_object__AsyncFunctionDef = _code_object__FunctionDef

</t>
<t tx="ekr.20221020070914.473">def _code_object__ClassDef(self, node):
    start = self.line_for_node(node)
    self.add_arc(-start, start)
    exits = self.add_body_arcs(node.body, from_start=ArcStart(start))
    for xit in exits:
        self.add_arc(
            xit.lineno, -start, xit.cause,
            f"didn't exit the body of class {node.name!r}",
        )

</t>
<t tx="ekr.20221020070914.474">def _make_expression_code_method(noun):                     # pylint: disable=no-self-argument
    """A function to make methods for expression-based callable _code_object__ methods."""
    def _code_object__expression_callable(self, node):
        start = self.line_for_node(node)
        self.add_arc(-start, start, None, f"didn't run the {noun} on line {start}")
        self.add_arc(start, -start, None, f"didn't finish the {noun} on line {start}")
    return _code_object__expression_callable

</t>
<t tx="ekr.20221020070914.475"># Code only used when dumping the AST for debugging.

SKIP_DUMP_FIELDS = ["ctx"]

</t>
<t tx="ekr.20221020070914.476">def _is_simple_value(value):
    """Is `value` simple enough to be displayed on a single line?"""
    return (
        value in [None, [], (), {}, set()] or
        isinstance(value, (bytes, int, float, str))
    )

</t>
<t tx="ekr.20221020070914.477">def ast_dump(node, depth=0, print=print):   # pylint: disable=redefined-builtin
    """Dump the AST for `node`.

    This recursively walks the AST, printing a readable version.

    """
    indent = " " * depth
    lineno = getattr(node, "lineno", None)
    if lineno is not None:
        linemark = f" @ {node.lineno},{node.col_offset}"
        if hasattr(node, "end_lineno"):
            linemark += ":"
            if node.end_lineno != node.lineno:
                linemark += f"{node.end_lineno},"
            linemark += f"{node.end_col_offset}"
    else:
        linemark = ""
    head = f"{indent}&lt;{node.__class__.__name__}{linemark}"

    named_fields = [
        (name, value)
        for name, value in ast.iter_fields(node)
        if name not in SKIP_DUMP_FIELDS
    ]
    if not named_fields:
        print(f"{head}&gt;")
    elif len(named_fields) == 1 and _is_simple_value(named_fields[0][1]):
        field_name, value = named_fields[0]
        print(f"{head} {field_name}: {value!r}&gt;")
    else:
        print(head)
        if 0:
            print("{}# mro: {}".format(
                indent, ", ".join(c.__name__ for c in node.__class__.__mro__[1:]),
            ))
        next_indent = indent + "    "
        for field_name, value in named_fields:
            prefix = f"{next_indent}{field_name}:"
            if _is_simple_value(value):
                print(f"{prefix} {value!r}")
            elif isinstance(value, list):
                print(f"{prefix} [")
                for n in value:
                    if _is_simple_value(n):
                        print(f"{next_indent}    {n!r}")
                    else:
                        ast_dump(n, depth + 8, print=print)
                print(f"{next_indent}]")
            else:
                print(prefix)
                ast_dump(value, depth + 8, print=print)

        print(f"{indent}&gt;")
</t>
<t tx="ekr.20221020070914.478">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Better tokenizing for coverage.py."""

import ast
import keyword
import re
import token
import tokenize

from coverage import env
from coverage.misc import contract


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.479">def phys_tokens(toks):
    """Return all physical tokens, even line continuations.

    tokenize.generate_tokens() doesn't return a token for the backslash that
    continues lines.  This wrapper provides those tokens so that we can
    re-create a faithful representation of the original source.

    Returns the same values as generate_tokens()

    """
    last_line = None
    last_lineno = -1
    last_ttext = None
    for ttype, ttext, (slineno, scol), (elineno, ecol), ltext in toks:
        if last_lineno != elineno:
            if last_line and last_line.endswith("\\\n"):
                # We are at the beginning of a new line, and the last line
                # ended with a backslash.  We probably have to inject a
                # backslash token into the stream. Unfortunately, there's more
                # to figure out.  This code::
                #
                #   usage = """\
                #   HEY THERE
                #   """
                #
                # triggers this condition, but the token text is::
                #
                #   '"""\\\nHEY THERE\n"""'
                #
                # so we need to figure out if the backslash is already in the
                # string token or not.
                inject_backslash = True
                if last_ttext.endswith("\\"):
                    inject_backslash = False
                elif ttype == token.STRING:
                    if "\n" in ttext and ttext.split('\n', 1)[0][-1] == '\\':
                        # It's a multi-line string and the first line ends with
                        # a backslash, so we don't need to inject another.
                        inject_backslash = False
                if inject_backslash:
                    # Figure out what column the backslash is in.
                    ccol = len(last_line.split("\n")[-2]) - 1
                    # Yield the token, with a fake token type.
                    yield (
                        99999, "\\\n",
                        (slineno, ccol), (slineno, ccol+2),
                        last_line
                    )
            last_line = ltext
        if ttype not in (tokenize.NEWLINE, tokenize.NL):
            last_ttext = ttext
        yield ttype, ttext, (slineno, scol), (elineno, ecol), ltext
        last_lineno = elineno


</t>
<t tx="ekr.20221020070914.48">def start(self):
    """Start collecting trace information."""
    if self._collectors:
        self._collectors[-1].pause()

    self.tracers = []

    # Check to see whether we had a fullcoverage tracer installed. If so,
    # get the stack frames it stashed away for us.
    traces0 = []
    fn0 = sys.gettrace()
    if fn0:
        tracer0 = getattr(fn0, '__self__', None)
        if tracer0:
            traces0 = getattr(tracer0, 'traces', [])

    try:
        # Install the tracer on this thread.
        fn = self._start_tracer()
    except:
        if self._collectors:
            self._collectors[-1].resume()
        raise

    # If _start_tracer succeeded, then we add ourselves to the global
    # stack of collectors.
    self._collectors.append(self)

    # Replay all the events from fullcoverage into the new trace function.
    for (frame, event, arg), lineno in traces0:
        try:
            fn(frame, event, arg, lineno=lineno)
        except TypeError as ex:
            raise Exception("fullcoverage must be run with the C trace function.") from ex

    # Install our installation tracer in threading, to jump-start other
    # threads.
    if self.threading:
        self.threading.settrace(self._installation_trace)

</t>
<t tx="ekr.20221020070914.480">class MatchCaseFinder(ast.NodeVisitor):
    """Helper for finding match/case lines."""
    @others
</t>
<t tx="ekr.20221020070914.481">def __init__(self, source):
    # This will be the set of line numbers that start match or case statements.
    self.match_case_lines = set()
    self.visit(ast.parse(source))

</t>
<t tx="ekr.20221020070914.482">def visit_Match(self, node):
    """Invoked by ast.NodeVisitor.visit"""
    self.match_case_lines.add(node.lineno)
    for case in node.cases:
        self.match_case_lines.add(case.pattern.lineno)
    self.generic_visit(node)


</t>
<t tx="ekr.20221020070914.483">@contract(source='unicode')
def source_token_lines(source):
    """Generate a series of lines, one for each line in `source`.

    Each line is a list of pairs, each pair is a token::

        [('key', 'def'), ('ws', ' '), ('nam', 'hello'), ('op', '('), ... ]

    Each pair has a token class, and the token text.

    If you concatenate all the token texts, and then join them with newlines,
    you should have your original `source` back, with two differences:
    trailing whitespace is not preserved, and a final line with no newline
    is indistinguishable from a final line with a newline.

    """

    ws_tokens = {token.INDENT, token.DEDENT, token.NEWLINE, tokenize.NL}
    line = []
    col = 0

    source = source.expandtabs(8).replace('\r\n', '\n')
    tokgen = generate_tokens(source)

    if env.PYBEHAVIOR.soft_keywords:
        match_case_lines = MatchCaseFinder(source).match_case_lines

    for ttype, ttext, (sline, scol), (_, ecol), _ in phys_tokens(tokgen):
        mark_start = True
        for part in re.split('(\n)', ttext):
            if part == '\n':
                yield line
                line = []
                col = 0
                mark_end = False
            elif part == '':
                mark_end = False
            elif ttype in ws_tokens:
                mark_end = False
            else:
                if mark_start and scol &gt; col:
                    line.append(("ws", " " * (scol - col)))
                    mark_start = False
                tok_class = tokenize.tok_name.get(ttype, 'xx').lower()[:3]
                if ttype == token.NAME:
                    if keyword.iskeyword(ttext):
                        # Hard keywords are always keywords.
                        tok_class = "key"
                    elif env.PYBEHAVIOR.soft_keywords and keyword.issoftkeyword(ttext):
                        # Soft keywords appear at the start of the line, on lines that start
                        # match or case statements.
                        if len(line) == 0:
                            is_start_of_line = True
                        elif (len(line) == 1) and line[0][0] == "ws":
                            is_start_of_line = True
                        else:
                            is_start_of_line = False
                        if is_start_of_line and sline in match_case_lines:
                            tok_class = "key"
                line.append((tok_class, part))
                mark_end = True
            scol = 0
        if mark_end:
            col = ecol

    if line:
        yield line


</t>
<t tx="ekr.20221020070914.484">class CachedTokenizer:
    """A one-element cache around tokenize.generate_tokens.

    When reporting, coverage.py tokenizes files twice, once to find the
    structure of the file, and once to syntax-color it.  Tokenizing is
    expensive, and easily cached.

    This is a one-element cache so that our twice-in-a-row tokenizing doesn't
    actually tokenize twice.

    """
    @others
</t>
<t tx="ekr.20221020070914.485">def __init__(self):
    self.last_text = None
    self.last_tokens = None

</t>
<t tx="ekr.20221020070914.486">@contract(text='unicode')
def generate_tokens(self, text):
    """A stand-in for `tokenize.generate_tokens`."""
    if text != self.last_text:
        self.last_text = text
        readline = iter(text.splitlines(True)).__next__
        try:
            self.last_tokens = list(tokenize.generate_tokens(readline))
        except:
            self.last_text = None
            raise
    return self.last_tokens

</t>
<t tx="ekr.20221020070914.487"># Create our generate_tokens cache as a callable replacement function.
generate_tokens = CachedTokenizer().generate_tokens


COOKIE_RE = re.compile(r"^[ \t]*#.*coding[:=][ \t]*([-\w.]+)", flags=re.MULTILINE)

</t>
<t tx="ekr.20221020070914.488">@contract(source='bytes')
def source_encoding(source):
    """Determine the encoding for `source`, according to PEP 263.

    `source` is a byte string: the text of the program.

    Returns a string, the name of the encoding.

    """
    readline = iter(source.splitlines(True)).__next__
    return tokenize.detect_encoding(readline)[0]


</t>
<t tx="ekr.20221020070914.489">@contract(source='unicode')
def compile_unicode(source, filename, mode):
    """Just like the `compile` builtin, but works on any Unicode string.

    Python 2's compile() builtin has a stupid restriction: if the source string
    is Unicode, then it may not have a encoding declaration in it.  Why not?
    Who knows!  It also decodes to utf-8, and then tries to interpret those
    utf-8 bytes according to the encoding declaration.  Why? Who knows!

    This function neuters the coding declaration, and compiles it.

    """
    source = neuter_encoding_declaration(source)
    code = compile(source, filename, mode)
    return code


</t>
<t tx="ekr.20221020070914.49">def stop(self):
    """Stop collecting trace information."""
    assert self._collectors
    if self._collectors[-1] is not self:
        print("self._collectors:")
        for c in self._collectors:
            print(f"  {c!r}\n{c.origin}")
    assert self._collectors[-1] is self, (
        f"Expected current collector to be {self!r}, but it's {self._collectors[-1]!r}"
    )

    self.pause()

    # Remove this Collector from the stack, and resume the one underneath
    # (if any).
    self._collectors.pop()
    if self._collectors:
        self._collectors[-1].resume()

</t>
<t tx="ekr.20221020070914.490">@contract(source='unicode', returns='unicode')
def neuter_encoding_declaration(source):
    """Return `source`, with any encoding declaration neutered."""
    if COOKIE_RE.search(source):
        source_lines = source.splitlines(True)
        for lineno in range(min(2, len(source_lines))):
            source_lines[lineno] = COOKIE_RE.sub("# (deleted declaration)", source_lines[lineno])
        source = "".join(source_lines)
    return source
</t>
<t tx="ekr.20221020070914.491">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""
.. versionadded:: 4.0

Plug-in interfaces for coverage.py.

Coverage.py supports a few different kinds of plug-ins that change its
behavior:

* File tracers implement tracing of non-Python file types.

* Configurers add custom configuration, using Python code to change the
  configuration.

* Dynamic context switchers decide when the dynamic context has changed, for
  example, to record what test function produced the coverage.

To write a coverage.py plug-in, create a module with a subclass of
:class:`~coverage.CoveragePlugin`.  You will override methods in your class to
participate in various aspects of coverage.py's processing.
Different types of plug-ins have to override different methods.

Any plug-in can optionally implement :meth:`~coverage.CoveragePlugin.sys_info`
to provide debugging information about their operation.

Your module must also contain a ``coverage_init`` function that registers an
instance of your plug-in class::

    import coverage

    class MyPlugin(coverage.CoveragePlugin):
        ...

    def coverage_init(reg, options):
        reg.add_file_tracer(MyPlugin())

You use the `reg` parameter passed to your ``coverage_init`` function to
register your plug-in object.  The registration method you call depends on
what kind of plug-in it is.

If your plug-in takes options, the `options` parameter is a dictionary of your
plug-in's options from the coverage.py configuration file.  Use them however
you want to configure your object before registering it.

Coverage.py will store its own information on your plug-in object, using
attributes whose names start with ``_coverage_``.  Don't be startled.

.. warning::
    Plug-ins are imported by coverage.py before it begins measuring code.
    If you write a plugin in your own project, it might import your product
    code before coverage.py can start measuring.  This can result in your
    own code being reported as missing.

    One solution is to put your plugins in your project tree, but not in
    your importable Python package.


.. _file_tracer_plugins:

File Tracers
============

File tracers implement measurement support for non-Python files.  File tracers
implement the :meth:`~coverage.CoveragePlugin.file_tracer` method to claim
files and the :meth:`~coverage.CoveragePlugin.file_reporter` method to report
on those files.

In your ``coverage_init`` function, use the ``add_file_tracer`` method to
register your file tracer.


.. _configurer_plugins:

Configurers
===========

.. versionadded:: 4.5

Configurers modify the configuration of coverage.py during start-up.
Configurers implement the :meth:`~coverage.CoveragePlugin.configure` method to
change the configuration.

In your ``coverage_init`` function, use the ``add_configurer`` method to
register your configurer.


.. _dynamic_context_plugins:

Dynamic Context Switchers
=========================

.. versionadded:: 5.0

Dynamic context switcher plugins implement the
:meth:`~coverage.CoveragePlugin.dynamic_context` method to dynamically compute
the context label for each measured frame.

Computed context labels are useful when you want to group measured data without
modifying the source code.

For example, you could write a plugin that checks `frame.f_code` to inspect
the currently executed method, and set the context label to a fully qualified
method name if it's an instance method of `unittest.TestCase` and the method
name starts with 'test'.  Such a plugin would provide basic coverage grouping
by test and could be used with test runners that have no built-in coveragepy
support.

In your ``coverage_init`` function, use the ``add_dynamic_context`` method to
register your dynamic context switcher.

"""

import functools

from coverage import files
from coverage.misc import contract, _needs_to_implement


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.492">class CoveragePlugin:
    """Base class for coverage.py plug-ins."""

    @others
</t>
<t tx="ekr.20221020070914.493">def file_tracer(self, filename):        # pylint: disable=unused-argument
    """Get a :class:`FileTracer` object for a file.

    Plug-in type: file tracer.

    Every Python source file is offered to your plug-in to give it a chance
    to take responsibility for tracing the file.  If your plug-in can
    handle the file, it should return a :class:`FileTracer` object.
    Otherwise return None.

    There is no way to register your plug-in for particular files.
    Instead, this method is invoked for all  files as they are executed,
    and the plug-in decides whether it can trace the file or not.
    Be prepared for `filename` to refer to all kinds of files that have
    nothing to do with your plug-in.

    The file name will be a Python file being executed.  There are two
    broad categories of behavior for a plug-in, depending on the kind of
    files your plug-in supports:

    * Static file names: each of your original source files has been
      converted into a distinct Python file.  Your plug-in is invoked with
      the Python file name, and it maps it back to its original source
      file.

    * Dynamic file names: all of your source files are executed by the same
      Python file.  In this case, your plug-in implements
      :meth:`FileTracer.dynamic_source_filename` to provide the actual
      source file for each execution frame.

    `filename` is a string, the path to the file being considered.  This is
    the absolute real path to the file.  If you are comparing to other
    paths, be sure to take this into account.

    Returns a :class:`FileTracer` object to use to trace `filename`, or
    None if this plug-in cannot trace this file.

    """
    return None

</t>
<t tx="ekr.20221020070914.494">def file_reporter(self, filename):      # pylint: disable=unused-argument
    """Get the :class:`FileReporter` class to use for a file.

    Plug-in type: file tracer.

    This will only be invoked if `filename` returns non-None from
    :meth:`file_tracer`.  It's an error to return None from this method.

    Returns a :class:`FileReporter` object to use to report on `filename`,
    or the string `"python"` to have coverage.py treat the file as Python.

    """
    _needs_to_implement(self, "file_reporter")

</t>
<t tx="ekr.20221020070914.495">def dynamic_context(self, frame):       # pylint: disable=unused-argument
    """Get the dynamically computed context label for `frame`.

    Plug-in type: dynamic context.

    This method is invoked for each frame when outside of a dynamic
    context, to see if a new dynamic context should be started.  If it
    returns a string, a new context label is set for this and deeper
    frames.  The dynamic context ends when this frame returns.

    Returns a string to start a new dynamic context, or None if no new
    context should be started.

    """
    return None

</t>
<t tx="ekr.20221020070914.496">def find_executable_files(self, src_dir):       # pylint: disable=unused-argument
    """Yield all of the executable files in `src_dir`, recursively.

    Plug-in type: file tracer.

    Executability is a plug-in-specific property, but generally means files
    which would have been considered for coverage analysis, had they been
    included automatically.

    Returns or yields a sequence of strings, the paths to files that could
    have been executed, including files that had been executed.

    """
    return []

</t>
<t tx="ekr.20221020070914.497">def configure(self, config):
    """Modify the configuration of coverage.py.

    Plug-in type: configurer.

    This method is called during coverage.py start-up, to give your plug-in
    a chance to change the configuration.  The `config` parameter is an
    object with :meth:`~coverage.Coverage.get_option` and
    :meth:`~coverage.Coverage.set_option` methods.  Do not call any other
    methods on the `config` object.

    """
    pass

</t>
<t tx="ekr.20221020070914.498">def sys_info(self):
    """Get a list of information useful for debugging.

    Plug-in type: any.

    This method will be invoked for ``--debug=sys``.  Your
    plug-in can return any information it wants to be displayed.

    Returns a list of pairs: `[(name, value), ...]`.

    """
    return []


</t>
<t tx="ekr.20221020070914.499">class FileTracer:
    """Support needed for files during the execution phase.

    File tracer plug-ins implement subclasses of FileTracer to return from
    their :meth:`~CoveragePlugin.file_tracer` method.

    You may construct this object from :meth:`CoveragePlugin.file_tracer` any
    way you like.  A natural choice would be to pass the file name given to
    `file_tracer`.

    `FileTracer` objects should only be created in the
    :meth:`CoveragePlugin.file_tracer` method.

    See :ref:`howitworks` for details of the different coverage.py phases.

    """

    @others
</t>
<t tx="ekr.20221020070914.5">blank_re = re.compile(r"\s*(#|$)")
else_re = re.compile(r"\s*else\s*:\s*(#|$)")

</t>
<t tx="ekr.20221020070914.50">def pause(self):
    """Pause tracing, but be prepared to `resume`."""
    for tracer in self.tracers:
        tracer.stop()
        stats = tracer.get_stats()
        if stats:
            print("\nCoverage.py tracer stats:")
            for k in human_sorted(stats.keys()):
                print(f"{k:&gt;20}: {stats[k]}")
    if self.threading:
        self.threading.settrace(None)

</t>
<t tx="ekr.20221020070914.500">def source_filename(self):
    """The source file name for this file.

    This may be any file name you like.  A key responsibility of a plug-in
    is to own the mapping from Python execution back to whatever source
    file name was originally the source of the code.

    See :meth:`CoveragePlugin.file_tracer` for details about static and
    dynamic file names.

    Returns the file name to credit with this execution.

    """
    _needs_to_implement(self, "source_filename")

</t>
<t tx="ekr.20221020070914.501">def has_dynamic_source_filename(self):
    """Does this FileTracer have dynamic source file names?

    FileTracers can provide dynamically determined file names by
    implementing :meth:`dynamic_source_filename`.  Invoking that function
    is expensive. To determine whether to invoke it, coverage.py uses the
    result of this function to know if it needs to bother invoking
    :meth:`dynamic_source_filename`.

    See :meth:`CoveragePlugin.file_tracer` for details about static and
    dynamic file names.

    Returns True if :meth:`dynamic_source_filename` should be called to get
    dynamic source file names.

    """
    return False

</t>
<t tx="ekr.20221020070914.502">def dynamic_source_filename(self, filename, frame):     # pylint: disable=unused-argument
    """Get a dynamically computed source file name.

    Some plug-ins need to compute the source file name dynamically for each
    frame.

    This function will not be invoked if
    :meth:`has_dynamic_source_filename` returns False.

    Returns the source file name for this frame, or None if this frame
    shouldn't be measured.

    """
    return None

</t>
<t tx="ekr.20221020070914.503">def line_number_range(self, frame):
    """Get the range of source line numbers for a given a call frame.

    The call frame is examined, and the source line number in the original
    file is returned.  The return value is a pair of numbers, the starting
    line number and the ending line number, both inclusive.  For example,
    returning (5, 7) means that lines 5, 6, and 7 should be considered
    executed.

    This function might decide that the frame doesn't indicate any lines
    from the source file were executed.  Return (-1, -1) in this case to
    tell coverage.py that no lines should be recorded for this frame.

    """
    lineno = frame.f_lineno
    return lineno, lineno


</t>
<t tx="ekr.20221020070914.504">@functools.total_ordering
class FileReporter:
    """Support needed for files during the analysis and reporting phases.

    File tracer plug-ins implement a subclass of `FileReporter`, and return
    instances from their :meth:`CoveragePlugin.file_reporter` method.

    There are many methods here, but only :meth:`lines` is required, to provide
    the set of executable lines in the file.

    See :ref:`howitworks` for details of the different coverage.py phases.

    """

    @others
    __hash__ = None     # This object doesn't need to be hashed.
</t>
<t tx="ekr.20221020070914.505">def __init__(self, filename):
    """Simple initialization of a `FileReporter`.

    The `filename` argument is the path to the file being reported.  This
    will be available as the `.filename` attribute on the object.  Other
    method implementations on this base class rely on this attribute.

    """
    self.filename = filename

</t>
<t tx="ekr.20221020070914.506">def __repr__(self):
    return "&lt;{0.__class__.__name__} filename={0.filename!r}&gt;".format(self)

</t>
<t tx="ekr.20221020070914.507">def relative_filename(self):
    """Get the relative file name for this file.

    This file path will be displayed in reports.  The default
    implementation will supply the actual project-relative file path.  You
    only need to supply this method if you have an unusual syntax for file
    paths.

    """
    return files.relative_filename(self.filename)

</t>
<t tx="ekr.20221020070914.508">@contract(returns='unicode')
def source(self):
    """Get the source for the file.

    Returns a Unicode string.

    The base implementation simply reads the `self.filename` file and
    decodes it as UTF-8.  Override this method if your file isn't readable
    as a text file, or if you need other encoding support.

    """
    with open(self.filename, "rb") as f:
        return f.read().decode("utf-8")

</t>
<t tx="ekr.20221020070914.509">def lines(self):
    """Get the executable lines in this file.

    Your plug-in must determine which lines in the file were possibly
    executable.  This method returns a set of those line numbers.

    Returns a set of line numbers.

    """
    _needs_to_implement(self, "lines")

</t>
<t tx="ekr.20221020070914.51">def resume(self):
    """Resume tracing after a `pause`."""
    for tracer in self.tracers:
        tracer.start()
    if self.threading:
        self.threading.settrace(self._installation_trace)
    else:
        self._start_tracer()

</t>
<t tx="ekr.20221020070914.510">def excluded_lines(self):
    """Get the excluded executable lines in this file.

    Your plug-in can use any method it likes to allow the user to exclude
    executable lines from consideration.

    Returns a set of line numbers.

    The base implementation returns the empty set.

    """
    return set()

</t>
<t tx="ekr.20221020070914.511">def translate_lines(self, lines):
    """Translate recorded lines into reported lines.

    Some file formats will want to report lines slightly differently than
    they are recorded.  For example, Python records the last line of a
    multi-line statement, but reports are nicer if they mention the first
    line.

    Your plug-in can optionally define this method to perform these kinds
    of adjustment.

    `lines` is a sequence of integers, the recorded line numbers.

    Returns a set of integers, the adjusted line numbers.

    The base implementation returns the numbers unchanged.

    """
    return set(lines)

</t>
<t tx="ekr.20221020070914.512">def arcs(self):
    """Get the executable arcs in this file.

    To support branch coverage, your plug-in needs to be able to indicate
    possible execution paths, as a set of line number pairs.  Each pair is
    a `(prev, next)` pair indicating that execution can transition from the
    `prev` line number to the `next` line number.

    Returns a set of pairs of line numbers.  The default implementation
    returns an empty set.

    """
    return set()

</t>
<t tx="ekr.20221020070914.513">def no_branch_lines(self):
    """Get the lines excused from branch coverage in this file.

    Your plug-in can use any method it likes to allow the user to exclude
    lines from consideration of branch coverage.

    Returns a set of line numbers.

    The base implementation returns the empty set.

    """
    return set()

</t>
<t tx="ekr.20221020070914.514">def translate_arcs(self, arcs):
    """Translate recorded arcs into reported arcs.

    Similar to :meth:`translate_lines`, but for arcs.  `arcs` is a set of
    line number pairs.

    Returns a set of line number pairs.

    The default implementation returns `arcs` unchanged.

    """
    return arcs

</t>
<t tx="ekr.20221020070914.515">def exit_counts(self):
    """Get a count of exits from that each line.

    To determine which lines are branches, coverage.py looks for lines that
    have more than one exit.  This function creates a dict mapping each
    executable line number to a count of how many exits it has.

    To be honest, this feels wrong, and should be refactored.  Let me know
    if you attempt to implement this method in your plug-in...

    """
    return {}

</t>
<t tx="ekr.20221020070914.516">def missing_arc_description(self, start, end, executed_arcs=None):     # pylint: disable=unused-argument
    """Provide an English sentence describing a missing arc.

    The `start` and `end` arguments are the line numbers of the missing
    arc. Negative numbers indicate entering or exiting code objects.

    The `executed_arcs` argument is a set of line number pairs, the arcs
    that were executed in this file.

    By default, this simply returns the string "Line {start} didn't jump
    to {end}".

    """
    return f"Line {start} didn't jump to line {end}"

</t>
<t tx="ekr.20221020070914.517">def source_token_lines(self):
    """Generate a series of tokenized lines, one for each line in `source`.

    These tokens are used for syntax-colored reports.

    Each line is a list of pairs, each pair is a token::

        [('key', 'def'), ('ws', ' '), ('nam', 'hello'), ('op', '('), ... ]

    Each pair has a token class, and the token text.  The token classes
    are:

    * ``'com'``: a comment
    * ``'key'``: a keyword
    * ``'nam'``: a name, or identifier
    * ``'num'``: a number
    * ``'op'``: an operator
    * ``'str'``: a string literal
    * ``'ws'``: some white space
    * ``'txt'``: some other kind of text

    If you concatenate all the token texts, and then join them with
    newlines, you should have your original source back.

    The default implementation simply returns each line tagged as
    ``'txt'``.

    """
    for line in self.source().splitlines():
        yield [('txt', line)]

</t>
<t tx="ekr.20221020070914.518">def __eq__(self, other):
    return isinstance(other, FileReporter) and self.filename == other.filename

</t>
<t tx="ekr.20221020070914.519">def __lt__(self, other):
    return isinstance(other, FileReporter) and self.filename &lt; other.filename

</t>
<t tx="ekr.20221020070914.52">def _activity(self):
    """Has any activity been traced?

    Returns a boolean, True if any trace function was invoked.

    """
    return any(tracer.activity() for tracer in self.tracers)

</t>
<t tx="ekr.20221020070914.520">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Support for plugins."""

import os
import os.path
import sys

from coverage.exceptions import PluginError
from coverage.misc import isolate_module
from coverage.plugin import CoveragePlugin, FileTracer, FileReporter

os = isolate_module(os)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.521">class Plugins:
    """The currently loaded collection of coverage.py plugins."""

    @others
</t>
<t tx="ekr.20221020070914.522">def __init__(self):
    self.order = []
    self.names = {}
    self.file_tracers = []
    self.configurers = []
    self.context_switchers = []

    self.current_module = None
    self.debug = None

</t>
<t tx="ekr.20221020070914.523">@classmethod
def load_plugins(cls, modules, config, debug=None):
    """Load plugins from `modules`.

    Returns a Plugins object with the loaded and configured plugins.

    """
    plugins = cls()
    plugins.debug = debug

    for module in modules:
        plugins.current_module = module
        __import__(module)
        mod = sys.modules[module]

        coverage_init = getattr(mod, "coverage_init", None)
        if not coverage_init:
            raise PluginError(
                f"Plugin module {module!r} didn't define a coverage_init function"
            )

        options = config.get_plugin_options(module)
        coverage_init(plugins, options)

    plugins.current_module = None
    return plugins

</t>
<t tx="ekr.20221020070914.524">def add_file_tracer(self, plugin):
    """Add a file tracer plugin.

    `plugin` is an instance of a third-party plugin class.  It must
    implement the :meth:`CoveragePlugin.file_tracer` method.

    """
    self._add_plugin(plugin, self.file_tracers)

</t>
<t tx="ekr.20221020070914.525">def add_configurer(self, plugin):
    """Add a configuring plugin.

    `plugin` is an instance of a third-party plugin class. It must
    implement the :meth:`CoveragePlugin.configure` method.

    """
    self._add_plugin(plugin, self.configurers)

</t>
<t tx="ekr.20221020070914.526">def add_dynamic_context(self, plugin):
    """Add a dynamic context plugin.

    `plugin` is an instance of a third-party plugin class.  It must
    implement the :meth:`CoveragePlugin.dynamic_context` method.

    """
    self._add_plugin(plugin, self.context_switchers)

</t>
<t tx="ekr.20221020070914.527">def add_noop(self, plugin):
    """Add a plugin that does nothing.

    This is only useful for testing the plugin support.

    """
    self._add_plugin(plugin, None)

</t>
<t tx="ekr.20221020070914.528">def _add_plugin(self, plugin, specialized):
    """Add a plugin object.

    `plugin` is a :class:`CoveragePlugin` instance to add.  `specialized`
    is a list to append the plugin to.

    """
    plugin_name = f"{self.current_module}.{plugin.__class__.__name__}"
    if self.debug and self.debug.should('plugin'):
        self.debug.write(f"Loaded plugin {self.current_module!r}: {plugin!r}")
        labelled = LabelledDebug(f"plugin {self.current_module!r}", self.debug)
        plugin = DebugPluginWrapper(plugin, labelled)

    # pylint: disable=attribute-defined-outside-init
    plugin._coverage_plugin_name = plugin_name
    plugin._coverage_enabled = True
    self.order.append(plugin)
    self.names[plugin_name] = plugin
    if specialized is not None:
        specialized.append(plugin)

</t>
<t tx="ekr.20221020070914.529">def __bool__(self):
    return bool(self.order)

</t>
<t tx="ekr.20221020070914.53">def switch_context(self, new_context):
    """Switch to a new dynamic context."""
    self.flush_data()
    if self.static_context:
        context = self.static_context
        if new_context:
            context += "|" + new_context
    else:
        context = new_context
    self.covdata.set_context(context)

</t>
<t tx="ekr.20221020070914.530">def __iter__(self):
    return iter(self.order)

</t>
<t tx="ekr.20221020070914.531">def get(self, plugin_name):
    """Return a plugin by name."""
    return self.names[plugin_name]


</t>
<t tx="ekr.20221020070914.532">class LabelledDebug:
    """A Debug writer, but with labels for prepending to the messages."""

    @others
</t>
<t tx="ekr.20221020070914.533">def __init__(self, label, debug, prev_labels=()):
    self.labels = list(prev_labels) + [label]
    self.debug = debug

</t>
<t tx="ekr.20221020070914.534">def add_label(self, label):
    """Add a label to the writer, and return a new `LabelledDebug`."""
    return LabelledDebug(label, self.debug, self.labels)

</t>
<t tx="ekr.20221020070914.535">def message_prefix(self):
    """The prefix to use on messages, combining the labels."""
    prefixes = self.labels + ['']
    return ":\n".join("  "*i+label for i, label in enumerate(prefixes))

</t>
<t tx="ekr.20221020070914.536">def write(self, message):
    """Write `message`, but with the labels prepended."""
    self.debug.write(f"{self.message_prefix()}{message}")


</t>
<t tx="ekr.20221020070914.537">class DebugPluginWrapper(CoveragePlugin):
    """Wrap a plugin, and use debug to report on what it's doing."""

    @others
</t>
<t tx="ekr.20221020070914.538">def __init__(self, plugin, debug):
    super().__init__()
    self.plugin = plugin
    self.debug = debug

</t>
<t tx="ekr.20221020070914.539">def file_tracer(self, filename):
    tracer = self.plugin.file_tracer(filename)
    self.debug.write(f"file_tracer({filename!r}) --&gt; {tracer!r}")
    if tracer:
        debug = self.debug.add_label(f"file {filename!r}")
        tracer = DebugFileTracerWrapper(tracer, debug)
    return tracer

</t>
<t tx="ekr.20221020070914.54">def disable_plugin(self, disposition):
    """Disable the plugin mentioned in `disposition`."""
    file_tracer = disposition.file_tracer
    plugin = file_tracer._coverage_plugin
    plugin_name = plugin._coverage_plugin_name
    self.warn(f"Disabling plug-in {plugin_name!r} due to previous exception")
    plugin._coverage_enabled = False
    disposition.trace = False

</t>
<t tx="ekr.20221020070914.540">def file_reporter(self, filename):
    reporter = self.plugin.file_reporter(filename)
    self.debug.write(f"file_reporter({filename!r}) --&gt; {reporter!r}")
    if reporter:
        debug = self.debug.add_label(f"file {filename!r}")
        reporter = DebugFileReporterWrapper(filename, reporter, debug)
    return reporter

</t>
<t tx="ekr.20221020070914.541">def dynamic_context(self, frame):
    context = self.plugin.dynamic_context(frame)
    self.debug.write(f"dynamic_context({frame!r}) --&gt; {context!r}")
    return context

</t>
<t tx="ekr.20221020070914.542">def find_executable_files(self, src_dir):
    executable_files = self.plugin.find_executable_files(src_dir)
    self.debug.write(f"find_executable_files({src_dir!r}) --&gt; {executable_files!r}")
    return executable_files

</t>
<t tx="ekr.20221020070914.543">def configure(self, config):
    self.debug.write(f"configure({config!r})")
    self.plugin.configure(config)

</t>
<t tx="ekr.20221020070914.544">def sys_info(self):
    return self.plugin.sys_info()


</t>
<t tx="ekr.20221020070914.545">class DebugFileTracerWrapper(FileTracer):
    """A debugging `FileTracer`."""

    @others
</t>
<t tx="ekr.20221020070914.546">def __init__(self, tracer, debug):
    self.tracer = tracer
    self.debug = debug

</t>
<t tx="ekr.20221020070914.547">def _show_frame(self, frame):
    """A short string identifying a frame, for debug messages."""
    return "%s@%d" % (
        os.path.basename(frame.f_code.co_filename),
        frame.f_lineno,
    )

</t>
<t tx="ekr.20221020070914.548">def source_filename(self):
    sfilename = self.tracer.source_filename()
    self.debug.write(f"source_filename() --&gt; {sfilename!r}")
    return sfilename

</t>
<t tx="ekr.20221020070914.549">def has_dynamic_source_filename(self):
    has = self.tracer.has_dynamic_source_filename()
    self.debug.write(f"has_dynamic_source_filename() --&gt; {has!r}")
    return has

</t>
<t tx="ekr.20221020070914.55">def cached_mapped_file(self, filename):
    """A locally cached version of file names mapped through file_mapper."""
    key = (type(filename), filename)
    try:
        return self.mapped_file_cache[key]
    except KeyError:
        return self.mapped_file_cache.setdefault(key, self.file_mapper(filename))

</t>
<t tx="ekr.20221020070914.550">def dynamic_source_filename(self, filename, frame):
    dyn = self.tracer.dynamic_source_filename(filename, frame)
    self.debug.write("dynamic_source_filename({!r}, {}) --&gt; {!r}".format(
        filename, self._show_frame(frame), dyn,
    ))
    return dyn

</t>
<t tx="ekr.20221020070914.551">def line_number_range(self, frame):
    pair = self.tracer.line_number_range(frame)
    self.debug.write(f"line_number_range({self._show_frame(frame)}) --&gt; {pair!r}")
    return pair


</t>
<t tx="ekr.20221020070914.552">class DebugFileReporterWrapper(FileReporter):
    """A debugging `FileReporter`."""

    @others
</t>
<t tx="ekr.20221020070914.553">def __init__(self, filename, reporter, debug):
    super().__init__(filename)
    self.reporter = reporter
    self.debug = debug

</t>
<t tx="ekr.20221020070914.554">def relative_filename(self):
    ret = self.reporter.relative_filename()
    self.debug.write(f"relative_filename() --&gt; {ret!r}")
    return ret

</t>
<t tx="ekr.20221020070914.555">def lines(self):
    ret = self.reporter.lines()
    self.debug.write(f"lines() --&gt; {ret!r}")
    return ret

</t>
<t tx="ekr.20221020070914.556">def excluded_lines(self):
    ret = self.reporter.excluded_lines()
    self.debug.write(f"excluded_lines() --&gt; {ret!r}")
    return ret

</t>
<t tx="ekr.20221020070914.557">def translate_lines(self, lines):
    ret = self.reporter.translate_lines(lines)
    self.debug.write(f"translate_lines({lines!r}) --&gt; {ret!r}")
    return ret

</t>
<t tx="ekr.20221020070914.558">def translate_arcs(self, arcs):
    ret = self.reporter.translate_arcs(arcs)
    self.debug.write(f"translate_arcs({arcs!r}) --&gt; {ret!r}")
    return ret

</t>
<t tx="ekr.20221020070914.559">def no_branch_lines(self):
    ret = self.reporter.no_branch_lines()
    self.debug.write(f"no_branch_lines() --&gt; {ret!r}")
    return ret

</t>
<t tx="ekr.20221020070914.56">def mapped_file_dict(self, d):
    """Return a dict like d, but with keys modified by file_mapper."""
    # The call to list(items()) ensures that the GIL protects the dictionary
    # iterator against concurrent modifications by tracers running
    # in other threads. We try three times in case of concurrent
    # access, hoping to get a clean copy.
    runtime_err = None
    for _ in range(3):                      # pragma: part covered
        try:
            items = list(d.items())
        except RuntimeError as ex:          # pragma: cant happen
            runtime_err = ex
        else:
            break
    else:
        raise runtime_err                   # pragma: cant happen

    return {self.cached_mapped_file(k): v for k, v in items}

</t>
<t tx="ekr.20221020070914.560">def exit_counts(self):
    ret = self.reporter.exit_counts()
    self.debug.write(f"exit_counts() --&gt; {ret!r}")
    return ret

</t>
<t tx="ekr.20221020070914.561">def arcs(self):
    ret = self.reporter.arcs()
    self.debug.write(f"arcs() --&gt; {ret!r}")
    return ret

</t>
<t tx="ekr.20221020070914.562">def source(self):
    ret = self.reporter.source()
    self.debug.write("source() --&gt; %d chars" % (len(ret),))
    return ret

</t>
<t tx="ekr.20221020070914.563">def source_token_lines(self):
    ret = list(self.reporter.source_token_lines())
    self.debug.write("source_token_lines() --&gt; %d tokens" % (len(ret),))
    return ret
</t>
<t tx="ekr.20221020070914.564">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Python source expertise for coverage.py"""

import os.path
import types
import zipimport

from coverage import env
from coverage.exceptions import CoverageException, NoSource
from coverage.files import canonical_filename, relative_filename
from coverage.misc import contract, expensive, isolate_module, join_regex
from coverage.parser import PythonParser
from coverage.phystokens import source_token_lines, source_encoding
from coverage.plugin import FileReporter

os = isolate_module(os)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.565">@contract(returns='bytes')
def read_python_source(filename):
    """Read the Python source text from `filename`.

    Returns bytes.

    """
    with open(filename, "rb") as f:
        source = f.read()

    if env.IRONPYTHON:
        # IronPython reads Unicode strings even for "rb" files.
        source = bytes(source)

    return source.replace(b"\r\n", b"\n").replace(b"\r", b"\n")


</t>
<t tx="ekr.20221020070914.566">@contract(returns='unicode')
def get_python_source(filename):
    """Return the source code, as unicode."""
    base, ext = os.path.splitext(filename)
    if ext == ".py" and env.WINDOWS:
        exts = [".py", ".pyw"]
    else:
        exts = [ext]

    for ext in exts:
        try_filename = base + ext
        if os.path.exists(try_filename):
            # A regular text file: open it.
            source = read_python_source(try_filename)
            break

        # Maybe it's in a zip file?
        source = get_zip_bytes(try_filename)
        if source is not None:
            break
    else:
        # Couldn't find source.
        raise NoSource(f"No source for code: '{filename}'.")

    # Replace \f because of http://bugs.python.org/issue19035
    source = source.replace(b'\f', b' ')
    source = source.decode(source_encoding(source), "replace")

    # Python code should always end with a line with a newline.
    if source and source[-1] != '\n':
        source += '\n'

    return source


</t>
<t tx="ekr.20221020070914.567">@contract(returns='bytes|None')
def get_zip_bytes(filename):
    """Get data from `filename` if it is a zip file path.

    Returns the bytestring data read from the zip file, or None if no zip file
    could be found or `filename` isn't in it.  The data returned will be
    an empty string if the file is empty.

    """
    markers = ['.zip'+os.sep, '.egg'+os.sep, '.pex'+os.sep]
    for marker in markers:
        if marker in filename:
            parts = filename.split(marker)
            try:
                zi = zipimport.zipimporter(parts[0]+marker[:-1])
            except zipimport.ZipImportError:
                continue
            try:
                data = zi.get_data(parts[1])
            except OSError:
                continue
            return data
    return None


</t>
<t tx="ekr.20221020070914.568">def source_for_file(filename):
    """Return the source filename for `filename`.

    Given a file name being traced, return the best guess as to the source
    file to attribute it to.

    """
    if filename.endswith(".py"):
        # .py files are themselves source files.
        return filename

    elif filename.endswith((".pyc", ".pyo")):
        # Bytecode files probably have source files near them.
        py_filename = filename[:-1]
        if os.path.exists(py_filename):
            # Found a .py file, use that.
            return py_filename
        if env.WINDOWS:
            # On Windows, it could be a .pyw file.
            pyw_filename = py_filename + "w"
            if os.path.exists(pyw_filename):
                return pyw_filename
        # Didn't find source, but it's probably the .py file we want.
        return py_filename

    elif filename.endswith("$py.class"):
        # Jython is easy to guess.
        return filename[:-9] + ".py"

    # No idea, just use the file name as-is.
    return filename


</t>
<t tx="ekr.20221020070914.569">def source_for_morf(morf):
    """Get the source filename for the module-or-file `morf`."""
    if hasattr(morf, '__file__') and morf.__file__:
        filename = morf.__file__
    elif isinstance(morf, types.ModuleType):
        # A module should have had .__file__, otherwise we can't use it.
        # This could be a PEP-420 namespace package.
        raise CoverageException(f"Module {morf} has no file")
    else:
        filename = morf

    filename = source_for_file(filename)
    return filename


</t>
<t tx="ekr.20221020070914.57">def plugin_was_disabled(self, plugin):
    """Record that `plugin` was disabled during the run."""
    self.disabled_plugins.add(plugin._coverage_plugin_name)

</t>
<t tx="ekr.20221020070914.570">class PythonFileReporter(FileReporter):
    """Report support for a Python file."""

    @others
</t>
<t tx="ekr.20221020070914.571">def __init__(self, morf, coverage=None):
    self.coverage = coverage

    filename = source_for_morf(morf)

    super().__init__(canonical_filename(filename))

    if hasattr(morf, '__name__'):
        name = morf.__name__.replace(".", os.sep)
        if os.path.basename(filename).startswith('__init__.'):
            name += os.sep + "__init__"
        name += ".py"
    else:
        name = relative_filename(filename)
    self.relname = name

    self._source = None
    self._parser = None
    self._excluded = None

</t>
<t tx="ekr.20221020070914.572">def __repr__(self):
    return f"&lt;PythonFileReporter {self.filename!r}&gt;"

</t>
<t tx="ekr.20221020070914.573">@contract(returns='unicode')
def relative_filename(self):
    return self.relname

</t>
<t tx="ekr.20221020070914.574">@property
def parser(self):
    """Lazily create a :class:`PythonParser`."""
    if self._parser is None:
        self._parser = PythonParser(
            filename=self.filename,
            exclude=self.coverage._exclude_regex('exclude'),
        )
        self._parser.parse_source()
    return self._parser

</t>
<t tx="ekr.20221020070914.575">def lines(self):
    """Return the line numbers of statements in the file."""
    return self.parser.statements

</t>
<t tx="ekr.20221020070914.576">def excluded_lines(self):
    """Return the line numbers of statements in the file."""
    return self.parser.excluded

</t>
<t tx="ekr.20221020070914.577">def translate_lines(self, lines):
    return self.parser.translate_lines(lines)

</t>
<t tx="ekr.20221020070914.578">def translate_arcs(self, arcs):
    return self.parser.translate_arcs(arcs)

</t>
<t tx="ekr.20221020070914.579">@expensive
def no_branch_lines(self):
    no_branch = self.parser.lines_matching(
        join_regex(self.coverage.config.partial_list),
        join_regex(self.coverage.config.partial_always_list),
    )
    return no_branch

</t>
<t tx="ekr.20221020070914.58">def flush_data(self):
    """Save the collected data to our associated `CoverageData`.

    Data may have also been saved along the way. This forces the
    last of the data to be saved.

    Returns True if there was data to save, False if not.
    """
    if not self._activity():
        return False

    if self.branch:
        if self.packed_arcs:
            # Unpack the line number pairs packed into integers.  See
            # tracer.c:CTracer_record_pair for the C code that creates
            # these packed ints.
            data = {}
            for fname, packeds in self.data.items():
                tuples = []
                for packed in packeds:
                    l1 = packed &amp; 0xFFFFF
                    l2 = (packed &amp; (0xFFFFF &lt;&lt; 20)) &gt;&gt; 20
                    if packed &amp; (1 &lt;&lt; 40):
                        l1 *= -1
                    if packed &amp; (1 &lt;&lt; 41):
                        l2 *= -1
                    tuples.append((l1, l2))
                data[fname] = tuples
        else:
            data = self.data
        self.covdata.add_arcs(self.mapped_file_dict(data))
    else:
        self.covdata.add_lines(self.mapped_file_dict(self.data))

    file_tracers = {
        k: v for k, v in self.file_tracers.items()
        if v not in self.disabled_plugins
    }
    self.covdata.add_file_tracers(self.mapped_file_dict(file_tracers))

    self._clear_data()
    return True
</t>
<t tx="ekr.20221020070914.580">@expensive
def arcs(self):
    return self.parser.arcs()

</t>
<t tx="ekr.20221020070914.581">@expensive
def exit_counts(self):
    return self.parser.exit_counts()

</t>
<t tx="ekr.20221020070914.582">def missing_arc_description(self, start, end, executed_arcs=None):
    return self.parser.missing_arc_description(start, end, executed_arcs)

</t>
<t tx="ekr.20221020070914.583">@contract(returns='unicode')
def source(self):
    if self._source is None:
        self._source = get_python_source(self.filename)
    return self._source

</t>
<t tx="ekr.20221020070914.584">def should_be_python(self):
    """Does it seem like this file should contain Python?

    This is used to decide if a file reported as part of the execution of
    a program was really likely to have contained Python in the first
    place.

    """
    # Get the file extension.
    _, ext = os.path.splitext(self.filename)

    # Anything named *.py* should be Python.
    if ext.startswith('.py'):
        return True
    # A file with no extension should be Python.
    if not ext:
        return True
    # Everything else is probably not Python.
    return False

</t>
<t tx="ekr.20221020070914.585">def source_token_lines(self):
    return source_token_lines(self.source())
</t>
<t tx="ekr.20221020070914.586">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Raw data collector for coverage.py."""

import atexit
import dis
import sys

from coverage import env

# We need the YIELD_VALUE opcode below, in a comparison-friendly form.
RESUME = dis.opmap.get('RESUME')
RETURN_VALUE = dis.opmap['RETURN_VALUE']
if RESUME is None:
    YIELD_VALUE = dis.opmap['YIELD_VALUE']
    YIELD_FROM = dis.opmap['YIELD_FROM']
    YIELD_FROM_OFFSET = 0 if env.PYPY else 2

# When running meta-coverage, this file can try to trace itself, which confuses
# everything.  Don't trace ourselves.

THIS_FILE = __file__.rstrip("co")

@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.587">class PyTracer:
    """Python implementation of the raw data tracer."""

    # Because of poor implementations of trace-function-manipulating tools,
    # the Python trace function must be kept very simple.  In particular, there
    # must be only one function ever set as the trace function, both through
    # sys.settrace, and as the return value from the trace function.  Put
    # another way, the trace function must always return itself.  It cannot
    # swap in other functions, or return None to avoid tracing a particular
    # frame.
    #
    # The trace manipulator that introduced this restriction is DecoratorTools,
    # which sets a trace function, and then later restores the pre-existing one
    # by calling sys.settrace with a function it found in the current frame.
    #
    # Systems that use DecoratorTools (or similar trace manipulations) must use
    # PyTracer to get accurate results.  The command-line --timid argument is
    # used to force the use of this tracer.

    @others
</t>
<t tx="ekr.20221020070914.588">def __init__(self):
    # Attributes set from the collector:
    self.data = None
    self.trace_arcs = False
    self.should_trace = None
    self.should_trace_cache = None
    self.should_start_context = None
    self.warn = None
    # The threading module to use, if any.
    self.threading = None

    self.cur_file_data = None
    self.last_line = 0          # int, but uninitialized.
    self.cur_file_name = None
    self.context = None
    self.started_context = False

    self.data_stack = []
    self.thread = None
    self.stopped = False
    self._activity = False

    self.in_atexit = False
    # On exit, self.in_atexit = True
    atexit.register(setattr, self, 'in_atexit', True)

    # Cache a bound method on the instance, so that we don't have to
    # re-create a bound method object all the time.
    self._cached_bound_method_trace = self._trace

</t>
<t tx="ekr.20221020070914.589">def __repr__(self):
    return "&lt;PyTracer at 0x{:x}: {} lines in {} files&gt;".format(
        id(self),
        sum(len(v) for v in self.data.values()),
        len(self.data),
    )

</t>
<t tx="ekr.20221020070914.59">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Config file for coverage.py"""

import collections
import configparser
import copy
import os
import os.path
import re

from coverage.exceptions import ConfigError
from coverage.misc import contract, isolate_module, human_sorted_items, substitute_variables

from coverage.tomlconfig import TomlConfigParser, TomlDecodeError

os = isolate_module(os)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.590">def log(self, marker, *args):
    """For hard-core logging of what this tracer is doing."""
    with open("/tmp/debug_trace.txt", "a") as f:
        f.write("{} {}[{}]".format(
            marker,
            id(self),
            len(self.data_stack),
        ))
        if 0:   # if you want thread ids..
            f.write(".{:x}.{:x}".format(
                self.thread.ident,
                self.threading.current_thread().ident,
            ))
        f.write(" {}".format(" ".join(map(str, args))))
        if 0:   # if you want callers..
            f.write(" | ")
            stack = " / ".join(
                (fname or "???").rpartition("/")[-1]
                for _, fname, _, _ in self.data_stack
            )
            f.write(stack)
        f.write("\n")

</t>
<t tx="ekr.20221020070914.591">def _trace(self, frame, event, arg_unused):
    """The trace function passed to sys.settrace."""

    if THIS_FILE in frame.f_code.co_filename:
        return None

    #self.log(":", frame.f_code.co_filename, frame.f_lineno, frame.f_code.co_name + "()", event)

    if (self.stopped and sys.gettrace() == self._cached_bound_method_trace):    # pylint: disable=comparison-with-callable
        # The PyTrace.stop() method has been called, possibly by another
        # thread, let's deactivate ourselves now.
        if 0:
            self.log("---\nX", frame.f_code.co_filename, frame.f_lineno)
            f = frame
            while f:
                self.log("&gt;", f.f_code.co_filename, f.f_lineno, f.f_code.co_name, f.f_trace)
                f = f.f_back
        sys.settrace(None)
        self.cur_file_data, self.cur_file_name, self.last_line, self.started_context = (
            self.data_stack.pop()
        )
        return None

    # if event != 'call' and frame.f_code.co_filename != self.cur_file_name:
    #     self.log("---\n*", frame.f_code.co_filename, self.cur_file_name, frame.f_lineno)

    if event == 'call':
        # Should we start a new context?
        if self.should_start_context and self.context is None:
            context_maybe = self.should_start_context(frame)
            if context_maybe is not None:
                self.context = context_maybe
                started_context = True
                self.switch_context(self.context)
            else:
                started_context = False
        else:
            started_context = False
        self.started_context = started_context

        # Entering a new frame.  Decide if we should trace in this file.
        self._activity = True
        self.data_stack.append(
            (
                self.cur_file_data,
                self.cur_file_name,
                self.last_line,
                started_context,
            )
        )

        # Improve tracing performance: when calling a function, both caller
        # and callee are often within the same file. if that's the case, we
        # don't have to re-check whether to trace the corresponding
        # function (which is a little bit espensive since it involves
        # dictionary lookups). This optimization is only correct if we
        # didn't start a context.
        filename = frame.f_code.co_filename
        if filename != self.cur_file_name or started_context:
            self.cur_file_name = filename
            disp = self.should_trace_cache.get(filename)
            if disp is None:
                disp = self.should_trace(filename, frame)
                self.should_trace_cache[filename] = disp

            self.cur_file_data = None
            if disp.trace:
                tracename = disp.source_filename
                if tracename not in self.data:
                    self.data[tracename] = set()
                self.cur_file_data = self.data[tracename]
            else:
                frame.f_trace_lines = False
        elif not self.cur_file_data:
            frame.f_trace_lines = False

        # The call event is really a "start frame" event, and happens for
        # function calls and re-entering generators.  The f_lasti field is
        # -1 for calls, and a real offset for generators.  Use &lt;0 as the
        # line number for calls, and the real line number for generators.
        if RESUME is not None:
            # The current opcode is guaranteed to be RESUME. The argument
            # determines what kind of resume it is.
            oparg = frame.f_code.co_code[frame.f_lasti + 1]
            real_call = (oparg == 0)
        else:
            real_call = (getattr(frame, 'f_lasti', -1) &lt; 0)
        if real_call:
            self.last_line = -frame.f_code.co_firstlineno
        else:
            self.last_line = frame.f_lineno

    elif event == 'line':
        # Record an executed line.
        if self.cur_file_data is not None:
            lineno = frame.f_lineno

            if self.trace_arcs:
                self.cur_file_data.add((self.last_line, lineno))
            else:
                self.cur_file_data.add(lineno)
            self.last_line = lineno

    elif event == 'return':
        if self.trace_arcs and self.cur_file_data:
            # Record an arc leaving the function, but beware that a
            # "return" event might just mean yielding from a generator.
            code = frame.f_code.co_code
            lasti = frame.f_lasti
            if RESUME is not None:
                if len(code) == lasti + 2:
                    # A return from the end of a code object is a real return.
                    real_return = True
                else:
                    # it's a real return.
                    real_return = (code[lasti + 2] != RESUME)
            else:
                if code[lasti] == RETURN_VALUE:
                    real_return = True
                elif code[lasti] == YIELD_VALUE:
                    real_return = False
                elif len(code) &lt;= lasti + YIELD_FROM_OFFSET:
                    real_return = True
                elif code[lasti + YIELD_FROM_OFFSET] == YIELD_FROM:
                    real_return = False
                else:
                    real_return = True
            if real_return:
                first = frame.f_code.co_firstlineno
                self.cur_file_data.add((self.last_line, -first))

        # Leaving this function, pop the filename stack.
        self.cur_file_data, self.cur_file_name, self.last_line, self.started_context = (
            self.data_stack.pop()
        )
        # Leaving a context?
        if self.started_context:
            self.context = None
            self.switch_context(None)
    return self._cached_bound_method_trace

</t>
<t tx="ekr.20221020070914.592">def start(self):
    """Start this Tracer.

    Return a Python function suitable for use with sys.settrace().

    """
    self.stopped = False
    if self.threading:
        if self.thread is None:
            self.thread = self.threading.current_thread()
        else:
            if self.thread.ident != self.threading.current_thread().ident:
                # Re-starting from a different thread!? Don't set the trace
                # function, but we are marked as running again, so maybe it
                # will be ok?
                #self.log("~", "starting on different threads")
                return self._cached_bound_method_trace

    sys.settrace(self._cached_bound_method_trace)
    return self._cached_bound_method_trace

</t>
<t tx="ekr.20221020070914.593">def stop(self):
    """Stop this Tracer."""
    # Get the active tracer callback before setting the stop flag to be
    # able to detect if the tracer was changed prior to stopping it.
    tf = sys.gettrace()

    # Set the stop flag. The actual call to sys.settrace(None) will happen
    # in the self._trace callback itself to make sure to call it from the
    # right thread.
    self.stopped = True

    if self.threading and self.thread.ident != self.threading.current_thread().ident:
        # Called on a different thread than started us: we can't unhook
        # ourselves, but we've set the flag that we should stop, so we
        # won't do any more tracing.
        #self.log("~", "stopping on different threads")
        return

    if self.warn:
        # PyPy clears the trace function before running atexit functions,
        # so don't warn if we are in atexit on PyPy and the trace function
        # has changed to None.
        dont_warn = (env.PYPY and env.PYPYVERSION &gt;= (5, 4) and self.in_atexit and tf is None)
        if (not dont_warn) and tf != self._cached_bound_method_trace:   # pylint: disable=comparison-with-callable
            self.warn(
                "Trace function changed, data is likely wrong: " +
                f"{tf!r} != {self._cached_bound_method_trace!r}",
                slug="trace-changed",
            )

</t>
<t tx="ekr.20221020070914.594">def activity(self):
    """Has there been any activity?"""
    return self._activity

</t>
<t tx="ekr.20221020070914.595">def reset_activity(self):
    """Reset the activity() flag."""
    self._activity = False

</t>
<t tx="ekr.20221020070914.596">def get_stats(self):
    """Return a dictionary of statistics, or None."""
    return None
</t>
<t tx="ekr.20221020070914.597">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Reporter foundation for coverage.py."""

import sys

from coverage.exceptions import CoverageException, NoDataError, NotPython
from coverage.files import prep_patterns, FnmatchMatcher
from coverage.misc import ensure_dir_for_file, file_be_gone


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.598">def render_report(output_path, reporter, morfs, msgfn):
    """Run a one-file report generator, managing the output file.

    This function ensures the output file is ready to be written to. Then writes
    the report to it. Then closes the file and cleans up.

    """
    file_to_close = None
    delete_file = False

    if output_path == "-":
        outfile = sys.stdout
    else:
        # Ensure that the output directory is created; done here
        # because this report pre-opens the output file.
        # HTMLReport does this using the Report plumbing because
        # its task is more complex, being multiple files.
        ensure_dir_for_file(output_path)
        outfile = open(output_path, "w", encoding="utf-8")
        file_to_close = outfile

    try:
        return reporter.report(morfs, outfile=outfile)
    except CoverageException:
        delete_file = True
        raise
    finally:
        if file_to_close:
            file_to_close.close()
            if delete_file:
                file_be_gone(output_path)           # pragma: part covered (doesn't return)
            else:
                msgfn(f"Wrote {reporter.report_type} to {output_path}")


</t>
<t tx="ekr.20221020070914.599">def get_analysis_to_report(coverage, morfs):
    """Get the files to report on.

    For each morf in `morfs`, if it should be reported on (based on the omit
    and include configuration options), yield a pair, the `FileReporter` and
    `Analysis` for the morf.

    """
    file_reporters = coverage._get_file_reporters(morfs)
    config = coverage.config

    if config.report_include:
        matcher = FnmatchMatcher(prep_patterns(config.report_include), "report_include")
        file_reporters = [fr for fr in file_reporters if matcher.match(fr.filename)]

    if config.report_omit:
        matcher = FnmatchMatcher(prep_patterns(config.report_omit), "report_omit")
        file_reporters = [fr for fr in file_reporters if not matcher.match(fr.filename)]

    if not file_reporters:
        raise NoDataError("No data to report.")

    for fr in sorted(file_reporters):
        try:
            analysis = coverage._analyze(fr)
        except NotPython:
            # Only report errors for .py files, and only if we didn't
            # explicitly suppress those errors.
            # NotPython is only raised by PythonFileReporter, which has a
            # should_be_python() method.
            if fr.should_be_python():
                if config.ignore_errors:
                    msg = f"Couldn't parse Python file '{fr.filename}'"
                    coverage._warn(msg, slug="couldnt-parse")
                else:
                    raise
        except Exception as exc:
            if config.ignore_errors:
                msg = f"Couldn't parse '{fr.filename}': {exc}".rstrip()
                coverage._warn(msg, slug="couldnt-parse")
            else:
                raise
        else:
            yield (fr, analysis)
</t>
<t tx="ekr.20221020070914.6">def report(self, morfs, directory=None):
    """Run the report.

    See `coverage.report()` for arguments.

    """
    self.directory = directory
    self.coverage.get_data()
    for fr, analysis in get_analysis_to_report(self.coverage, morfs):
        self.annotate_file(fr, analysis)

</t>
<t tx="ekr.20221020070914.60">class HandyConfigParser(configparser.RawConfigParser):
    """Our specialization of ConfigParser."""

    @others
</t>
<t tx="ekr.20221020070914.600">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Results of coverage measurement."""

import collections

from coverage.debug import SimpleReprMixin
from coverage.exceptions import ConfigError
from coverage.misc import contract, nice_pair


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.601">class Analysis:
    """The results of analyzing a FileReporter."""

    @others
</t>
<t tx="ekr.20221020070914.602">def __init__(self, data, precision, file_reporter, file_mapper):
    self.data = data
    self.file_reporter = file_reporter
    self.filename = file_mapper(self.file_reporter.filename)
    self.statements = self.file_reporter.lines()
    self.excluded = self.file_reporter.excluded_lines()

    # Identify missing statements.
    executed = self.data.lines(self.filename) or []
    executed = self.file_reporter.translate_lines(executed)
    self.executed = executed
    self.missing = self.statements - self.executed

    if self.data.has_arcs():
        self._arc_possibilities = sorted(self.file_reporter.arcs())
        self.exit_counts = self.file_reporter.exit_counts()
        self.no_branch = self.file_reporter.no_branch_lines()
        n_branches = self._total_branches()
        mba = self.missing_branch_arcs()
        n_partial_branches = sum(len(v) for k,v in mba.items() if k not in self.missing)
        n_missing_branches = sum(len(v) for k,v in mba.items())
    else:
        self._arc_possibilities = []
        self.exit_counts = {}
        self.no_branch = set()
        n_branches = n_partial_branches = n_missing_branches = 0

    self.numbers = Numbers(
        precision=precision,
        n_files=1,
        n_statements=len(self.statements),
        n_excluded=len(self.excluded),
        n_missing=len(self.missing),
        n_branches=n_branches,
        n_partial_branches=n_partial_branches,
        n_missing_branches=n_missing_branches,
    )

</t>
<t tx="ekr.20221020070914.603">def missing_formatted(self, branches=False):
    """The missing line numbers, formatted nicely.

    Returns a string like "1-2, 5-11, 13-14".

    If `branches` is true, includes the missing branch arcs also.

    """
    if branches and self.has_arcs():
        arcs = self.missing_branch_arcs().items()
    else:
        arcs = None

    return format_lines(self.statements, self.missing, arcs=arcs)

</t>
<t tx="ekr.20221020070914.604">def has_arcs(self):
    """Were arcs measured in this result?"""
    return self.data.has_arcs()

</t>
<t tx="ekr.20221020070914.605">@contract(returns='list(tuple(int, int))')
def arc_possibilities(self):
    """Returns a sorted list of the arcs in the code."""
    return self._arc_possibilities

</t>
<t tx="ekr.20221020070914.606">@contract(returns='list(tuple(int, int))')
def arcs_executed(self):
    """Returns a sorted list of the arcs actually executed in the code."""
    executed = self.data.arcs(self.filename) or []
    executed = self.file_reporter.translate_arcs(executed)
    return sorted(executed)

</t>
<t tx="ekr.20221020070914.607">@contract(returns='list(tuple(int, int))')
def arcs_missing(self):
    """Returns a sorted list of the unexecuted arcs in the code."""
    possible = self.arc_possibilities()
    executed = self.arcs_executed()
    missing = (
        p for p in possible
            if p not in executed
                and p[0] not in self.no_branch
                and p[1] not in self.excluded
    )
    return sorted(missing)

</t>
<t tx="ekr.20221020070914.608">@contract(returns='list(tuple(int, int))')
def arcs_unpredicted(self):
    """Returns a sorted list of the executed arcs missing from the code."""
    possible = self.arc_possibilities()
    executed = self.arcs_executed()
    # Exclude arcs here which connect a line to itself.  They can occur
    # in executed data in some cases.  This is where they can cause
    # trouble, and here is where it's the least burden to remove them.
    # Also, generators can somehow cause arcs from "enter" to "exit", so
    # make sure we have at least one positive value.
    unpredicted = (
        e for e in executed
            if e not in possible
                and e[0] != e[1]
                and (e[0] &gt; 0 or e[1] &gt; 0)
    )
    return sorted(unpredicted)

</t>
<t tx="ekr.20221020070914.609">def _branch_lines(self):
    """Returns a list of line numbers that have more than one exit."""
    return [l1 for l1,count in self.exit_counts.items() if count &gt; 1]

</t>
<t tx="ekr.20221020070914.61">def __init__(self, our_file):
    """Create the HandyConfigParser.

    `our_file` is True if this config file is specifically for coverage,
    False if we are examining another config file (tox.ini, setup.cfg)
    for possible settings.
    """

    configparser.RawConfigParser.__init__(self)
    self.section_prefixes = ["coverage:"]
    if our_file:
        self.section_prefixes.append("")

</t>
<t tx="ekr.20221020070914.610">def _total_branches(self):
    """How many total branches are there?"""
    return sum(count for count in self.exit_counts.values() if count &gt; 1)

</t>
<t tx="ekr.20221020070914.611">@contract(returns='dict(int: list(int))')
def missing_branch_arcs(self):
    """Return arcs that weren't executed from branch lines.

    Returns {l1:[l2a,l2b,...], ...}

    """
    missing = self.arcs_missing()
    branch_lines = set(self._branch_lines())
    mba = collections.defaultdict(list)
    for l1, l2 in missing:
        if l1 in branch_lines:
            mba[l1].append(l2)
    return mba

</t>
<t tx="ekr.20221020070914.612">@contract(returns='dict(int: list(int))')
def executed_branch_arcs(self):
    """Return arcs that were executed from branch lines.

    Returns {l1:[l2a,l2b,...], ...}

    """
    executed = self.arcs_executed()
    branch_lines = set(self._branch_lines())
    eba = collections.defaultdict(list)
    for l1, l2 in executed:
        if l1 in branch_lines:
            eba[l1].append(l2)
    return eba

</t>
<t tx="ekr.20221020070914.613">@contract(returns='dict(int: tuple(int, int))')
def branch_stats(self):
    """Get stats about branches.

    Returns a dict mapping line numbers to a tuple:
    (total_exits, taken_exits).
    """

    missing_arcs = self.missing_branch_arcs()
    stats = {}
    for lnum in self._branch_lines():
        exits = self.exit_counts[lnum]
        missing = len(missing_arcs[lnum])
        stats[lnum] = (exits, exits - missing)
    return stats


</t>
<t tx="ekr.20221020070914.614">class Numbers(SimpleReprMixin):
    """The numerical results of measuring coverage.

    This holds the basic statistics from `Analysis`, and is used to roll
    up statistics across files.

    """

    @others
</t>
<t tx="ekr.20221020070914.615">def __init__(self,
        precision=0,
        n_files=0, n_statements=0, n_excluded=0, n_missing=0,
        n_branches=0, n_partial_branches=0, n_missing_branches=0
        ):
    assert 0 &lt;= precision &lt; 10
    self._precision = precision
    self._near0 = 1.0 / 10**precision
    self._near100 = 100.0 - self._near0
    self.n_files = n_files
    self.n_statements = n_statements
    self.n_excluded = n_excluded
    self.n_missing = n_missing
    self.n_branches = n_branches
    self.n_partial_branches = n_partial_branches
    self.n_missing_branches = n_missing_branches

</t>
<t tx="ekr.20221020070914.616">def init_args(self):
    """Return a list for __init__(*args) to recreate this object."""
    return [
        self._precision,
        self.n_files, self.n_statements, self.n_excluded, self.n_missing,
        self.n_branches, self.n_partial_branches, self.n_missing_branches,
    ]

</t>
<t tx="ekr.20221020070914.617">@property
def n_executed(self):
    """Returns the number of executed statements."""
    return self.n_statements - self.n_missing

</t>
<t tx="ekr.20221020070914.618">@property
def n_executed_branches(self):
    """Returns the number of executed branches."""
    return self.n_branches - self.n_missing_branches

</t>
<t tx="ekr.20221020070914.619">@property
def pc_covered(self):
    """Returns a single percentage value for coverage."""
    if self.n_statements &gt; 0:
        numerator, denominator = self.ratio_covered
        pc_cov = (100.0 * numerator) / denominator
    else:
        pc_cov = 100.0
    return pc_cov

</t>
<t tx="ekr.20221020070914.62">def read(self, filenames, encoding_unused=None):
    """Read a file name as UTF-8 configuration data."""
    return configparser.RawConfigParser.read(self, filenames, encoding="utf-8")

</t>
<t tx="ekr.20221020070914.620">@property
def pc_covered_str(self):
    """Returns the percent covered, as a string, without a percent sign.

    Note that "0" is only returned when the value is truly zero, and "100"
    is only returned when the value is truly 100.  Rounding can never
    result in either "0" or "100".

    """
    return self.display_covered(self.pc_covered)

</t>
<t tx="ekr.20221020070914.621">def display_covered(self, pc):
    """Return a displayable total percentage, as a string.

    Note that "0" is only returned when the value is truly zero, and "100"
    is only returned when the value is truly 100.  Rounding can never
    result in either "0" or "100".

    """
    if 0 &lt; pc &lt; self._near0:
        pc = self._near0
    elif self._near100 &lt; pc &lt; 100:
        pc = self._near100
    else:
        pc = round(pc, self._precision)
    return "%.*f" % (self._precision, pc)

</t>
<t tx="ekr.20221020070914.622">def pc_str_width(self):
    """How many characters wide can pc_covered_str be?"""
    width = 3   # "100"
    if self._precision &gt; 0:
        width += 1 + self._precision
    return width

</t>
<t tx="ekr.20221020070914.623">@property
def ratio_covered(self):
    """Return a numerator and denominator for the coverage ratio."""
    numerator = self.n_executed + self.n_executed_branches
    denominator = self.n_statements + self.n_branches
    return numerator, denominator

</t>
<t tx="ekr.20221020070914.624">def __add__(self, other):
    nums = Numbers(precision=self._precision)
    nums.n_files = self.n_files + other.n_files
    nums.n_statements = self.n_statements + other.n_statements
    nums.n_excluded = self.n_excluded + other.n_excluded
    nums.n_missing = self.n_missing + other.n_missing
    nums.n_branches = self.n_branches + other.n_branches
    nums.n_partial_branches = (
        self.n_partial_branches + other.n_partial_branches
    )
    nums.n_missing_branches = (
        self.n_missing_branches + other.n_missing_branches
    )
    return nums

</t>
<t tx="ekr.20221020070914.625">def __radd__(self, other):
    # Implementing 0+Numbers allows us to sum() a list of Numbers.
    assert other == 0   # we only ever call it this way.
    return self


</t>
<t tx="ekr.20221020070914.626">def _line_ranges(statements, lines):
    """Produce a list of ranges for `format_lines`."""
    statements = sorted(statements)
    lines = sorted(lines)

    pairs = []
    start = None
    lidx = 0
    for stmt in statements:
        if lidx &gt;= len(lines):
            break
        if stmt == lines[lidx]:
            lidx += 1
            if not start:
                start = stmt
            end = stmt
        elif start:
            pairs.append((start, end))
            start = None
    if start:
        pairs.append((start, end))
    return pairs


</t>
<t tx="ekr.20221020070914.627">def format_lines(statements, lines, arcs=None):
    """Nicely format a list of line numbers.

    Format a list of line numbers for printing by coalescing groups of lines as
    long as the lines represent consecutive statements.  This will coalesce
    even if there are gaps between statements.

    For example, if `statements` is [1,2,3,4,5,10,11,12,13,14] and
    `lines` is [1,2,5,10,11,13,14] then the result will be "1-2, 5-11, 13-14".

    Both `lines` and `statements` can be any iterable. All of the elements of
    `lines` must be in `statements`, and all of the values must be positive
    integers.

    If `arcs` is provided, they are (start,[end,end,end]) pairs that will be
    included in the output as long as start isn't in `lines`.

    """
    line_items = [(pair[0], nice_pair(pair)) for pair in _line_ranges(statements, lines)]
    if arcs:
        line_exits = sorted(arcs)
        for line, exits in line_exits:
            for ex in sorted(exits):
                if line not in lines and ex not in lines:
                    dest = (ex if ex &gt; 0 else "exit")
                    line_items.append((line, f"{line}-&gt;{dest}"))

    ret = ', '.join(t[-1] for t in sorted(line_items))
    return ret


</t>
<t tx="ekr.20221020070914.628">@contract(total='number', fail_under='number', precision=int, returns=bool)
def should_fail_under(total, fail_under, precision):
    """Determine if a total should fail due to fail-under.

    `total` is a float, the coverage measurement total. `fail_under` is the
    fail_under setting to compare with. `precision` is the number of digits
    to consider after the decimal point.

    Returns True if the total should fail.

    """
    # We can never achieve higher than 100% coverage, or less than zero.
    if not (0 &lt;= fail_under &lt;= 100.0):
        msg = f"fail_under={fail_under} is invalid. Must be between 0 and 100."
        raise ConfigError(msg)

    # Special case for fail_under=100, it must really be 100.
    if fail_under == 100.0 and total != 100.0:
        return True

    return round(total, precision) &lt; fail_under
</t>
<t tx="ekr.20221020070914.629">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""SQLite coverage data."""

import collections
import datetime
import functools
import glob
import itertools
import os
import random
import re
import socket
import sqlite3
import sys
import textwrap
import threading
import zlib

from coverage.debug import NoDebugging, SimpleReprMixin, clipped_repr
from coverage.exceptions import CoverageException, DataError
from coverage.files import PathAliases
from coverage.misc import contract, file_be_gone, isolate_module
from coverage.numbits import numbits_to_nums, numbits_union, nums_to_numbits
from coverage.version import __version__

os = isolate_module(os)

# If you change the schema, increment the SCHEMA_VERSION, and update the
# docs in docs/dbschema.rst by running "make cogdoc".

SCHEMA_VERSION = 7

# Schema versions:
# 1: Released in 5.0a2
# 2: Added contexts in 5.0a3.
# 3: Replaced line table with line_map table.
# 4: Changed line_map.bitmap to line_map.numbits.
# 5: Added foreign key declarations.
# 6: Key-value in meta.
# 7: line_map -&gt; line_bits

SCHEMA = """\
CREATE TABLE coverage_schema (
    -- One row, to record the version of the schema in this db.
    version integer
);

CREATE TABLE meta (
    -- Key-value pairs, to record metadata about the data
    key text,
    value text,
    unique (key)
    -- Keys:
    --  'has_arcs' boolean      -- Is this data recording branches?
    --  'sys_argv' text         -- The coverage command line that recorded the data.
    --  'version' text          -- The version of coverage.py that made the file.
    --  'when' text             -- Datetime when the file was created.
);

CREATE TABLE file (
    -- A row per file measured.
    id integer primary key,
    path text,
    unique (path)
);

CREATE TABLE context (
    -- A row per context measured.
    id integer primary key,
    context text,
    unique (context)
);

CREATE TABLE line_bits (
    -- If recording lines, a row per context per file executed.
    -- All of the line numbers for that file/context are in one numbits.
    file_id integer,            -- foreign key to `file`.
    context_id integer,         -- foreign key to `context`.
    numbits blob,               -- see the numbits functions in coverage.numbits
    foreign key (file_id) references file (id),
    foreign key (context_id) references context (id),
    unique (file_id, context_id)
);

CREATE TABLE arc (
    -- If recording branches, a row per context per from/to line transition executed.
    file_id integer,            -- foreign key to `file`.
    context_id integer,         -- foreign key to `context`.
    fromno integer,             -- line number jumped from.
    tono integer,               -- line number jumped to.
    foreign key (file_id) references file (id),
    foreign key (context_id) references context (id),
    unique (file_id, context_id, fromno, tono)
);

CREATE TABLE tracer (
    -- A row per file indicating the tracer used for that file.
    file_id integer primary key,
    tracer text,
    foreign key (file_id) references file (id)
);
"""

@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.63">def has_option(self, section, option):
    for section_prefix in self.section_prefixes:
        real_section = section_prefix + section
        has = configparser.RawConfigParser.has_option(self, real_section, option)
        if has:
            return has
    return False

</t>
<t tx="ekr.20221020070914.630">class CoverageData(SimpleReprMixin):
    """Manages collected coverage data, including file storage.

    This class is the public supported API to the data that coverage.py
    collects during program execution.  It includes information about what code
    was executed. It does not include information from the analysis phase, to
    determine what lines could have been executed, or what lines were not
    executed.

    .. note::

        The data file is currently a SQLite database file, with a
        :ref:`documented schema &lt;dbschema&gt;`. The schema is subject to change
        though, so be careful about querying it directly. Use this API if you
        can to isolate yourself from changes.

    There are a number of kinds of data that can be collected:

    * **lines**: the line numbers of source lines that were executed.
      These are always available.

    * **arcs**: pairs of source and destination line numbers for transitions
      between source lines.  These are only available if branch coverage was
      used.

    * **file tracer names**: the module names of the file tracer plugins that
      handled each file in the data.

    Lines, arcs, and file tracer names are stored for each source file. File
    names in this API are case-sensitive, even on platforms with
    case-insensitive file systems.

    A data file either stores lines, or arcs, but not both.

    A data file is associated with the data when the :class:`CoverageData`
    is created, using the parameters `basename`, `suffix`, and `no_disk`. The
    base name can be queried with :meth:`base_filename`, and the actual file
    name being used is available from :meth:`data_filename`.

    To read an existing coverage.py data file, use :meth:`read`.  You can then
    access the line, arc, or file tracer data with :meth:`lines`, :meth:`arcs`,
    or :meth:`file_tracer`.

    The :meth:`has_arcs` method indicates whether arc data is available.  You
    can get a set of the files in the data with :meth:`measured_files`.  As
    with most Python containers, you can determine if there is any data at all
    by using this object as a boolean value.

    The contexts for each line in a file can be read with
    :meth:`contexts_by_lineno`.

    To limit querying to certain contexts, use :meth:`set_query_context` or
    :meth:`set_query_contexts`. These will narrow the focus of subsequent
    :meth:`lines`, :meth:`arcs`, and :meth:`contexts_by_lineno` calls. The set
    of all measured context names can be retrieved with
    :meth:`measured_contexts`.

    Most data files will be created by coverage.py itself, but you can use
    methods here to create data files if you like.  The :meth:`add_lines`,
    :meth:`add_arcs`, and :meth:`add_file_tracers` methods add data, in ways
    that are convenient for coverage.py.

    To record data for contexts, use :meth:`set_context` to set a context to
    be used for subsequent :meth:`add_lines` and :meth:`add_arcs` calls.

    To add a source file without any measured data, use :meth:`touch_file`,
    or :meth:`touch_files` for a list of such files.

    Write the data to its file with :meth:`write`.

    You can clear the data in memory with :meth:`erase`.  Two data collections
    can be combined by using :meth:`update` on one :class:`CoverageData`,
    passing it the other.

    Data in a :class:`CoverageData` can be serialized and deserialized with
    :meth:`dumps` and :meth:`loads`.

    The methods used during the coverage.py collection phase
    (:meth:`add_lines`, :meth:`add_arcs`, :meth:`set_context`, and
    :meth:`add_file_tracers`) are thread-safe.  Other methods may not be.

    """

    @others
</t>
<t tx="ekr.20221020070914.631">def __init__(self, basename=None, suffix=None, no_disk=False, warn=None, debug=None):
    """Create a :class:`CoverageData` object to hold coverage-measured data.

    Arguments:
        basename (str): the base name of the data file, defaulting to
            ".coverage". This can be a path to a file in another directory.
        suffix (str or bool): has the same meaning as the `data_suffix`
            argument to :class:`coverage.Coverage`.
        no_disk (bool): if True, keep all data in memory, and don't
            write any disk file.
        warn: a warning callback function, accepting a warning message
            argument.
        debug: a `DebugControl` object (optional)

    """
    self._no_disk = no_disk
    self._basename = os.path.abspath(basename or ".coverage")
    self._suffix = suffix
    self._warn = warn
    self._debug = debug or NoDebugging()

    self._choose_filename()
    self._file_map = {}
    # Maps thread ids to SqliteDb objects.
    self._dbs = {}
    self._pid = os.getpid()
    # Synchronize the operations used during collection.
    self._lock = threading.RLock()

    # Are we in sync with the data file?
    self._have_used = False

    self._has_lines = False
    self._has_arcs = False

    self._current_context = None
    self._current_context_id = None
    self._query_context_ids = None

</t>
<t tx="ekr.20221020070914.632">def _locked(method):            # pylint: disable=no-self-argument
    """A decorator for methods that should hold self._lock."""
    @functools.wraps(method)
    def _wrapped(self, *args, **kwargs):
        if self._debug.should("lock"):
            self._debug.write(f"Locking {self._lock!r} for {method.__name__}")
        with self._lock:
            if self._debug.should("lock"):
                self._debug.write(f"Locked  {self._lock!r} for {method.__name__}")
            # pylint: disable=not-callable
            return method(self, *args, **kwargs)
    return _wrapped

</t>
<t tx="ekr.20221020070914.633">def _choose_filename(self):
    """Set self._filename based on inited attributes."""
    if self._no_disk:
        self._filename = ":memory:"
    else:
        self._filename = self._basename
        suffix = filename_suffix(self._suffix)
        if suffix:
            self._filename += "." + suffix

</t>
<t tx="ekr.20221020070914.634">def _reset(self):
    """Reset our attributes."""
    if not self._no_disk:
        for db in self._dbs.values():
            db.close()
        self._dbs = {}
    self._file_map = {}
    self._have_used = False
    self._current_context_id = None

</t>
<t tx="ekr.20221020070914.635">def _open_db(self):
    """Open an existing db file, and read its metadata."""
    if self._debug.should("dataio"):
        self._debug.write(f"Opening data file {self._filename!r}")
    self._dbs[threading.get_ident()] = SqliteDb(self._filename, self._debug)
    self._read_db()

</t>
<t tx="ekr.20221020070914.636">def _read_db(self):
    """Read the metadata from a database so that we are ready to use it."""
    with self._dbs[threading.get_ident()] as db:
        try:
            schema_version, = db.execute_one("select version from coverage_schema")
        except Exception as exc:
            if "no such table: coverage_schema" in str(exc):
                self._init_db(db)
            else:
                raise DataError(
                    "Data file {!r} doesn't seem to be a coverage data file: {}".format(
                        self._filename, exc
                    )
                ) from exc
        else:
            if schema_version != SCHEMA_VERSION:
                raise DataError(
                    "Couldn't use data file {!r}: wrong schema: {} instead of {}".format(
                        self._filename, schema_version, SCHEMA_VERSION
                    )
                )

        for row in db.execute("select value from meta where key = 'has_arcs'"):
            self._has_arcs = bool(int(row[0]))
            self._has_lines = not self._has_arcs

        for file_id, path in db.execute("select id, path from file"):
            self._file_map[path] = file_id

</t>
<t tx="ekr.20221020070914.637">def _init_db(self, db):
    """Write the initial contents of the database."""
    if self._debug.should("dataio"):
        self._debug.write(f"Initing data file {self._filename!r}")
    db.executescript(SCHEMA)
    db.execute("insert into coverage_schema (version) values (?)", (SCHEMA_VERSION,))
    db.executemany(
        "insert or ignore into meta (key, value) values (?, ?)",
        [
            ("sys_argv", str(getattr(sys, "argv", None))),
            ("version", __version__),
            ("when", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")),
        ]
    )

</t>
<t tx="ekr.20221020070914.638">def _connect(self):
    """Get the SqliteDb object to use."""
    if threading.get_ident() not in self._dbs:
        self._open_db()
    return self._dbs[threading.get_ident()]

</t>
<t tx="ekr.20221020070914.639">def __bool__(self):
    if (threading.get_ident() not in self._dbs and not os.path.exists(self._filename)):
        return False
    try:
        with self._connect() as con:
            rows = con.execute("select * from file limit 1")
            return bool(list(rows))
    except CoverageException:
        return False

</t>
<t tx="ekr.20221020070914.64">def has_section(self, section):
    for section_prefix in self.section_prefixes:
        real_section = section_prefix + section
        has = configparser.RawConfigParser.has_section(self, real_section)
        if has:
            return real_section
    return False

</t>
<t tx="ekr.20221020070914.640">@contract(returns="bytes")
def dumps(self):
    """Serialize the current data to a byte string.

    The format of the serialized data is not documented. It is only
    suitable for use with :meth:`loads` in the same version of
    coverage.py.

    Note that this serialization is not what gets stored in coverage data
    files.  This method is meant to produce bytes that can be transmitted
    elsewhere and then deserialized with :meth:`loads`.

    Returns:
        A byte string of serialized data.

    .. versionadded:: 5.0

    """
    if self._debug.should("dataio"):
        self._debug.write(f"Dumping data from data file {self._filename!r}")
    with self._connect() as con:
        script = con.dump()
        return b"z" + zlib.compress(script.encode("utf-8"))

</t>
<t tx="ekr.20221020070914.641">@contract(data="bytes")
def loads(self, data):
    """Deserialize data from :meth:`dumps`.

    Use with a newly-created empty :class:`CoverageData` object.  It's
    undefined what happens if the object already has data in it.

    Note that this is not for reading data from a coverage data file.  It
    is only for use on data you produced with :meth:`dumps`.

    Arguments:
        data: A byte string of serialized data produced by :meth:`dumps`.

    .. versionadded:: 5.0

    """
    if self._debug.should("dataio"):
        self._debug.write(f"Loading data into data file {self._filename!r}")
    if data[:1] != b"z":
        raise DataError(
            f"Unrecognized serialization: {data[:40]!r} (head of {len(data)} bytes)"
        )
    script = zlib.decompress(data[1:]).decode("utf-8")
    self._dbs[threading.get_ident()] = db = SqliteDb(self._filename, self._debug)
    with db:
        db.executescript(script)
    self._read_db()
    self._have_used = True

</t>
<t tx="ekr.20221020070914.642">def _file_id(self, filename, add=False):
    """Get the file id for `filename`.

    If filename is not in the database yet, add it if `add` is True.
    If `add` is not True, return None.
    """
    if filename not in self._file_map:
        if add:
            with self._connect() as con:
                self._file_map[filename] = con.execute_for_rowid(
                    "insert or replace into file (path) values (?)",
                    (filename,)
                )
    return self._file_map.get(filename)

</t>
<t tx="ekr.20221020070914.643">def _context_id(self, context):
    """Get the id for a context."""
    assert context is not None
    self._start_using()
    with self._connect() as con:
        row = con.execute_one("select id from context where context = ?", (context,))
        if row is not None:
            return row[0]
        else:
            return None

</t>
<t tx="ekr.20221020070914.644">@_locked
def set_context(self, context):
    """Set the current context for future :meth:`add_lines` etc.

    `context` is a str, the name of the context to use for the next data
    additions.  The context persists until the next :meth:`set_context`.

    .. versionadded:: 5.0

    """
    if self._debug.should("dataop"):
        self._debug.write(f"Setting context: {context!r}")
    self._current_context = context
    self._current_context_id = None

</t>
<t tx="ekr.20221020070914.645">def _set_context_id(self):
    """Use the _current_context to set _current_context_id."""
    context = self._current_context or ""
    context_id = self._context_id(context)
    if context_id is not None:
        self._current_context_id = context_id
    else:
        with self._connect() as con:
            self._current_context_id = con.execute_for_rowid(
                "insert into context (context) values (?)",
                (context,)
            )

</t>
<t tx="ekr.20221020070914.646">def base_filename(self):
    """The base filename for storing data.

    .. versionadded:: 5.0

    """
    return self._basename

</t>
<t tx="ekr.20221020070914.647">def data_filename(self):
    """Where is the data stored?

    .. versionadded:: 5.0

    """
    return self._filename

</t>
<t tx="ekr.20221020070914.648">@_locked
def add_lines(self, line_data):
    """Add measured line data.

    `line_data` is a dictionary mapping file names to iterables of ints::

        { filename: { line1, line2, ... }, ...}

    """
    if self._debug.should("dataop"):
        self._debug.write("Adding lines: %d files, %d lines total" % (
            len(line_data), sum(len(lines) for lines in line_data.values())
        ))
    self._start_using()
    self._choose_lines_or_arcs(lines=True)
    if not line_data:
        return
    with self._connect() as con:
        self._set_context_id()
        for filename, linenos in line_data.items():
            linemap = nums_to_numbits(linenos)
            file_id = self._file_id(filename, add=True)
            query = "select numbits from line_bits where file_id = ? and context_id = ?"
            existing = list(con.execute(query, (file_id, self._current_context_id)))
            if existing:
                linemap = numbits_union(linemap, existing[0][0])

            con.execute(
                "insert or replace into line_bits " +
                " (file_id, context_id, numbits) values (?, ?, ?)",
                (file_id, self._current_context_id, linemap),
            )

</t>
<t tx="ekr.20221020070914.649">@_locked
def add_arcs(self, arc_data):
    """Add measured arc data.

    `arc_data` is a dictionary mapping file names to iterables of pairs of
    ints::

        { filename: { (l1,l2), (l1,l2), ... }, ...}

    """
    if self._debug.should("dataop"):
        self._debug.write("Adding arcs: %d files, %d arcs total" % (
            len(arc_data), sum(len(arcs) for arcs in arc_data.values())
        ))
    self._start_using()
    self._choose_lines_or_arcs(arcs=True)
    if not arc_data:
        return
    with self._connect() as con:
        self._set_context_id()
        for filename, arcs in arc_data.items():
            file_id = self._file_id(filename, add=True)
            data = [(file_id, self._current_context_id, fromno, tono) for fromno, tono in arcs]
            con.executemany(
                "insert or ignore into arc " +
                "(file_id, context_id, fromno, tono) values (?, ?, ?, ?)",
                data,
            )

</t>
<t tx="ekr.20221020070914.65">def options(self, section):
    for section_prefix in self.section_prefixes:
        real_section = section_prefix + section
        if configparser.RawConfigParser.has_section(self, real_section):
            return configparser.RawConfigParser.options(self, real_section)
    raise ConfigError(f"No section: {section!r}")

</t>
<t tx="ekr.20221020070914.650">def _choose_lines_or_arcs(self, lines=False, arcs=False):
    """Force the data file to choose between lines and arcs."""
    assert lines or arcs
    assert not (lines and arcs)
    if lines and self._has_arcs:
        if self._debug.should("dataop"):
            self._debug.write("Error: Can't add line measurements to existing branch data")
        raise DataError("Can't add line measurements to existing branch data")
    if arcs and self._has_lines:
        if self._debug.should("dataop"):
            self._debug.write("Error: Can't add branch measurements to existing line data")
        raise DataError("Can't add branch measurements to existing line data")
    if not self._has_arcs and not self._has_lines:
        self._has_lines = lines
        self._has_arcs = arcs
        with self._connect() as con:
            con.execute(
                "insert or ignore into meta (key, value) values (?, ?)",
                ("has_arcs", str(int(arcs)))
            )

</t>
<t tx="ekr.20221020070914.651">@_locked
def add_file_tracers(self, file_tracers):
    """Add per-file plugin information.

    `file_tracers` is { filename: plugin_name, ... }

    """
    if self._debug.should("dataop"):
        self._debug.write("Adding file tracers: %d files" % (len(file_tracers),))
    if not file_tracers:
        return
    self._start_using()
    with self._connect() as con:
        for filename, plugin_name in file_tracers.items():
            file_id = self._file_id(filename)
            if file_id is None:
                raise DataError(
                    f"Can't add file tracer data for unmeasured file '{filename}'"
                )

            existing_plugin = self.file_tracer(filename)
            if existing_plugin:
                if existing_plugin != plugin_name:
                    raise DataError(
                        "Conflicting file tracer name for '{}': {!r} vs {!r}".format(
                            filename, existing_plugin, plugin_name,
                        )
                    )
            elif plugin_name:
                con.execute(
                    "insert into tracer (file_id, tracer) values (?, ?)",
                    (file_id, plugin_name)
                )

</t>
<t tx="ekr.20221020070914.652">def touch_file(self, filename, plugin_name=""):
    """Ensure that `filename` appears in the data, empty if needed.

    `plugin_name` is the name of the plugin responsible for this file. It is used
    to associate the right filereporter, etc.
    """
    self.touch_files([filename], plugin_name)

</t>
<t tx="ekr.20221020070914.653">def touch_files(self, filenames, plugin_name=""):
    """Ensure that `filenames` appear in the data, empty if needed.

    `plugin_name` is the name of the plugin responsible for these files. It is used
    to associate the right filereporter, etc.
    """
    if self._debug.should("dataop"):
        self._debug.write(f"Touching {filenames!r}")
    self._start_using()
    with self._connect(): # Use this to get one transaction.
        if not self._has_arcs and not self._has_lines:
            raise DataError("Can't touch files in an empty CoverageData")

        for filename in filenames:
            self._file_id(filename, add=True)
            if plugin_name:
                # Set the tracer for this file
                self.add_file_tracers({filename: plugin_name})

</t>
<t tx="ekr.20221020070914.654">def update(self, other_data, aliases=None):
    """Update this data with data from several other :class:`CoverageData` instances.

    If `aliases` is provided, it's a `PathAliases` object that is used to
    re-map paths to match the local machine's.
    """
    if self._debug.should("dataop"):
        self._debug.write("Updating with data from {!r}".format(
            getattr(other_data, "_filename", "???"),
        ))
    if self._has_lines and other_data._has_arcs:
        raise DataError("Can't combine arc data with line data")
    if self._has_arcs and other_data._has_lines:
        raise DataError("Can't combine line data with arc data")

    aliases = aliases or PathAliases()

    # Force the database we're writing to to exist before we start nesting contexts.
    self._start_using()

    # Collector for all arcs, lines and tracers
    other_data.read()
    with other_data._connect() as con:
        # Get files data.
        cur = con.execute("select path from file")
        files = {path: aliases.map(path) for (path,) in cur}
        cur.close()

        # Get contexts data.
        cur = con.execute("select context from context")
        contexts = [context for (context,) in cur]
        cur.close()

        # Get arc data.
        cur = con.execute(
            "select file.path, context.context, arc.fromno, arc.tono " +
            "from arc " +
            "inner join file on file.id = arc.file_id " +
            "inner join context on context.id = arc.context_id"
        )
        arcs = [(files[path], context, fromno, tono) for (path, context, fromno, tono) in cur]
        cur.close()

        # Get line data.
        cur = con.execute(
            "select file.path, context.context, line_bits.numbits " +
            "from line_bits " +
            "inner join file on file.id = line_bits.file_id " +
            "inner join context on context.id = line_bits.context_id"
        )
        lines = {(files[path], context): numbits for (path, context, numbits) in cur}
        cur.close()

        # Get tracer data.
        cur = con.execute(
            "select file.path, tracer " +
            "from tracer " +
            "inner join file on file.id = tracer.file_id"
        )
        tracers = {files[path]: tracer for (path, tracer) in cur}
        cur.close()

    with self._connect() as con:
        con.con.isolation_level = "IMMEDIATE"

        # Get all tracers in the DB. Files not in the tracers are assumed
        # to have an empty string tracer. Since Sqlite does not support
        # full outer joins, we have to make two queries to fill the
        # dictionary.
        this_tracers = {path: "" for path, in con.execute("select path from file")}
        this_tracers.update({
            aliases.map(path): tracer
            for path, tracer in con.execute(
                "select file.path, tracer from tracer " +
                "inner join file on file.id = tracer.file_id"
            )
        })

        # Create all file and context rows in the DB.
        con.executemany(
            "insert or ignore into file (path) values (?)",
            ((file,) for file in files.values())
        )
        file_ids = {
            path: id
            for id, path in con.execute("select id, path from file")
        }
        self._file_map.update(file_ids)
        con.executemany(
            "insert or ignore into context (context) values (?)",
            ((context,) for context in contexts)
        )
        context_ids = {
            context: id
            for id, context in con.execute("select id, context from context")
        }

        # Prepare tracers and fail, if a conflict is found.
        # tracer_paths is used to ensure consistency over the tracer data
        # and tracer_map tracks the tracers to be inserted.
        tracer_map = {}
        for path in files.values():
            this_tracer = this_tracers.get(path)
            other_tracer = tracers.get(path, "")
            # If there is no tracer, there is always the None tracer.
            if this_tracer is not None and this_tracer != other_tracer:
                raise DataError(
                    "Conflicting file tracer name for '{}': {!r} vs {!r}".format(
                        path, this_tracer, other_tracer
                    )
                )
            tracer_map[path] = other_tracer

        # Prepare arc and line rows to be inserted by converting the file
        # and context strings with integer ids. Then use the efficient
        # `executemany()` to insert all rows at once.
        arc_rows = (
            (file_ids[file], context_ids[context], fromno, tono)
            for file, context, fromno, tono in arcs
        )

        # Get line data.
        cur = con.execute(
            "select file.path, context.context, line_bits.numbits " +
            "from line_bits " +
            "inner join file on file.id = line_bits.file_id " +
            "inner join context on context.id = line_bits.context_id"
        )
        for path, context, numbits in cur:
            key = (aliases.map(path), context)
            if key in lines:
                numbits = numbits_union(lines[key], numbits)
            lines[key] = numbits
        cur.close()

        if arcs:
            self._choose_lines_or_arcs(arcs=True)

            # Write the combined data.
            con.executemany(
                "insert or ignore into arc " +
                "(file_id, context_id, fromno, tono) values (?, ?, ?, ?)",
                arc_rows
            )

        if lines:
            self._choose_lines_or_arcs(lines=True)
            con.execute("delete from line_bits")
            con.executemany(
                "insert into line_bits " +
                "(file_id, context_id, numbits) values (?, ?, ?)",
                [
                    (file_ids[file], context_ids[context], numbits)
                    for (file, context), numbits in lines.items()
                ]
            )
        con.executemany(
            "insert or ignore into tracer (file_id, tracer) values (?, ?)",
            ((file_ids[filename], tracer) for filename, tracer in tracer_map.items())
        )

    if not self._no_disk:
        # Update all internal cache data.
        self._reset()
        self.read()

</t>
<t tx="ekr.20221020070914.655">def erase(self, parallel=False):
    """Erase the data in this object.

    If `parallel` is true, then also deletes data files created from the
    basename by parallel-mode.

    """
    self._reset()
    if self._no_disk:
        return
    if self._debug.should("dataio"):
        self._debug.write(f"Erasing data file {self._filename!r}")
    file_be_gone(self._filename)
    if parallel:
        data_dir, local = os.path.split(self._filename)
        local_abs_path = os.path.join(os.path.abspath(data_dir), local)
        pattern = glob.escape(local_abs_path) + ".*"
        for filename in glob.glob(pattern):
            if self._debug.should("dataio"):
                self._debug.write(f"Erasing parallel data file {filename!r}")
            file_be_gone(filename)

</t>
<t tx="ekr.20221020070914.656">def read(self):
    """Start using an existing data file."""
    if os.path.exists(self._filename):
        with self._connect():
            self._have_used = True

</t>
<t tx="ekr.20221020070914.657">def write(self):
    """Ensure the data is written to the data file."""
    pass

</t>
<t tx="ekr.20221020070914.658">def _start_using(self):
    """Call this before using the database at all."""
    if self._pid != os.getpid():
        # Looks like we forked! Have to start a new data file.
        self._reset()
        self._choose_filename()
        self._pid = os.getpid()
    if not self._have_used:
        self.erase()
    self._have_used = True

</t>
<t tx="ekr.20221020070914.659">def has_arcs(self):
    """Does the database have arcs (True) or lines (False)."""
    return bool(self._has_arcs)

</t>
<t tx="ekr.20221020070914.66">def get_section(self, section):
    """Get the contents of a section, as a dictionary."""
    d = {}
    for opt in self.options(section):
        d[opt] = self.get(section, opt)
    return d

</t>
<t tx="ekr.20221020070914.660">def measured_files(self):
    """A set of all files that had been measured."""
    return set(self._file_map)

</t>
<t tx="ekr.20221020070914.661">def measured_contexts(self):
    """A set of all contexts that have been measured.

    .. versionadded:: 5.0

    """
    self._start_using()
    with self._connect() as con:
        contexts = {row[0] for row in con.execute("select distinct(context) from context")}
    return contexts

</t>
<t tx="ekr.20221020070914.662">def file_tracer(self, filename):
    """Get the plugin name of the file tracer for a file.

    Returns the name of the plugin that handles this file.  If the file was
    measured, but didn't use a plugin, then "" is returned.  If the file
    was not measured, then None is returned.

    """
    self._start_using()
    with self._connect() as con:
        file_id = self._file_id(filename)
        if file_id is None:
            return None
        row = con.execute_one("select tracer from tracer where file_id = ?", (file_id,))
        if row is not None:
            return row[0] or ""
        return ""   # File was measured, but no tracer associated.

</t>
<t tx="ekr.20221020070914.663">def set_query_context(self, context):
    """Set a context for subsequent querying.

    The next :meth:`lines`, :meth:`arcs`, or :meth:`contexts_by_lineno`
    calls will be limited to only one context.  `context` is a string which
    must match a context exactly.  If it does not, no exception is raised,
    but queries will return no data.

    .. versionadded:: 5.0

    """
    self._start_using()
    with self._connect() as con:
        cur = con.execute("select id from context where context = ?", (context,))
        self._query_context_ids = [row[0] for row in cur.fetchall()]

</t>
<t tx="ekr.20221020070914.664">def set_query_contexts(self, contexts):
    """Set a number of contexts for subsequent querying.

    The next :meth:`lines`, :meth:`arcs`, or :meth:`contexts_by_lineno`
    calls will be limited to the specified contexts.  `contexts` is a list
    of Python regular expressions.  Contexts will be matched using
    :func:`re.search &lt;python:re.search&gt;`.  Data will be included in query
    results if they are part of any of the contexts matched.

    .. versionadded:: 5.0

    """
    self._start_using()
    if contexts:
        with self._connect() as con:
            context_clause = " or ".join(["context regexp ?"] * len(contexts))
            cur = con.execute("select id from context where " + context_clause, contexts)
            self._query_context_ids = [row[0] for row in cur.fetchall()]
    else:
        self._query_context_ids = None

</t>
<t tx="ekr.20221020070914.665">def lines(self, filename):
    """Get the list of lines executed for a source file.

    If the file was not measured, returns None.  A file might be measured,
    and have no lines executed, in which case an empty list is returned.

    If the file was executed, returns a list of integers, the line numbers
    executed in the file. The list is in no particular order.

    """
    self._start_using()
    if self.has_arcs():
        arcs = self.arcs(filename)
        if arcs is not None:
            all_lines = itertools.chain.from_iterable(arcs)
            return list({l for l in all_lines if l &gt; 0})

    with self._connect() as con:
        file_id = self._file_id(filename)
        if file_id is None:
            return None
        else:
            query = "select numbits from line_bits where file_id = ?"
            data = [file_id]
            if self._query_context_ids is not None:
                ids_array = ", ".join("?" * len(self._query_context_ids))
                query += " and context_id in (" + ids_array + ")"
                data += self._query_context_ids
            bitmaps = list(con.execute(query, data))
            nums = set()
            for row in bitmaps:
                nums.update(numbits_to_nums(row[0]))
            return list(nums)

</t>
<t tx="ekr.20221020070914.666">def arcs(self, filename):
    """Get the list of arcs executed for a file.

    If the file was not measured, returns None.  A file might be measured,
    and have no arcs executed, in which case an empty list is returned.

    If the file was executed, returns a list of 2-tuples of integers. Each
    pair is a starting line number and an ending line number for a
    transition from one line to another. The list is in no particular
    order.

    Negative numbers have special meaning.  If the starting line number is
    -N, it represents an entry to the code object that starts at line N.
    If the ending ling number is -N, it's an exit from the code object that
    starts at line N.

    """
    self._start_using()
    with self._connect() as con:
        file_id = self._file_id(filename)
        if file_id is None:
            return None
        else:
            query = "select distinct fromno, tono from arc where file_id = ?"
            data = [file_id]
            if self._query_context_ids is not None:
                ids_array = ", ".join("?" * len(self._query_context_ids))
                query += " and context_id in (" + ids_array + ")"
                data += self._query_context_ids
            arcs = con.execute(query, data)
            return list(arcs)

</t>
<t tx="ekr.20221020070914.667">def contexts_by_lineno(self, filename):
    """Get the contexts for each line in a file.

    Returns:
        A dict mapping line numbers to a list of context names.

    .. versionadded:: 5.0

    """
    self._start_using()
    with self._connect() as con:
        file_id = self._file_id(filename)
        if file_id is None:
            return {}

        lineno_contexts_map = collections.defaultdict(set)
        if self.has_arcs():
            query = (
                "select arc.fromno, arc.tono, context.context " +
                "from arc, context " +
                "where arc.file_id = ? and arc.context_id = context.id"
            )
            data = [file_id]
            if self._query_context_ids is not None:
                ids_array = ", ".join("?" * len(self._query_context_ids))
                query += " and arc.context_id in (" + ids_array + ")"
                data += self._query_context_ids
            for fromno, tono, context in con.execute(query, data):
                if fromno &gt; 0:
                    lineno_contexts_map[fromno].add(context)
                if tono &gt; 0:
                    lineno_contexts_map[tono].add(context)
        else:
            query = (
                "select l.numbits, c.context from line_bits l, context c " +
                "where l.context_id = c.id " +
                "and file_id = ?"
            )
            data = [file_id]
            if self._query_context_ids is not None:
                ids_array = ", ".join("?" * len(self._query_context_ids))
                query += " and l.context_id in (" + ids_array + ")"
                data += self._query_context_ids
            for numbits, context in con.execute(query, data):
                for lineno in numbits_to_nums(numbits):
                    lineno_contexts_map[lineno].add(context)

    return {lineno: list(contexts) for lineno, contexts in lineno_contexts_map.items()}

</t>
<t tx="ekr.20221020070914.668">@classmethod
def sys_info(cls):
    """Our information for `Coverage.sys_info`.

    Returns a list of (key, value) pairs.

    """
    with SqliteDb(":memory:", debug=NoDebugging()) as db:
        temp_store = [row[0] for row in db.execute("pragma temp_store")]
        copts = [row[0] for row in db.execute("pragma compile_options")]
        copts = textwrap.wrap(", ".join(copts), width=75)

    return [
        ("sqlite3_version", sqlite3.version),
        ("sqlite3_sqlite_version", sqlite3.sqlite_version),
        ("sqlite3_temp_store", temp_store),
        ("sqlite3_compile_options", copts),
    ]


</t>
<t tx="ekr.20221020070914.669">def filename_suffix(suffix):
    """Compute a filename suffix for a data file.

    If `suffix` is a string or None, simply return it. If `suffix` is True,
    then build a suffix incorporating the hostname, process id, and a random
    number.

    Returns a string or None.

    """
    if suffix is True:
        # If data_suffix was a simple true value, then make a suffix with
        # plenty of distinguishing information.  We do this here in
        # `save()` at the last minute so that the pid will be correct even
        # if the process forks.
        dice = random.Random(os.urandom(8)).randint(0, 999999)
        suffix = "%s.%s.%06d" % (socket.gethostname(), os.getpid(), dice)
    return suffix


</t>
<t tx="ekr.20221020070914.67">def get(self, section, option, *args, **kwargs):
    """Get a value, replacing environment variables also.

    The arguments are the same as `RawConfigParser.get`, but in the found
    value, ``$WORD`` or ``${WORD}`` are replaced by the value of the
    environment variable ``WORD``.

    Returns the finished value.

    """
    for section_prefix in self.section_prefixes:
        real_section = section_prefix + section
        if configparser.RawConfigParser.has_option(self, real_section, option):
            break
    else:
        raise ConfigError(f"No option {option!r} in section: {section!r}")

    v = configparser.RawConfigParser.get(self, real_section, option, *args, **kwargs)
    v = substitute_variables(v, os.environ)
    return v

</t>
<t tx="ekr.20221020070914.670">class SqliteDb(SimpleReprMixin):
    """A simple abstraction over a SQLite database.

    Use as a context manager, then you can use it like a
    :class:`python:sqlite3.Connection` object::

        with SqliteDb(filename, debug_control) as db:
            db.execute("insert into schema (version) values (?)", (SCHEMA_VERSION,))

    """
    @others
</t>
<t tx="ekr.20221020070914.671">def __init__(self, filename, debug):
    self.debug = debug
    self.filename = filename
    self.nest = 0
    self.con = None

</t>
<t tx="ekr.20221020070914.672">def _connect(self):
    """Connect to the db and do universal initialization."""
    if self.con is not None:
        return

    # It can happen that Python switches threads while the tracer writes
    # data. The second thread will also try to write to the data,
    # effectively causing a nested context. However, given the idempotent
    # nature of the tracer operations, sharing a connection among threads
    # is not a problem.
    if self.debug.should("sql"):
        self.debug.write(f"Connecting to {self.filename!r}")
    try:
        self.con = sqlite3.connect(self.filename, check_same_thread=False)
    except sqlite3.Error as exc:
        raise DataError(f"Couldn't use data file {self.filename!r}: {exc}") from exc

    self.con.create_function("REGEXP", 2, lambda txt, pat: re.search(txt, pat) is not None)

    # This pragma makes writing faster. It disables rollbacks, but we never need them.
    # PyPy needs the .close() calls here, or sqlite gets twisted up:
    # https://bitbucket.org/pypy/pypy/issues/2872/default-isolation-mode-is-different-on
    self.execute("pragma journal_mode=off").close()
    # This pragma makes writing faster.
    self.execute("pragma synchronous=off").close()

</t>
<t tx="ekr.20221020070914.673">def close(self):
    """If needed, close the connection."""
    if self.con is not None and self.filename != ":memory:":
        self.con.close()
        self.con = None

</t>
<t tx="ekr.20221020070914.674">def __enter__(self):
    if self.nest == 0:
        self._connect()
        self.con.__enter__()
    self.nest += 1
    return self

</t>
<t tx="ekr.20221020070914.675">def __exit__(self, exc_type, exc_value, traceback):
    self.nest -= 1
    if self.nest == 0:
        try:
            self.con.__exit__(exc_type, exc_value, traceback)
            self.close()
        except Exception as exc:
            if self.debug.should("sql"):
                self.debug.write(f"EXCEPTION from __exit__: {exc}")
            raise DataError(f"Couldn't end data file {self.filename!r}: {exc}") from exc

</t>
<t tx="ekr.20221020070914.676">def execute(self, sql, parameters=()):
    """Same as :meth:`python:sqlite3.Connection.execute`."""
    if self.debug.should("sql"):
        tail = f" with {parameters!r}" if parameters else ""
        self.debug.write(f"Executing {sql!r}{tail}")
    try:
        try:
            return self.con.execute(sql, parameters)
        except Exception:
            # In some cases, an error might happen that isn't really an
            # error.  Try again immediately.
            # https://github.com/nedbat/coveragepy/issues/1010
            return self.con.execute(sql, parameters)
    except sqlite3.Error as exc:
        msg = str(exc)
        try:
            # `execute` is the first thing we do with the database, so try
            # hard to provide useful hints if something goes wrong now.
            with open(self.filename, "rb") as bad_file:
                cov4_sig = b"!coverage.py: This is a private format"
                if bad_file.read(len(cov4_sig)) == cov4_sig:
                    msg = (
                        "Looks like a coverage 4.x data file. " +
                        "Are you mixing versions of coverage?"
                    )
        except Exception:   # pragma: cant happen
            pass
        if self.debug.should("sql"):
            self.debug.write(f"EXCEPTION from execute: {msg}")
        raise DataError(f"Couldn't use data file {self.filename!r}: {msg}") from exc

</t>
<t tx="ekr.20221020070914.677">def execute_for_rowid(self, sql, parameters=()):
    """Like execute, but returns the lastrowid."""
    con = self.execute(sql, parameters)
    rowid = con.lastrowid
    if self.debug.should("sqldata"):
        self.debug.write(f"Row id result: {rowid!r}")
    return rowid

</t>
<t tx="ekr.20221020070914.678">def execute_one(self, sql, parameters=()):
    """Execute a statement and return the one row that results.

    This is like execute(sql, parameters).fetchone(), except it is
    correct in reading the entire result set.  This will raise an
    exception if more than one row results.

    Returns a row, or None if there were no rows.
    """
    rows = list(self.execute(sql, parameters))
    if len(rows) == 0:
        return None
    elif len(rows) == 1:
        return rows[0]
    else:
        raise AssertionError(f"SQL {sql!r} shouldn't return {len(rows)} rows")

</t>
<t tx="ekr.20221020070914.679">def executemany(self, sql, data):
    """Same as :meth:`python:sqlite3.Connection.executemany`."""
    if self.debug.should("sql"):
        data = list(data)
        final = ":" if self.debug.should("sqldata") else ""
        self.debug.write(f"Executing many {sql!r} with {len(data)} rows{final}")
        if self.debug.should("sqldata"):
            for i, row in enumerate(data):
                self.debug.write(f"{i:4d}: {row!r}")
    try:
        return self.con.executemany(sql, data)
    except Exception:   # pragma: cant happen
        # In some cases, an error might happen that isn't really an
        # error.  Try again immediately.
        # https://github.com/nedbat/coveragepy/issues/1010
        return self.con.executemany(sql, data)

</t>
<t tx="ekr.20221020070914.68">def getlist(self, section, option):
    """Read a list of strings.

    The value of `section` and `option` is treated as a comma- and newline-
    separated list of strings.  Each value is stripped of whitespace.

    Returns the list of strings.

    """
    value_list = self.get(section, option)
    values = []
    for value_line in value_list.split('\n'):
        for value in value_line.split(','):
            value = value.strip()
            if value:
                values.append(value)
    return values

</t>
<t tx="ekr.20221020070914.680">def executescript(self, script):
    """Same as :meth:`python:sqlite3.Connection.executescript`."""
    if self.debug.should("sql"):
        self.debug.write("Executing script with {} chars: {}".format(
            len(script), clipped_repr(script, 100),
        ))
    self.con.executescript(script)

</t>
<t tx="ekr.20221020070914.681">def dump(self):
    """Return a multi-line string, the SQL dump of the database."""
    return "\n".join(self.con.iterdump())
</t>
<t tx="ekr.20221020070914.682"></t>
<t tx="ekr.20221020070914.683">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Summary reporting"""

import sys

from coverage.exceptions import ConfigError, NoDataError
from coverage.misc import human_sorted_items
from coverage.report import get_analysis_to_report
from coverage.results import Numbers


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.684">class SummaryReporter:
    """A reporter for writing the summary report."""

    @others
</t>
<t tx="ekr.20221020070914.685">def __init__(self, coverage):
    self.coverage = coverage
    self.config = self.coverage.config
    self.branches = coverage.get_data().has_arcs()
    self.outfile = None
    self.fr_analysis = []
    self.skipped_count = 0
    self.empty_count = 0
    self.total = Numbers(precision=self.config.precision)
    self.fmt_err = "%s   %s: %s"

</t>
<t tx="ekr.20221020070914.686">def writeout(self, line):
    """Write a line to the output, adding a newline."""
    self.outfile.write(line.rstrip())
    self.outfile.write("\n")

</t>
<t tx="ekr.20221020070914.687">def report(self, morfs, outfile=None):
    """Writes a report summarizing coverage statistics per module.

    `outfile` is a file object to write the summary to. It must be opened
    for native strings (bytes on Python 2, Unicode on Python 3).

    """
    self.outfile = outfile or sys.stdout

    self.coverage.get_data().set_query_contexts(self.config.report_contexts)
    for fr, analysis in get_analysis_to_report(self.coverage, morfs):
        self.report_one_file(fr, analysis)

    # Prepare the formatting strings, header, and column sorting.
    max_name = max([len(fr.relative_filename()) for (fr, analysis) in self.fr_analysis] + [5])
    fmt_name = "%%- %ds  " % max_name
    fmt_skip_covered = "\n%s file%s skipped due to complete coverage."
    fmt_skip_empty = "\n%s empty file%s skipped."

    header = (fmt_name % "Name") + " Stmts   Miss"
    fmt_coverage = fmt_name + "%6d %6d"
    if self.branches:
        header += " Branch BrPart"
        fmt_coverage += " %6d %6d"
    width100 = Numbers(precision=self.config.precision).pc_str_width()
    header += "%*s" % (width100+4, "Cover")
    fmt_coverage += "%%%ds%%%%" % (width100+3,)
    if self.config.show_missing:
        header += "   Missing"
        fmt_coverage += "   %s"
    rule = "-" * len(header)

    column_order = dict(name=0, stmts=1, miss=2, cover=-1)
    if self.branches:
        column_order.update(dict(branch=3, brpart=4))

    # Write the header
    self.writeout(header)
    self.writeout(rule)

    # `lines` is a list of pairs, (line text, line values).  The line text
    # is a string that will be printed, and line values is a tuple of
    # sortable values.
    lines = []

    for (fr, analysis) in self.fr_analysis:
        nums = analysis.numbers

        args = (fr.relative_filename(), nums.n_statements, nums.n_missing)
        if self.branches:
            args += (nums.n_branches, nums.n_partial_branches)
        args += (nums.pc_covered_str,)
        if self.config.show_missing:
            args += (analysis.missing_formatted(branches=True),)
        text = fmt_coverage % args
        # Add numeric percent coverage so that sorting makes sense.
        args += (nums.pc_covered,)
        lines.append((text, args))

    # Sort the lines and write them out.
    sort_option = (self.config.sort or "name").lower()
    reverse = False
    if sort_option[0] == '-':
        reverse = True
        sort_option = sort_option[1:]
    elif sort_option[0] == '+':
        sort_option = sort_option[1:]

    if sort_option == "name":
        lines = human_sorted_items(lines, reverse=reverse)
    else:
        position = column_order.get(sort_option)
        if position is None:
            raise ConfigError(f"Invalid sorting option: {self.config.sort!r}")
        lines.sort(key=lambda l: (l[1][position], l[0]), reverse=reverse)

    for line in lines:
        self.writeout(line[0])

    # Write a TOTAL line if we had at least one file.
    if self.total.n_files &gt; 0:
        self.writeout(rule)
        args = ("TOTAL", self.total.n_statements, self.total.n_missing)
        if self.branches:
            args += (self.total.n_branches, self.total.n_partial_branches)
        args += (self.total.pc_covered_str,)
        if self.config.show_missing:
            args += ("",)
        self.writeout(fmt_coverage % args)

    # Write other final lines.
    if not self.total.n_files and not self.skipped_count:
        raise NoDataError("No data to report.")

    if self.config.skip_covered and self.skipped_count:
        self.writeout(
            fmt_skip_covered % (self.skipped_count, 's' if self.skipped_count &gt; 1 else '')
        )
    if self.config.skip_empty and self.empty_count:
        self.writeout(
            fmt_skip_empty % (self.empty_count, 's' if self.empty_count &gt; 1 else '')
        )

    return self.total.n_statements and self.total.pc_covered

</t>
<t tx="ekr.20221020070914.688">def report_one_file(self, fr, analysis):
    """Report on just one file, the callback from report()."""
    nums = analysis.numbers
    self.total += nums

    no_missing_lines = (nums.n_missing == 0)
    no_missing_branches = (nums.n_partial_branches == 0)
    if self.config.skip_covered and no_missing_lines and no_missing_branches:
        # Don't report on 100% files.
        self.skipped_count += 1
    elif self.config.skip_empty and nums.n_statements == 0:
        # Don't report on empty files.
        self.empty_count += 1
    else:
        self.fr_analysis.append((fr, analysis))
</t>
<t tx="ekr.20221020070914.689">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""A simple Python template renderer, for a nano-subset of Django syntax.

For a detailed discussion of this code, see this chapter from 500 Lines:
http://aosabook.org/en/500L/a-template-engine.html

"""

# Coincidentally named the same as http://code.activestate.com/recipes/496702/

import re


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.69">def getregexlist(self, section, option):
    """Read a list of full-line regexes.

    The value of `section` and `option` is treated as a newline-separated
    list of regexes.  Each value is stripped of whitespace.

    Returns the list of strings.

    """
    line_list = self.get(section, option)
    value_list = []
    for value in line_list.splitlines():
        value = value.strip()
        try:
            re.compile(value)
        except re.error as e:
            raise ConfigError(
                f"Invalid [{section}].{option} value {value!r}: {e}"
            ) from e
        if value:
            value_list.append(value)
    return value_list


</t>
<t tx="ekr.20221020070914.690">class TempliteSyntaxError(ValueError):
    """Raised when a template has a syntax error."""
    pass


</t>
<t tx="ekr.20221020070914.691">class TempliteValueError(ValueError):
    """Raised when an expression won't evaluate in a template."""
    pass


</t>
<t tx="ekr.20221020070914.692">class CodeBuilder:
    """Build source code conveniently."""

    @others
</t>
<t tx="ekr.20221020070914.693">def __init__(self, indent=0):
    self.code = []
    self.indent_level = indent

</t>
<t tx="ekr.20221020070914.694">def __str__(self):
    return "".join(str(c) for c in self.code)

</t>
<t tx="ekr.20221020070914.695">def add_line(self, line):
    """Add a line of source to the code.

    Indentation and newline will be added for you, don't provide them.

    """
    self.code.extend([" " * self.indent_level, line, "\n"])

</t>
<t tx="ekr.20221020070914.696">def add_section(self):
    """Add a section, a sub-CodeBuilder."""
    section = CodeBuilder(self.indent_level)
    self.code.append(section)
    return section

</t>
<t tx="ekr.20221020070914.697">INDENT_STEP = 4      # PEP8 says so!

</t>
<t tx="ekr.20221020070914.698">def indent(self):
    """Increase the current indent for following lines."""
    self.indent_level += self.INDENT_STEP

</t>
<t tx="ekr.20221020070914.699">def dedent(self):
    """Decrease the current indent for following lines."""
    self.indent_level -= self.INDENT_STEP

</t>
<t tx="ekr.20221020070914.7">def annotate_file(self, fr, analysis):
    """Annotate a single file.

    `fr` is the FileReporter for the file to annotate.

    """
    statements = sorted(analysis.statements)
    missing = sorted(analysis.missing)
    excluded = sorted(analysis.excluded)

    if self.directory:
        ensure_dir(self.directory)
        dest_file = os.path.join(self.directory, flat_rootname(fr.relative_filename()))
        if dest_file.endswith("_py"):
            dest_file = dest_file[:-3] + ".py"
        dest_file += ",cover"
    else:
        dest_file = fr.filename + ",cover"

    with open(dest_file, 'w', encoding='utf-8') as dest:
        i = j = 0
        covered = True
        source = fr.source()
        for lineno, line in enumerate(source.splitlines(True), start=1):
            while i &lt; len(statements) and statements[i] &lt; lineno:
                i += 1
            while j &lt; len(missing) and missing[j] &lt; lineno:
                j += 1
            if i &lt; len(statements) and statements[i] == lineno:
                covered = j &gt;= len(missing) or missing[j] &gt; lineno
            if self.blank_re.match(line):
                dest.write('  ')
            elif self.else_re.match(line):
                # Special logic for lines containing only 'else:'.
                if j &gt;= len(missing):
                    dest.write('&gt; ')
                elif statements[i] == missing[j]:
                    dest.write('! ')
                else:
                    dest.write('&gt; ')
            elif lineno in excluded:
                dest.write('- ')
            elif covered:
                dest.write('&gt; ')
            else:
                dest.write('! ')

            dest.write(line)
</t>
<t tx="ekr.20221020070914.70"># The default line exclusion regexes.
DEFAULT_EXCLUDE = [
    r'#\s*(pragma|PRAGMA)[:\s]?\s*(no|NO)\s*(cover|COVER)',
]

# The default partial branch regexes, to be modified by the user.
DEFAULT_PARTIAL = [
    r'#\s*(pragma|PRAGMA)[:\s]?\s*(no|NO)\s*(branch|BRANCH)',
]

# The default partial branch regexes, based on Python semantics.
# These are any Python branching constructs that can't actually execute all
# their branches.
DEFAULT_PARTIAL_ALWAYS = [
    'while (True|1|False|0):',
    'if (True|1|False|0):',
]


</t>
<t tx="ekr.20221020070914.700">def get_globals(self):
    """Execute the code, and return a dict of globals it defines."""
    # A check that the caller really finished all the blocks they started.
    assert self.indent_level == 0
    # Get the Python source as a single string.
    python_source = str(self)
    # Execute the source, defining globals, and return them.
    global_namespace = {}
    exec(python_source, global_namespace)
    return global_namespace


</t>
<t tx="ekr.20221020070914.701">class Templite:
    """A simple template renderer, for a nano-subset of Django syntax.

    Supported constructs are extended variable access::

        {{var.modifier.modifier|filter|filter}}

    loops::

        {% for var in list %}...{% endfor %}

    and ifs::

        {% if var %}...{% endif %}

    Comments are within curly-hash markers::

        {# This will be ignored #}

    Lines between `{% joined %}` and `{% endjoined %}` will have lines stripped
    and joined.  Be careful, this could join words together!

    Any of these constructs can have a hyphen at the end (`-}}`, `-%}`, `-#}`),
    which will collapse the whitespace following the tag.

    Construct a Templite with the template text, then use `render` against a
    dictionary context to create a finished string::

        templite = Templite('''
            &lt;h1&gt;Hello {{name|upper}}!&lt;/h1&gt;
            {% for topic in topics %}
                &lt;p&gt;You are interested in {{topic}}.&lt;/p&gt;
            {% endif %}
            ''',
            {'upper': str.upper},
        )
        text = templite.render({
            'name': "Ned",
            'topics': ['Python', 'Geometry', 'Juggling'],
        })

    """
    @others
</t>
<t tx="ekr.20221020070914.702">def __init__(self, text, *contexts):
    """Construct a Templite with the given `text`.

    `contexts` are dictionaries of values to use for future renderings.
    These are good for filters and global values.

    """
    self.context = {}
    for context in contexts:
        self.context.update(context)

    self.all_vars = set()
    self.loop_vars = set()

    # We construct a function in source form, then compile it and hold onto
    # it, and execute it to render the template.
    code = CodeBuilder()

    code.add_line("def render_function(context, do_dots):")
    code.indent()
    vars_code = code.add_section()
    code.add_line("result = []")
    code.add_line("append_result = result.append")
    code.add_line("extend_result = result.extend")
    code.add_line("to_str = str")

    buffered = []

    def flush_output():
        """Force `buffered` to the code builder."""
        if len(buffered) == 1:
            code.add_line("append_result(%s)" % buffered[0])
        elif len(buffered) &gt; 1:
            code.add_line("extend_result([%s])" % ", ".join(buffered))
        del buffered[:]

    ops_stack = []

    # Split the text to form a list of tokens.
    tokens = re.split(r"(?s)({{.*?}}|{%.*?%}|{#.*?#})", text)

    squash = in_joined = False

    for token in tokens:
        if token.startswith('{'):
            start, end = 2, -2
            squash = (token[-3] == '-')
            if squash:
                end = -3

            if token.startswith('{#'):
                # Comment: ignore it and move on.
                continue
            elif token.startswith('{{'):
                # An expression to evaluate.
                expr = self._expr_code(token[start:end].strip())
                buffered.append("to_str(%s)" % expr)
            else:
                # token.startswith('{%')
                # Action tag: split into words and parse further.
                flush_output()

                words = token[start:end].strip().split()
                if words[0] == 'if':
                    # An if statement: evaluate the expression to determine if.
                    if len(words) != 2:
                        self._syntax_error("Don't understand if", token)
                    ops_stack.append('if')
                    code.add_line("if %s:" % self._expr_code(words[1]))
                    code.indent()
                elif words[0] == 'for':
                    # A loop: iterate over expression result.
                    if len(words) != 4 or words[2] != 'in':
                        self._syntax_error("Don't understand for", token)
                    ops_stack.append('for')
                    self._variable(words[1], self.loop_vars)
                    code.add_line(
                        "for c_{} in {}:".format(
                            words[1],
                            self._expr_code(words[3])
                        )
                    )
                    code.indent()
                elif words[0] == 'joined':
                    ops_stack.append('joined')
                    in_joined = True
                elif words[0].startswith('end'):
                    # Endsomething.  Pop the ops stack.
                    if len(words) != 1:
                        self._syntax_error("Don't understand end", token)
                    end_what = words[0][3:]
                    if not ops_stack:
                        self._syntax_error("Too many ends", token)
                    start_what = ops_stack.pop()
                    if start_what != end_what:
                        self._syntax_error("Mismatched end tag", end_what)
                    if end_what == 'joined':
                        in_joined = False
                    else:
                        code.dedent()
                else:
                    self._syntax_error("Don't understand tag", words[0])
        else:
            # Literal content.  If it isn't empty, output it.
            if in_joined:
                token = re.sub(r"\s*\n\s*", "", token.strip())
            elif squash:
                token = token.lstrip()
            if token:
                buffered.append(repr(token))

    if ops_stack:
        self._syntax_error("Unmatched action tag", ops_stack[-1])

    flush_output()

    for var_name in self.all_vars - self.loop_vars:
        vars_code.add_line(f"c_{var_name} = context[{var_name!r}]")

    code.add_line('return "".join(result)')
    code.dedent()
    self._render_function = code.get_globals()['render_function']

</t>
<t tx="ekr.20221020070914.703">def _expr_code(self, expr):
    """Generate a Python expression for `expr`."""
    if "|" in expr:
        pipes = expr.split("|")
        code = self._expr_code(pipes[0])
        for func in pipes[1:]:
            self._variable(func, self.all_vars)
            code = f"c_{func}({code})"
    elif "." in expr:
        dots = expr.split(".")
        code = self._expr_code(dots[0])
        args = ", ".join(repr(d) for d in dots[1:])
        code = f"do_dots({code}, {args})"
    else:
        self._variable(expr, self.all_vars)
        code = "c_%s" % expr
    return code

</t>
<t tx="ekr.20221020070914.704">def _syntax_error(self, msg, thing):
    """Raise a syntax error using `msg`, and showing `thing`."""
    raise TempliteSyntaxError(f"{msg}: {thing!r}")

</t>
<t tx="ekr.20221020070914.705">def _variable(self, name, vars_set):
    """Track that `name` is used as a variable.

    Adds the name to `vars_set`, a set of variable names.

    Raises an syntax error if `name` is not a valid name.

    """
    if not re.match(r"[_a-zA-Z][_a-zA-Z0-9]*$", name):
        self._syntax_error("Not a valid name", name)
    vars_set.add(name)

</t>
<t tx="ekr.20221020070914.706">def render(self, context=None):
    """Render this template by applying it to `context`.

    `context` is a dictionary of values to use in this rendering.

    """
    # Make the complete context we'll use.
    render_context = dict(self.context)
    if context:
        render_context.update(context)
    return self._render_function(render_context, self._do_dots)

</t>
<t tx="ekr.20221020070914.707">def _do_dots(self, value, *dots):
    """Evaluate dotted expressions at run-time."""
    for dot in dots:
        try:
            value = getattr(value, dot)
        except AttributeError:
            try:
                value = value[dot]
            except (TypeError, KeyError) as exc:
                raise TempliteValueError(
                    f"Couldn't evaluate {value!r}.{dot}"
                ) from exc
        if callable(value):
            value = value()
    return value
</t>
<t tx="ekr.20221020070914.708">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""TOML configuration support for coverage.py"""

import configparser
import os
import re

from coverage import env
from coverage.exceptions import ConfigError
from coverage.misc import import_third_party, substitute_variables


if env.PYVERSION &gt;= (3, 11, 0, "alpha", 7):
    import tomllib      # pylint: disable=import-error
else:
    # TOML support on Python 3.10 and below is an install-time extra option.
    # (Import typing is here because import_third_party will unload any module
    # that wasn't already imported. tomli imports typing, and if we unload it,
    # later it's imported again, and on Python 3.6, this causes infinite
    # recursion.)
    import typing   # pylint: disable=unused-import
    tomllib = import_third_party("tomli")


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.709">class TomlDecodeError(Exception):
    """An exception class that exists even when toml isn't installed."""
    pass


</t>
<t tx="ekr.20221020070914.71">class CoverageConfig:
    """Coverage.py configuration.

    The attributes of this class are the various settings that control the
    operation of coverage.py.

    """
    # pylint: disable=too-many-instance-attributes

    @others
</t>
<t tx="ekr.20221020070914.710">class TomlConfigParser:
    """TOML file reading with the interface of HandyConfigParser."""

    # This class has the same interface as config.HandyConfigParser, no
    # need for docstrings.
    # pylint: disable=missing-function-docstring

    @others
</t>
<t tx="ekr.20221020070914.711">def __init__(self, our_file):
    self.our_file = our_file
    self.data = None

</t>
<t tx="ekr.20221020070914.712">def read(self, filenames):
    # RawConfigParser takes a filename or list of filenames, but we only
    # ever call this with a single filename.
    assert isinstance(filenames, (bytes, str, os.PathLike))
    filename = os.fspath(filenames)

    try:
        with open(filename, encoding='utf-8') as fp:
            toml_text = fp.read()
    except OSError:
        return []
    if tomllib is not None:
        toml_text = substitute_variables(toml_text, os.environ)
        try:
            self.data = tomllib.loads(toml_text)
        except tomllib.TOMLDecodeError as err:
            raise TomlDecodeError(str(err)) from err
        return [filename]
    else:
        has_toml = re.search(r"^\[tool\.coverage\.", toml_text, flags=re.MULTILINE)
        if self.our_file or has_toml:
            # Looks like they meant to read TOML, but we can't read it.
            msg = "Can't read {!r} without TOML support. Install with [toml] extra"
            raise ConfigError(msg.format(filename))
        return []

</t>
<t tx="ekr.20221020070914.713">def _get_section(self, section):
    """Get a section from the data.

    Arguments:
        section (str): A section name, which can be dotted.

    Returns:
        name (str): the actual name of the section that was found, if any,
            or None.
        data (str): the dict of data in the section, or None if not found.

    """
    prefixes = ["tool.coverage."]
    if self.our_file:
        prefixes.append("")
    for prefix in prefixes:
        real_section = prefix + section
        parts = real_section.split(".")
        try:
            data = self.data[parts[0]]
            for part in parts[1:]:
                data = data[part]
        except KeyError:
            continue
        break
    else:
        return None, None
    return real_section, data

</t>
<t tx="ekr.20221020070914.714">def _get(self, section, option):
    """Like .get, but returns the real section name and the value."""
    name, data = self._get_section(section)
    if data is None:
        raise configparser.NoSectionError(section)
    try:
        return name, data[option]
    except KeyError as exc:
        raise configparser.NoOptionError(option, name) from exc

</t>
<t tx="ekr.20221020070914.715">def has_option(self, section, option):
    _, data = self._get_section(section)
    if data is None:
        return False
    return option in data

</t>
<t tx="ekr.20221020070914.716">def has_section(self, section):
    name, _ = self._get_section(section)
    return name

</t>
<t tx="ekr.20221020070914.717">def options(self, section):
    _, data = self._get_section(section)
    if data is None:
        raise configparser.NoSectionError(section)
    return list(data.keys())

</t>
<t tx="ekr.20221020070914.718">def get_section(self, section):
    _, data = self._get_section(section)
    return data

</t>
<t tx="ekr.20221020070914.719">def get(self, section, option):
    _, value = self._get(section, option)
    return value

</t>
<t tx="ekr.20221020070914.72">def __init__(self):
    """Initialize the configuration attributes to their defaults."""
    # Metadata about the config.
    # We tried to read these config files.
    self.attempted_config_files = []
    # We did read these config files, but maybe didn't find any content for us.
    self.config_files_read = []
    # The file that gave us our configuration.
    self.config_file = None
    self._config_contents = None

    # Defaults for [run] and [report]
    self._include = None
    self._omit = None

    # Defaults for [run]
    self.branch = False
    self.command_line = None
    self.concurrency = None
    self.context = None
    self.cover_pylib = False
    self.data_file = ".coverage"
    self.debug = []
    self.disable_warnings = []
    self.dynamic_context = None
    self.note = None
    self.parallel = False
    self.plugins = []
    self.relative_files = False
    self.run_include = None
    self.run_omit = None
    self.sigterm = False
    self.source = None
    self.source_pkgs = []
    self.timid = False
    self._crash = None

    # Defaults for [report]
    self.exclude_list = DEFAULT_EXCLUDE[:]
    self.fail_under = 0.0
    self.ignore_errors = False
    self.report_include = None
    self.report_omit = None
    self.partial_always_list = DEFAULT_PARTIAL_ALWAYS[:]
    self.partial_list = DEFAULT_PARTIAL[:]
    self.precision = 0
    self.report_contexts = None
    self.show_missing = False
    self.skip_covered = False
    self.skip_empty = False
    self.sort = None

    # Defaults for [html]
    self.extra_css = None
    self.html_dir = "htmlcov"
    self.html_skip_covered = None
    self.html_skip_empty = None
    self.html_title = "Coverage report"
    self.show_contexts = False

    # Defaults for [xml]
    self.xml_output = "coverage.xml"
    self.xml_package_depth = 99

    # Defaults for [json]
    self.json_output = "coverage.json"
    self.json_pretty_print = False
    self.json_show_contexts = False

    # Defaults for [lcov]
    self.lcov_output = "coverage.lcov"

    # Defaults for [paths]
    self.paths = collections.OrderedDict()

    # Options for plugins
    self.plugin_options = {}

</t>
<t tx="ekr.20221020070914.720">def _check_type(self, section, option, value, type_, type_desc):
    if not isinstance(value, type_):
        raise ValueError(
            'Option {!r} in section {!r} is not {}: {!r}'
                .format(option, section, type_desc, value)
        )

</t>
<t tx="ekr.20221020070914.721">def getboolean(self, section, option):
    name, value = self._get(section, option)
    self._check_type(name, option, value, bool, "a boolean")
    return value

</t>
<t tx="ekr.20221020070914.722">def getlist(self, section, option):
    name, values = self._get(section, option)
    self._check_type(name, option, values, list, "a list")
    return values

</t>
<t tx="ekr.20221020070914.723">def getregexlist(self, section, option):
    name, values = self._get(section, option)
    self._check_type(name, option, values, list, "a list")
    for value in values:
        value = value.strip()
        try:
            re.compile(value)
        except re.error as e:
            raise ConfigError(f"Invalid [{name}].{option} value {value!r}: {e}") from e
    return values

</t>
<t tx="ekr.20221020070914.724">def getint(self, section, option):
    name, value = self._get(section, option)
    self._check_type(name, option, value, int, "an integer")
    return value

</t>
<t tx="ekr.20221020070914.725">def getfloat(self, section, option):
    name, value = self._get(section, option)
    if isinstance(value, int):
        value = float(value)
    self._check_type(name, option, value, float, "a float")
    return value
</t>
<t tx="ekr.20221020070914.726">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""The version and URL for coverage.py"""
# This file is exec'ed in setup.py, don't import anything!

# Same semantics as sys.version_info.
version_info = (6, 5, 0, "final", 0)


@others
__version__ = _make_version(*version_info)
__url__ = _make_url(*version_info)
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.727">def _make_version(major, minor, micro, releaselevel, serial):
    """Create a readable version string from version_info tuple components."""
    assert releaselevel in ['alpha', 'beta', 'candidate', 'final']
    version = "%d.%d.%d" % (major, minor, micro)
    if releaselevel != 'final':
        short = {'alpha': 'a', 'beta': 'b', 'candidate': 'rc'}[releaselevel]
        version += f"{short}{serial}"
    return version


</t>
<t tx="ekr.20221020070914.728">def _make_url(major, minor, micro, releaselevel, serial):
    """Make the URL people should start at for this version of coverage.py."""
    url = "https://coverage.readthedocs.io"
    if releaselevel != 'final':
        # For pre-releases, use a version-specific URL.
        url += "/en/" + _make_version(major, minor, micro, releaselevel, serial)
    return url


</t>
<t tx="ekr.20221020070914.729">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""XML reporting for coverage.py"""

import os
import os.path
import sys
import time
import xml.dom.minidom

from coverage import __url__, __version__, files
from coverage.misc import isolate_module, human_sorted, human_sorted_items
from coverage.report import get_analysis_to_report

os = isolate_module(os)


DTD_URL = 'https://raw.githubusercontent.com/cobertura/web/master/htdocs/xml/coverage-04.dtd'


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.73">MUST_BE_LIST = {
    "debug", "concurrency", "plugins",
    "report_omit", "report_include",
    "run_omit", "run_include",
}

</t>
<t tx="ekr.20221020070914.730">def rate(hit, num):
    """Return the fraction of `hit`/`num`, as a string."""
    if num == 0:
        return "1"
    else:
        return "%.4g" % (float(hit) / num)


</t>
<t tx="ekr.20221020070914.731">class XmlReporter:
    """A reporter for writing Cobertura-style XML coverage results."""

    report_type = "XML report"

    @others
</t>
<t tx="ekr.20221020070914.732">def __init__(self, coverage):
    self.coverage = coverage
    self.config = self.coverage.config

    self.source_paths = set()
    if self.config.source:
        for src in self.config.source:
            if os.path.exists(src):
                if not self.config.relative_files:
                    src = files.canonical_filename(src)
                self.source_paths.add(src)
    self.packages = {}
    self.xml_out = None

</t>
<t tx="ekr.20221020070914.733">def report(self, morfs, outfile=None):
    """Generate a Cobertura-compatible XML report for `morfs`.

    `morfs` is a list of modules or file names.

    `outfile` is a file object to write the XML to.

    """
    # Initial setup.
    outfile = outfile or sys.stdout
    has_arcs = self.coverage.get_data().has_arcs()

    # Create the DOM that will store the data.
    impl = xml.dom.minidom.getDOMImplementation()
    self.xml_out = impl.createDocument(None, "coverage", None)

    # Write header stuff.
    xcoverage = self.xml_out.documentElement
    xcoverage.setAttribute("version", __version__)
    xcoverage.setAttribute("timestamp", str(int(time.time()*1000)))
    xcoverage.appendChild(self.xml_out.createComment(
        f" Generated by coverage.py: {__url__} "
    ))
    xcoverage.appendChild(self.xml_out.createComment(f" Based on {DTD_URL} "))

    # Call xml_file for each file in the data.
    for fr, analysis in get_analysis_to_report(self.coverage, morfs):
        self.xml_file(fr, analysis, has_arcs)

    xsources = self.xml_out.createElement("sources")
    xcoverage.appendChild(xsources)

    # Populate the XML DOM with the source info.
    for path in human_sorted(self.source_paths):
        xsource = self.xml_out.createElement("source")
        xsources.appendChild(xsource)
        txt = self.xml_out.createTextNode(path)
        xsource.appendChild(txt)

    lnum_tot, lhits_tot = 0, 0
    bnum_tot, bhits_tot = 0, 0

    xpackages = self.xml_out.createElement("packages")
    xcoverage.appendChild(xpackages)

    # Populate the XML DOM with the package info.
    for pkg_name, pkg_data in human_sorted_items(self.packages.items()):
        class_elts, lhits, lnum, bhits, bnum = pkg_data
        xpackage = self.xml_out.createElement("package")
        xpackages.appendChild(xpackage)
        xclasses = self.xml_out.createElement("classes")
        xpackage.appendChild(xclasses)
        for _, class_elt in human_sorted_items(class_elts.items()):
            xclasses.appendChild(class_elt)
        xpackage.setAttribute("name", pkg_name.replace(os.sep, '.'))
        xpackage.setAttribute("line-rate", rate(lhits, lnum))
        if has_arcs:
            branch_rate = rate(bhits, bnum)
        else:
            branch_rate = "0"
        xpackage.setAttribute("branch-rate", branch_rate)
        xpackage.setAttribute("complexity", "0")

        lnum_tot += lnum
        lhits_tot += lhits
        bnum_tot += bnum
        bhits_tot += bhits

    xcoverage.setAttribute("lines-valid", str(lnum_tot))
    xcoverage.setAttribute("lines-covered", str(lhits_tot))
    xcoverage.setAttribute("line-rate", rate(lhits_tot, lnum_tot))
    if has_arcs:
        xcoverage.setAttribute("branches-valid", str(bnum_tot))
        xcoverage.setAttribute("branches-covered", str(bhits_tot))
        xcoverage.setAttribute("branch-rate", rate(bhits_tot, bnum_tot))
    else:
        xcoverage.setAttribute("branches-covered", "0")
        xcoverage.setAttribute("branches-valid", "0")
        xcoverage.setAttribute("branch-rate", "0")
    xcoverage.setAttribute("complexity", "0")

    # Write the output file.
    outfile.write(serialize_xml(self.xml_out))

    # Return the total percentage.
    denom = lnum_tot + bnum_tot
    if denom == 0:
        pct = 0.0
    else:
        pct = 100.0 * (lhits_tot + bhits_tot) / denom
    return pct

</t>
<t tx="ekr.20221020070914.734">def xml_file(self, fr, analysis, has_arcs):
    """Add to the XML report for a single file."""

    if self.config.skip_empty:
        if analysis.numbers.n_statements == 0:
            return

    # Create the 'lines' and 'package' XML elements, which
    # are populated later.  Note that a package == a directory.
    filename = fr.filename.replace("\\", "/")
    for source_path in self.source_paths:
        source_path = files.canonical_filename(source_path)
        if filename.startswith(source_path.replace("\\", "/") + "/"):
            rel_name = filename[len(source_path)+1:]
            break
    else:
        rel_name = fr.relative_filename()
        self.source_paths.add(fr.filename[:-len(rel_name)].rstrip(r"\/"))

    dirname = os.path.dirname(rel_name) or "."
    dirname = "/".join(dirname.split("/")[:self.config.xml_package_depth])
    package_name = dirname.replace("/", ".")

    package = self.packages.setdefault(package_name, [{}, 0, 0, 0, 0])

    xclass = self.xml_out.createElement("class")

    xclass.appendChild(self.xml_out.createElement("methods"))

    xlines = self.xml_out.createElement("lines")
    xclass.appendChild(xlines)

    xclass.setAttribute("name", os.path.relpath(rel_name, dirname))
    xclass.setAttribute("filename", rel_name.replace("\\", "/"))
    xclass.setAttribute("complexity", "0")

    branch_stats = analysis.branch_stats()
    missing_branch_arcs = analysis.missing_branch_arcs()

    # For each statement, create an XML 'line' element.
    for line in sorted(analysis.statements):
        xline = self.xml_out.createElement("line")
        xline.setAttribute("number", str(line))

        # Q: can we get info about the number of times a statement is
        # executed?  If so, that should be recorded here.
        xline.setAttribute("hits", str(int(line not in analysis.missing)))

        if has_arcs:
            if line in branch_stats:
                total, taken = branch_stats[line]
                xline.setAttribute("branch", "true")
                xline.setAttribute(
                    "condition-coverage",
                    "%d%% (%d/%d)" % (100*taken//total, taken, total)
                )
            if line in missing_branch_arcs:
                annlines = ["exit" if b &lt; 0 else str(b) for b in missing_branch_arcs[line]]
                xline.setAttribute("missing-branches", ",".join(annlines))
        xlines.appendChild(xline)

    class_lines = len(analysis.statements)
    class_hits = class_lines - len(analysis.missing)

    if has_arcs:
        class_branches = sum(t for t, k in branch_stats.values())
        missing_branches = sum(t - k for t, k in branch_stats.values())
        class_br_hits = class_branches - missing_branches
    else:
        class_branches = 0.0
        class_br_hits = 0.0

    # Finalize the statistics that are collected in the XML DOM.
    xclass.setAttribute("line-rate", rate(class_hits, class_lines))
    if has_arcs:
        branch_rate = rate(class_br_hits, class_branches)
    else:
        branch_rate = "0"
    xclass.setAttribute("branch-rate", branch_rate)

    package[0][rel_name] = xclass
    package[1] += class_hits
    package[2] += class_lines
    package[3] += class_br_hits
    package[4] += class_branches


</t>
<t tx="ekr.20221020070914.735">def serialize_xml(dom):
    """Serialize a minidom node to XML."""
    return dom.toprettyxml()
</t>
<t tx="ekr.20221020070914.736">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Code coverage measurement for Python.

Ned Batchelder
https://nedbatchelder.com/code/coverage

"""

import sys

from coverage.version import __version__, __url__, version_info

from coverage.control import Coverage, process_startup
from coverage.data import CoverageData
from coverage.exceptions import CoverageException
from coverage.plugin import CoveragePlugin, FileTracer, FileReporter
from coverage.pytracer import PyTracer

# Backward compatibility.
coverage = Coverage

# On Windows, we encode and decode deep enough that something goes wrong and
# the encodings.utf_8 module is loaded and then unloaded, I don't know why.
# Adding a reference here prevents it from being unloaded.  Yuk.
import encodings.utf_8      # pylint: disable=wrong-import-position, wrong-import-order

# Because of the "from coverage.control import fooey" lines at the top of the
# file, there's an entry for coverage.coverage in sys.modules, mapped to None.
# This makes some inspection tools (like pydoc) unable to find the class
# coverage.coverage.  So remove that entry.
try:
    del sys.modules['coverage.coverage']
except KeyError:
    pass
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.737">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Coverage.py's main entry point."""

import sys
from coverage.cmdline import main
sys.exit(main())
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.738"></t>
<t tx="ekr.20221020070914.739">@path C:/Python/Python3.10/Lib/site-packages/coverage/fullcoverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Imposter encodings module that installs a coverage-style tracer.

This is NOT the encodings module; it is an imposter that sets up tracing
instrumentation and then replaces itself with the real encodings module.

If the directory that holds this file is placed first in the PYTHONPATH when
using "coverage" to run Python's tests, then this file will become the very
first module imported by the internals of Python 3.  It installs a
coverage.py-compatible trace function that can watch Standard Library modules
execute from the very earliest stages of Python's own boot process.  This fixes
a problem with coverage.py - that it starts too late to trace the coverage of
many of the most fundamental modules in the Standard Library.

"""

import sys

@others
sys.settrace(FullCoverageTracer().fullcoverage_trace)

# Remove our own directory from sys.path; remove ourselves from
# sys.modules; and re-import "encodings", which will be the real package
# this time.  Note that the delete from sys.modules dictionary has to
# happen last, since all of the symbols in this module will become None
# at that exact moment, including "sys".

parentdir = max(filter(__file__.startswith, sys.path), key=len)
sys.path.remove(parentdir)
del sys.modules['encodings']
import encodings
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.74">def from_args(self, **kwargs):
    """Read config values from `kwargs`."""
    for k, v in kwargs.items():
        if v is not None:
            if k in self.MUST_BE_LIST and isinstance(v, str):
                v = [v]
            setattr(self, k, v)

</t>
<t tx="ekr.20221020070914.740">class FullCoverageTracer:
    @others
</t>
<t tx="ekr.20221020070914.741">def __init__(self):
    # `traces` is a list of trace events.  Frames are tricky: the same
    # frame object is used for a whole scope, with new line numbers
    # written into it.  So in one scope, all the frame objects are the
    # same object, and will eventually all will point to the last line
    # executed.  So we keep the line numbers alongside the frames.
    # The list looks like:
    #
    #   traces = [
    #       ((frame, event, arg), lineno), ...
    #       ]
    #
    self.traces = []

</t>
<t tx="ekr.20221020070914.742">def fullcoverage_trace(self, *args):
    frame, event, arg = args
    if frame.f_lineno is not None:
        # https://bugs.python.org/issue46911
        self.traces.append((args, frame.f_lineno))
    return self.fullcoverage_trace

</t>
<t tx="ekr.20221020070914.75">@contract(filename=str)
def from_file(self, filename, warn, our_file):
    """Read configuration from a .rc file.

    `filename` is a file name to read.

    `our_file` is True if this config file is specifically for coverage,
    False if we are examining another config file (tox.ini, setup.cfg)
    for possible settings.

    Returns True or False, whether the file could be read, and it had some
    coverage.py settings in it.

    """
    _, ext = os.path.splitext(filename)
    if ext == '.toml':
        cp = TomlConfigParser(our_file)
    else:
        cp = HandyConfigParser(our_file)

    self.attempted_config_files.append(filename)

    try:
        files_read = cp.read(filename)
    except (configparser.Error, TomlDecodeError) as err:
        raise ConfigError(f"Couldn't read config file {filename}: {err}") from err
    if not files_read:
        return False

    self.config_files_read.extend(map(os.path.abspath, files_read))

    any_set = False
    try:
        for option_spec in self.CONFIG_FILE_OPTIONS:
            was_set = self._set_attr_from_config_option(cp, *option_spec)
            if was_set:
                any_set = True
    except ValueError as err:
        raise ConfigError(f"Couldn't read config file {filename}: {err}") from err

    # Check that there are no unrecognized options.
    all_options = collections.defaultdict(set)
    for option_spec in self.CONFIG_FILE_OPTIONS:
        section, option = option_spec[1].split(":")
        all_options[section].add(option)

    for section, options in all_options.items():
        real_section = cp.has_section(section)
        if real_section:
            for unknown in set(cp.options(section)) - options:
                warn(
                    "Unrecognized option '[{}] {}=' in config file {}".format(
                        real_section, unknown, filename
                    )
                )

    # [paths] is special
    if cp.has_section('paths'):
        for option in cp.options('paths'):
            self.paths[option] = cp.getlist('paths', option)
            any_set = True

    # plugins can have options
    for plugin in self.plugins:
        if cp.has_section(plugin):
            self.plugin_options[plugin] = cp.get_section(plugin)
            any_set = True

    # Was this file used as a config file? If it's specifically our file,
    # then it was used.  If we're piggybacking on someone else's file,
    # then it was only used if we found some settings in it.
    if our_file:
        used = True
    else:
        used = any_set

    if used:
        self.config_file = os.path.abspath(filename)
        with open(filename, "rb") as f:
            self._config_contents = f.read()

    return used

</t>
<t tx="ekr.20221020070914.76">def copy(self):
    """Return a copy of the configuration."""
    return copy.deepcopy(self)

</t>
<t tx="ekr.20221020070914.77">CONCURRENCY_CHOICES = {"thread", "gevent", "greenlet", "eventlet", "multiprocessing"}

CONFIG_FILE_OPTIONS = [
    # These are *args for _set_attr_from_config_option:
    #   (attr, where, type_="")
    #
    #   attr is the attribute to set on the CoverageConfig object.
    #   where is the section:name to read from the configuration file.
    #   type_ is the optional type to apply, by using .getTYPE to read the
    #       configuration value from the file.

    # [run]
    ('branch', 'run:branch', 'boolean'),
    ('command_line', 'run:command_line'),
    ('concurrency', 'run:concurrency', 'list'),
    ('context', 'run:context'),
    ('cover_pylib', 'run:cover_pylib', 'boolean'),
    ('data_file', 'run:data_file'),
    ('debug', 'run:debug', 'list'),
    ('disable_warnings', 'run:disable_warnings', 'list'),
    ('dynamic_context', 'run:dynamic_context'),
    ('note', 'run:note'),
    ('parallel', 'run:parallel', 'boolean'),
    ('plugins', 'run:plugins', 'list'),
    ('relative_files', 'run:relative_files', 'boolean'),
    ('run_include', 'run:include', 'list'),
    ('run_omit', 'run:omit', 'list'),
    ('sigterm', 'run:sigterm', 'boolean'),
    ('source', 'run:source', 'list'),
    ('source_pkgs', 'run:source_pkgs', 'list'),
    ('timid', 'run:timid', 'boolean'),
    ('_crash', 'run:_crash'),

    # [report]
    ('exclude_list', 'report:exclude_lines', 'regexlist'),
    ('fail_under', 'report:fail_under', 'float'),
    ('ignore_errors', 'report:ignore_errors', 'boolean'),
    ('partial_always_list', 'report:partial_branches_always', 'regexlist'),
    ('partial_list', 'report:partial_branches', 'regexlist'),
    ('precision', 'report:precision', 'int'),
    ('report_contexts', 'report:contexts', 'list'),
    ('report_include', 'report:include', 'list'),
    ('report_omit', 'report:omit', 'list'),
    ('show_missing', 'report:show_missing', 'boolean'),
    ('skip_covered', 'report:skip_covered', 'boolean'),
    ('skip_empty', 'report:skip_empty', 'boolean'),
    ('sort', 'report:sort'),

    # [html]
    ('extra_css', 'html:extra_css'),
    ('html_dir', 'html:directory'),
    ('html_skip_covered', 'html:skip_covered', 'boolean'),
    ('html_skip_empty', 'html:skip_empty', 'boolean'),
    ('html_title', 'html:title'),
    ('show_contexts', 'html:show_contexts', 'boolean'),

    # [xml]
    ('xml_output', 'xml:output'),
    ('xml_package_depth', 'xml:package_depth', 'int'),

    # [json]
    ('json_output', 'json:output'),
    ('json_pretty_print', 'json:pretty_print', 'boolean'),
    ('json_show_contexts', 'json:show_contexts', 'boolean'),

    # [lcov]
    ('lcov_output', 'lcov:output'),
]

</t>
<t tx="ekr.20221020070914.78">def _set_attr_from_config_option(self, cp, attr, where, type_=''):
    """Set an attribute on self if it exists in the ConfigParser.

    Returns True if the attribute was set.

    """
    section, option = where.split(":")
    if cp.has_option(section, option):
        method = getattr(cp, 'get' + type_)
        setattr(self, attr, method(section, option))
        return True
    return False

</t>
<t tx="ekr.20221020070914.79">def get_plugin_options(self, plugin):
    """Get a dictionary of options for the plugin named `plugin`."""
    return self.plugin_options.get(plugin, {})

</t>
<t tx="ekr.20221020070914.8">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Bytecode manipulation for coverage.py"""

import types


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.80">def set_option(self, option_name, value):
    """Set an option in the configuration.

    `option_name` is a colon-separated string indicating the section and
    option name.  For example, the ``branch`` option in the ``[run]``
    section of the config file would be indicated with `"run:branch"`.

    `value` is the new value for the option.

    """
    # Special-cased options.
    if option_name == "paths":
        self.paths = value
        return

    # Check all the hard-coded options.
    for option_spec in self.CONFIG_FILE_OPTIONS:
        attr, where = option_spec[:2]
        if where == option_name:
            setattr(self, attr, value)
            return

    # See if it's a plugin option.
    plugin_name, _, key = option_name.partition(":")
    if key and plugin_name in self.plugins:
        self.plugin_options.setdefault(plugin_name, {})[key] = value
        return

    # If we get here, we didn't find the option.
    raise ConfigError(f"No such option: {option_name!r}")

</t>
<t tx="ekr.20221020070914.81">def get_option(self, option_name):
    """Get an option from the configuration.

    `option_name` is a colon-separated string indicating the section and
    option name.  For example, the ``branch`` option in the ``[run]``
    section of the config file would be indicated with `"run:branch"`.

    Returns the value of the option.

    """
    # Special-cased options.
    if option_name == "paths":
        return self.paths

    # Check all the hard-coded options.
    for option_spec in self.CONFIG_FILE_OPTIONS:
        attr, where = option_spec[:2]
        if where == option_name:
            return getattr(self, attr)

    # See if it's a plugin option.
    plugin_name, _, key = option_name.partition(":")
    if key and plugin_name in self.plugins:
        return self.plugin_options.get(plugin_name, {}).get(key)

    # If we get here, we didn't find the option.
    raise ConfigError(f"No such option: {option_name!r}")

</t>
<t tx="ekr.20221020070914.82">def post_process_file(self, path):
    """Make final adjustments to a file path to make it usable."""
    return os.path.expanduser(path)

</t>
<t tx="ekr.20221020070914.83">def post_process(self):
    """Make final adjustments to settings to make them usable."""
    self.data_file = self.post_process_file(self.data_file)
    self.html_dir = self.post_process_file(self.html_dir)
    self.xml_output = self.post_process_file(self.xml_output)
    self.paths = collections.OrderedDict(
        (k, [self.post_process_file(f) for f in v])
        for k, v in self.paths.items()
    )

</t>
<t tx="ekr.20221020070914.84">def debug_info(self):
    """Make a list of (name, value) pairs for writing debug info."""
    return human_sorted_items(
        (k, v) for k, v in self.__dict__.items() if not k.startswith("_")
    )


</t>
<t tx="ekr.20221020070914.85">def config_files_to_try(config_file):
    """What config files should we try to read?

    Returns a list of tuples:
        (filename, is_our_file, was_file_specified)
    """

    # Some API users were specifying ".coveragerc" to mean the same as
    # True, so make it so.
    if config_file == ".coveragerc":
        config_file = True
    specified_file = (config_file is not True)
    if not specified_file:
        # No file was specified. Check COVERAGE_RCFILE.
        config_file = os.environ.get('COVERAGE_RCFILE')
        if config_file:
            specified_file = True
    if not specified_file:
        # Still no file specified. Default to .coveragerc
        config_file = ".coveragerc"
    files_to_try = [
        (config_file, True, specified_file),
        ("setup.cfg", False, False),
        ("tox.ini", False, False),
        ("pyproject.toml", False, False),
    ]
    return files_to_try


</t>
<t tx="ekr.20221020070914.86">def read_coverage_config(config_file, warn, **kwargs):
    """Read the coverage.py configuration.

    Arguments:
        config_file: a boolean or string, see the `Coverage` class for the
            tricky details.
        warn: a function to issue warnings.
        all others: keyword arguments from the `Coverage` class, used for
            setting values in the configuration.

    Returns:
        config:
            config is a CoverageConfig object read from the appropriate
            configuration file.

    """
    # Build the configuration from a number of sources:
    # 1) defaults:
    config = CoverageConfig()

    # 2) from a file:
    if config_file:
        files_to_try = config_files_to_try(config_file)

        for fname, our_file, specified_file in files_to_try:
            config_read = config.from_file(fname, warn, our_file=our_file)
            if config_read:
                break
            if specified_file:
                raise ConfigError(f"Couldn't read {fname!r} as a config file")

    # $set_env.py: COVERAGE_DEBUG - Options for --debug.
    # 3) from environment variables:
    env_data_file = os.environ.get('COVERAGE_FILE')
    if env_data_file:
        config.data_file = env_data_file
    debugs = os.environ.get('COVERAGE_DEBUG')
    if debugs:
        config.debug.extend(d.strip() for d in debugs.split(","))

    # 4) from constructor arguments:
    config.from_args(**kwargs)

    # Once all the config has been collected, there's a little post-processing
    # to do.
    config.post_process()

    return config
</t>
<t tx="ekr.20221020070914.87">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Determine contexts for coverage.py"""


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.88">def combine_context_switchers(context_switchers):
    """Create a single context switcher from multiple switchers.

    `context_switchers` is a list of functions that take a frame as an
    argument and return a string to use as the new context label.

    Returns a function that composites `context_switchers` functions, or None
    if `context_switchers` is an empty list.

    When invoked, the combined switcher calls `context_switchers` one-by-one
    until a string is returned.  The combined switcher returns None if all
    `context_switchers` return None.
    """
    if not context_switchers:
        return None

    if len(context_switchers) == 1:
        return context_switchers[0]

    @others
    return should_start_context


</t>
<t tx="ekr.20221020070914.89">def should_start_context(frame):
    """The combiner for multiple context switchers."""
    for switcher in context_switchers:
        new_context = switcher(frame)
        if new_context is not None:
            return new_context
    return None

</t>
<t tx="ekr.20221020070914.9">def code_objects(code):
    """Iterate over all the code objects in `code`."""
    stack = [code]
    while stack:
        # We're going to return the code object on the stack, but first
        # push its children for later returning.
        code = stack.pop()
        for c in code.co_consts:
            if isinstance(c, types.CodeType):
                stack.append(c)
        yield code
</t>
<t tx="ekr.20221020070914.90">def should_start_context_test_function(frame):
    """Is this frame calling a test_* function?"""
    co_name = frame.f_code.co_name
    if co_name.startswith("test") or co_name == "runTest":
        return qualname_from_frame(frame)
    return None


</t>
<t tx="ekr.20221020070914.91">def qualname_from_frame(frame):
    """Get a qualified name for the code running in `frame`."""
    co = frame.f_code
    fname = co.co_name
    method = None
    if co.co_argcount and co.co_varnames[0] == "self":
        self = frame.f_locals.get("self", None)
        method = getattr(self, fname, None)

    if method is None:
        func = frame.f_globals.get(fname)
        if func is None:
            return None
        return func.__module__ + "." + fname

    func = getattr(method, "__func__", None)
    if func is None:
        cls = self.__class__
        return cls.__module__ + "." + cls.__name__ + "." + fname

    return func.__module__ + "." + func.__qualname__
</t>
<t tx="ekr.20221020070914.92">@path C:/Python/Python3.10/Lib/site-packages/coverage/
# Licensed under the Apache License: http://www.apache.org/licenses/LICENSE-2.0
# For details: https://github.com/nedbat/coveragepy/blob/master/NOTICE.txt

"""Core control stuff for coverage.py."""

import atexit
import collections
import contextlib
import os
import os.path
import platform
import signal
import sys
import threading
import time
import warnings

from coverage import env
from coverage.annotate import AnnotateReporter
from coverage.collector import Collector, CTracer
from coverage.config import read_coverage_config
from coverage.context import should_start_context_test_function, combine_context_switchers
from coverage.data import CoverageData, combine_parallel_data
from coverage.debug import DebugControl, short_stack, write_formatted_info
from coverage.disposition import disposition_debug_msg
from coverage.exceptions import ConfigError, CoverageException, CoverageWarning, PluginError
from coverage.files import PathAliases, abs_file, relative_filename, set_relative_directory
from coverage.html import HtmlReporter
from coverage.inorout import InOrOut
from coverage.jsonreport import JsonReporter
from coverage.lcovreport import LcovReporter
from coverage.misc import bool_or_none, join_regex, human_sorted
from coverage.misc import DefaultValue, ensure_dir_for_file, isolate_module
from coverage.plugin import FileReporter
from coverage.plugin_support import Plugins
from coverage.python import PythonFileReporter
from coverage.report import render_report
from coverage.results import Analysis
from coverage.summary import SummaryReporter
from coverage.xmlreport import XmlReporter

try:
    from coverage.multiproc import patch_multiprocessing
except ImportError:                                         # pragma: only jython
    # Jython has no multiprocessing module.
    patch_multiprocessing = None

os = isolate_module(os)

@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20221020070914.93">@contextlib.contextmanager
def override_config(cov, **kwargs):
    """Temporarily tweak the configuration of `cov`.

    The arguments are applied to `cov.config` with the `from_args` method.
    At the end of the with-statement, the old configuration is restored.
    """
    original_config = cov.config
    cov.config = cov.config.copy()
    try:
        cov.config.from_args(**kwargs)
        yield
    finally:
        cov.config = original_config


</t>
<t tx="ekr.20221020070914.94">DEFAULT_DATAFILE = DefaultValue("MISSING")
_DEFAULT_DATAFILE = DEFAULT_DATAFILE  # Just in case, for backwards compatibility

</t>
<t tx="ekr.20221020070914.95">class Coverage:
    """Programmatic access to coverage.py.

    To use::

        from coverage import Coverage

        cov = Coverage()
        cov.start()
        #.. call your code ..
        cov.stop()
        cov.html_report(directory='covhtml')

    Note: in keeping with Python custom, names starting with underscore are
    not part of the public API. They might stop working at any point.  Please
    limit yourself to documented methods to avoid problems.

    Methods can raise any of the exceptions described in :ref:`api_exceptions`.

    """

    # The stack of started Coverage instances.
    _instances = []

    @others
</t>
<t tx="ekr.20221020070914.96">@classmethod
def current(cls):
    """Get the latest started `Coverage` instance, if any.

    Returns: a `Coverage` instance, or None.

    .. versionadded:: 5.0

    """
    if cls._instances:
        return cls._instances[-1]
    else:
        return None

</t>
<t tx="ekr.20221020070914.97">def __init__(
    self, data_file=DEFAULT_DATAFILE, data_suffix=None, cover_pylib=None,
    auto_data=False, timid=None, branch=None, config_file=True,
    source=None, source_pkgs=None, omit=None, include=None, debug=None,
    concurrency=None, check_preimported=False, context=None,
    messages=False,
):  # pylint: disable=too-many-arguments
    """
    Many of these arguments duplicate and override values that can be
    provided in a configuration file.  Parameters that are missing here
    will use values from the config file.

    `data_file` is the base name of the data file to use. The config value
    defaults to ".coverage".  None can be provided to prevent writing a data
    file.  `data_suffix` is appended (with a dot) to `data_file` to create
    the final file name.  If `data_suffix` is simply True, then a suffix is
    created with the machine and process identity included.

    `cover_pylib` is a boolean determining whether Python code installed
    with the Python interpreter is measured.  This includes the Python
    standard library and any packages installed with the interpreter.

    If `auto_data` is true, then any existing data file will be read when
    coverage measurement starts, and data will be saved automatically when
    measurement stops.

    If `timid` is true, then a slower and simpler trace function will be
    used.  This is important for some environments where manipulation of
    tracing functions breaks the faster trace function.

    If `branch` is true, then branch coverage will be measured in addition
    to the usual statement coverage.

    `config_file` determines what configuration file to read:

        * If it is ".coveragerc", it is interpreted as if it were True,
          for backward compatibility.

        * If it is a string, it is the name of the file to read.  If the
          file can't be read, it is an error.

        * If it is True, then a few standard files names are tried
          (".coveragerc", "setup.cfg", "tox.ini").  It is not an error for
          these files to not be found.

        * If it is False, then no configuration file is read.

    `source` is a list of file paths or package names.  Only code located
    in the trees indicated by the file paths or package names will be
    measured.

    `source_pkgs` is a list of package names. It works the same as
    `source`, but can be used to name packages where the name can also be
    interpreted as a file path.

    `include` and `omit` are lists of file name patterns. Files that match
    `include` will be measured, files that match `omit` will not.  Each
    will also accept a single string argument.

    `debug` is a list of strings indicating what debugging information is
    desired.

    `concurrency` is a string indicating the concurrency library being used
    in the measured code.  Without this, coverage.py will get incorrect
    results if these libraries are in use.  Valid strings are "greenlet",
    "eventlet", "gevent", "multiprocessing", or "thread" (the default).
    This can also be a list of these strings.

    If `check_preimported` is true, then when coverage is started, the
    already-imported files will be checked to see if they should be
    measured by coverage.  Importing measured files before coverage is
    started can mean that code is missed.

    `context` is a string to use as the :ref:`static context
    &lt;static_contexts&gt;` label for collected data.

    If `messages` is true, some messages will be printed to stdout
    indicating what is happening.

    .. versionadded:: 4.0
        The `concurrency` parameter.

    .. versionadded:: 4.2
        The `concurrency` parameter can now be a list of strings.

    .. versionadded:: 5.0
        The `check_preimported` and `context` parameters.

    .. versionadded:: 5.3
        The `source_pkgs` parameter.

    .. versionadded:: 6.0
        The `messages` parameter.

    """
    # data_file=None means no disk file at all. data_file missing means
    # use the value from the config file.
    self._no_disk = data_file is None
    if data_file is DEFAULT_DATAFILE:
        data_file = None

    self.config = None

    # This is injectable by tests.
    self._debug_file = None

    self._auto_load = self._auto_save = auto_data
    self._data_suffix_specified = data_suffix

    # Is it ok for no data to be collected?
    self._warn_no_data = True
    self._warn_unimported_source = True
    self._warn_preimported_source = check_preimported
    self._no_warn_slugs = None
    self._messages = messages

    # A record of all the warnings that have been issued.
    self._warnings = []

    # Other instance attributes, set later.
    self._data = self._collector = None
    self._plugins = None
    self._inorout = None
    self._data_suffix = self._run_suffix = None
    self._exclude_re = None
    self._debug = None
    self._file_mapper = None
    self._old_sigterm = None

    # State machine variables:
    # Have we initialized everything?
    self._inited = False
    self._inited_for_start = False
    # Have we started collecting and not stopped it?
    self._started = False
    # Should we write the debug output?
    self._should_write_debug = True

    # Build our configuration from a number of sources.
    self.config = read_coverage_config(
        config_file=config_file, warn=self._warn,
        data_file=data_file, cover_pylib=cover_pylib, timid=timid,
        branch=branch, parallel=bool_or_none(data_suffix),
        source=source, source_pkgs=source_pkgs, run_omit=omit, run_include=include, debug=debug,
        report_omit=omit, report_include=include,
        concurrency=concurrency, context=context,
    )

    # If we have sub-process measurement happening automatically, then we
    # want any explicit creation of a Coverage object to mean, this process
    # is already coverage-aware, so don't auto-measure it.  By now, the
    # auto-creation of a Coverage object has already happened.  But we can
    # find it and tell it not to save its data.
    if not env.METACOV:
        _prevent_sub_process_measurement()

</t>
<t tx="ekr.20221020070914.98">def _init(self):
    """Set all the initial state.

    This is called by the public methods to initialize state. This lets us
    construct a :class:`Coverage` object, then tweak its state before this
    function is called.

    """
    if self._inited:
        return

    self._inited = True

    # Create and configure the debugging controller. COVERAGE_DEBUG_FILE
    # is an environment variable, the name of a file to append debug logs
    # to.
    self._debug = DebugControl(self.config.debug, self._debug_file)

    if "multiprocessing" in (self.config.concurrency or ()):
        # Multi-processing uses parallel for the subprocesses, so also use
        # it for the main process.
        self.config.parallel = True

    # _exclude_re is a dict that maps exclusion list names to compiled regexes.
    self._exclude_re = {}

    set_relative_directory()
    self._file_mapper = relative_filename if self.config.relative_files else abs_file

    # Load plugins
    self._plugins = Plugins.load_plugins(self.config.plugins, self.config, self._debug)

    # Run configuring plugins.
    for plugin in self._plugins.configurers:
        # We need an object with set_option and get_option. Either self or
        # self.config will do. Choosing randomly stops people from doing
        # other things with those objects, against the public API.  Yes,
        # this is a bit childish. :)
        plugin.configure([self, self.config][int(time.time()) % 2])

</t>
<t tx="ekr.20221020070914.99">def _post_init(self):
    """Stuff to do after everything is initialized."""
    if self._should_write_debug:
        self._should_write_debug = False
        self._write_startup_debug()

    # '[run] _crash' will raise an exception if the value is close by in
    # the call stack, for testing error handling.
    if self.config._crash and self.config._crash in short_stack(limit=4):
        raise Exception(f"Crashing because called by {self.config._crash}")

</t>
<t tx="ekr.20221020071523.1">def _convert_branch_arcs(branch_arcs):
    """Convert branch arcs to a list of two-element tuples."""
    for source, targets in branch_arcs.items():
        for target in targets:
            yield source, target
</t>
</tnodes>
</leo_file>
