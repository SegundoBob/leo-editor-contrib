<?xml version="1.0" encoding="utf-8"?>
<!-- Created by Leo: https://leo-editor.github.io/leo-editor/leo_toc.html -->
<leo_file xmlns:leo="http://leo-editor.github.io/leo-editor/namespaces/leo-python-editor/1.1" >
<leo_header file_format="2"/>
<globals/>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ekr.20230415045841.1"><vh>https://github.com/IBM/neuro-vector-symbolic-architectures</vh></v>
<v t="ekr.20230415045841.2"><vh>@@clean __init__.py</vh></v>
<v t="ekr.20230415045841.3"><vh>@path perception</vh>
<v t="ekr.20230415045841.4"><vh>@@clean __init__.py</vh></v>
<v t="ekr.20230415045841.5"><vh>@@clean metrics.py</vh>
<v t="ekr.20230415045841.6"><vh>log</vh></v>
<v t="ekr.20230415045841.7"><vh>generate_IM</vh></v>
<v t="ekr.20230415045841.8"><vh>class fixCos</vh>
<v t="ekr.20230415045841.9"><vh>fixCos.__init__</vh></v>
<v t="ekr.20230415045841.10"><vh>fixCos.forward</vh></v>
<v t="ekr.20230415045841.11"><vh>fixCos.get_s</vh></v>
</v>
<v t="ekr.20230415045841.12"><vh>class marginalization</vh>
<v t="ekr.20230415045841.13"><vh>marginalization.__init__</vh></v>
<v t="ekr.20230415045841.14"><vh>marginalization.forward</vh></v>
<v t="ekr.20230415045841.15"><vh>marginalization.get_s</vh></v>
</v>
<v t="ekr.20230415045841.16"><vh>get_marginalization_readout</vh></v>
<v t="ekr.20230415045841.17"><vh>class hd_mult_frontend</vh>
<v t="ekr.20230415045841.18"><vh>hd_mult_frontend.__init__</vh></v>
<v t="ekr.20230415045841.19"><vh>hd_mult_frontend.forward</vh></v>
<v t="ekr.20230415045841.20"><vh>hd_mult_frontend.store_s</vh></v>
</v>
<v t="ekr.20230415045841.21"><vh>class randXentropyloss</vh>
<v t="ekr.20230415045841.22"><vh>randXentropyloss.__init__</vh></v>
<v t="ekr.20230415045841.23"><vh>randXentropyloss.forward</vh></v>
</v>
<v t="ekr.20230415045841.24"><vh>class addXentropyloss</vh>
<v t="ekr.20230415045841.25"><vh>addXentropyloss.__init__</vh></v>
<v t="ekr.20230415045841.26"><vh>addXentropyloss.forward</vh></v>
</v>
<v t="ekr.20230415045841.27"><vh>class marginalization_line</vh>
<v t="ekr.20230415045841.28"><vh>marginalization_line.__init__</vh></v>
<v t="ekr.20230415045841.29"><vh>marginalization_line.forward</vh></v>
<v t="ekr.20230415045841.30"><vh>marginalization_line.get_s</vh></v>
</v>
<v t="ekr.20230415045841.31"><vh>class hd_mult_frontend_pgm</vh>
<v t="ekr.20230415045841.32"><vh>hd_mult_frontend_pgm.__init__</vh></v>
<v t="ekr.20230415045841.33"><vh>hd_mult_frontend_pgm.forward</vh></v>
<v t="ekr.20230415045841.34"><vh>hd_mult_frontend_pgm.store_s</vh></v>
</v>
<v t="ekr.20230415045841.35"><vh>generate_IM_pgm</vh></v>
</v>
<v t="ekr.20230415045841.36"><vh>@@clean resnet.py</vh>
<v t="ekr.20230415045841.37"><vh>conv3x3</vh></v>
<v t="ekr.20230415045841.38"><vh>conv1x1</vh></v>
<v t="ekr.20230415045841.39"><vh>class Bottleneck</vh>
<v t="ekr.20230415045841.40"><vh>Bottleneck.__init__</vh></v>
<v t="ekr.20230415045841.41"><vh>Bottleneck.forward</vh></v>
</v>
<v t="ekr.20230415045841.42"><vh>class BasicBlock</vh>
<v t="ekr.20230415045841.43"><vh>BasicBlock.__init__</vh></v>
<v t="ekr.20230415045841.44"><vh>BasicBlock.forward</vh></v>
</v>
<v t="ekr.20230415045841.45"><vh>class ResNet</vh>
<v t="ekr.20230415045841.46"><vh>ResNet.__init__</vh></v>
<v t="ekr.20230415045841.47"><vh>ResNet._make_layer</vh></v>
<v t="ekr.20230415045841.48"><vh>ResNet.forward</vh></v>
</v>
<v t="ekr.20230415045841.49"><vh>_resnet</vh></v>
<v t="ekr.20230415045841.50"><vh>resnet18</vh></v>
</v>
</v>
<v t="ekr.20230415045841.51"><vh>@path reasoning</vh>
<v t="ekr.20230415045841.52"><vh>@@clean __init__.py</vh></v>
<v t="ekr.20230415045841.53"><vh>@@clean vsa_backend_pgm.py</vh>
<v t="ekr.20230415045841.54"><vh>class vsa_rule_detector_PGM</vh>
<v t="ekr.20230415045841.55"><vh>vsa_rule_detector_PGM.__init__</vh></v>
<v t="ekr.20230415045841.56"><vh>vsa_rule_detector_PGM.union</vh></v>
<v t="ekr.20230415045841.57"><vh>vsa_rule_detector_PGM.progression_plus</vh></v>
</v>
<v t="ekr.20230415045841.58"><vh>class vsa_rule_executor_PGM</vh>
<v t="ekr.20230415045841.59"><vh>vsa_rule_executor_PGM.__init__</vh></v>
<v t="ekr.20230415045841.60"><vh>vsa_rule_executor_PGM.union</vh></v>
<v t="ekr.20230415045841.61"><vh>vsa_rule_executor_PGM.progression_plus</vh></v>
</v>
</v>
<v t="ekr.20230415045841.62"><vh>@@clean vsa_backend_raven.py</vh>
<v t="ekr.20230415045841.63"><vh>class vsa_rule_detector_extended</vh>
<v t="ekr.20230415045841.64"><vh>vsa_rule_detector_extended.__init__</vh></v>
<v t="ekr.20230415045841.65"><vh>vsa_rule_detector_extended.distribute_three</vh></v>
<v t="ekr.20230415045841.66"><vh>vsa_rule_detector_extended.constant</vh></v>
<v t="ekr.20230415045841.67"><vh>vsa_rule_detector_extended.progression_plus</vh></v>
<v t="ekr.20230415045841.68"><vh>vsa_rule_detector_extended.progression_minus</vh></v>
<v t="ekr.20230415045841.69"><vh>vsa_rule_detector_extended.arithmetic_plus</vh></v>
<v t="ekr.20230415045841.70"><vh>vsa_rule_detector_extended.arithmetic_minus</vh></v>
</v>
<v t="ekr.20230415045841.71"><vh>class vsa_rule_executor_extended</vh>
<v t="ekr.20230415045841.72"><vh>vsa_rule_executor_extended.__init__</vh></v>
<v t="ekr.20230415045841.73"><vh>vsa_rule_executor_extended.distribute_three</vh></v>
<v t="ekr.20230415045841.74"><vh>vsa_rule_executor_extended.constant</vh></v>
<v t="ekr.20230415045841.75"><vh>vsa_rule_executor_extended.progression_plus</vh></v>
<v t="ekr.20230415045841.76"><vh>vsa_rule_executor_extended.progression_minus</vh></v>
<v t="ekr.20230415045841.77"><vh>vsa_rule_executor_extended.arithmetic_plus</vh></v>
<v t="ekr.20230415045841.78"><vh>vsa_rule_executor_extended.arithmetic_minus</vh></v>
</v>
</v>
<v t="ekr.20230415045841.79"><vh>@@clean vsa_block_utils.py</vh>
<v t="ekr.20230415045841.80"><vh>cosine2pmf</vh></v>
<v t="ekr.20230415045841.81"><vh>block_binding2</vh></v>
<v t="ekr.20230415045841.82"><vh>cyclic_shift</vh></v>
<v t="ekr.20230415045841.83"><vh>block_unbinding2</vh></v>
<v t="ekr.20230415045841.84"><vh>block_binding3</vh></v>
<v t="ekr.20230415045841.85"><vh>block_unbinding3</vh></v>
<v t="ekr.20230415045841.86"><vh>binding_circular</vh></v>
<v t="ekr.20230415045841.87"><vh>inv_binding_circular</vh></v>
<v t="ekr.20230415045841.88"><vh>match_prob</vh></v>
<v t="ekr.20230415045841.89"><vh>match_prob_0</vh></v>
<v t="ekr.20230415045841.90"><vh>match_prob_multi</vh></v>
<v t="ekr.20230415045841.91"><vh>match_prob_multi_batched</vh></v>
<v t="ekr.20230415045841.92"><vh>pmf2vec</vh></v>
<v t="ekr.20230415045841.93"><vh>check_collision</vh></v>
<v t="ekr.20230415045841.94"><vh>block_continuous_codebook</vh></v>
<v t="ekr.20230415045841.95"><vh>sample_block_continuous_codebook</vh></v>
<v t="ekr.20230415045841.96"><vh>block_discrete_codebook</vh></v>
</v>
</v>
</vnodes>
<tnodes>
<t tx="ekr.20230415045841.1"></t>
<t tx="ekr.20230415045841.10">def forward(self, input, label=None):
    x = F.normalize(input)
    W = F.normalize(self.W)
    logits = F.linear(x, W)
    output = self.s * logits
    return output

</t>
<t tx="ekr.20230415045841.11">def get_s(self):
    return self.s.data.item()

</t>
<t tx="ekr.20230415045841.12">class marginalization(nn.Module):
    '''
    Maps cosine similarites to object PMFs by marginalization

    Parameters
    ----------
    s:              float 
        inverse softmax temperature
    trainable_s:    boolean
        Trainable inverse softmax temperature if activated    
    in_act:         str
        input activation
    exist_act:      str
        input activation for existence probability
    dims:           tuple
        dimensions of (color, size, type) 
    '''
    @others
</t>
<t tx="ekr.20230415045841.13">def __init__(self,s=1,m=0,trainable_s=False, in_act = "ReLU",exist_act="Identity",dims=(10,6,5)):
    super(marginalization, self).__init__()
    exist_readout, typ_readout, siz_readout, col_readout = get_marginalization_readout(dims)
    self.typ_readout = nn.Parameter(typ_readout,requires_grad=False)
    self.siz_readout = nn.Parameter(siz_readout,requires_grad=False)
    self.col_readout = nn.Parameter(col_readout,requires_grad=False)
    self.exist_readout = nn.Parameter(exist_readout,requires_grad=False)
    if trainable_s: 
        self.s_type = Parameter(t.Tensor([s]), requires_grad=trainable_s)
        self.s_size = Parameter(t.Tensor([s]), requires_grad=trainable_s)
        self.s_color = Parameter(t.Tensor([s]), requires_grad=trainable_s)
        self.s_exist = Parameter(t.Tensor([s]), requires_grad=trainable_s)
    else: 
        self.s_type, self.s_size, self.s_color, self.s_exist = s, s, s, s

    self.m = m
    self.in_act = getattr(nn,in_act)()
    self.exist_act = getattr(nn,exist_act)()

</t>
<t tx="ekr.20230415045841.14">def forward(self, x):
    x_1 = self.in_act(x-self.m)
    type_prob = F.softmax(self.s_type*F.linear(x_1,self.typ_readout), dim=-1)
    size_prob = F.softmax(self.s_size*F.linear(x_1,self.siz_readout), dim=-1)
    color_prob = F.softmax(self.s_color*F.linear(x_1,self.col_readout), dim=-1)
    exist_prob = F.softmax(self.s_exist*F.linear(self.exist_act(x),self.exist_readout), dim=-1)

    return [log(exist_prob),log(type_prob),log(size_prob),log(color_prob)]

</t>
<t tx="ekr.20230415045841.15">def get_s(self):
    return self.s_exist.data.item(),self.s_type.data.item(), self.s_size.data.item(), self.s_color.data.item() 

</t>
<t tx="ekr.20230415045841.16">def get_marginalization_readout(dims): 
    '''
    Compute the binary matrix for doing marginalization

    Parameters
    ----------
    dims:           tuple
        dimensions of (color, size, type) 

    Return
    ------
    exist_readout:  torch tensor (2, nmax)
    typ_readout:  torch tensor (n_typ, nmax)
    siz_readout:  torch tensor (n_siz, nmax)
    col_readout:  torch tensor (n_col, nmax)
    '''
    n_col, n_siz, n_typ= dims
    nmax = n_col*n_siz*n_typ +1
    typ_readout = t.zeros(n_typ,nmax); siz_readout = t.zeros(n_siz,nmax)
    col_readout = t.zeros(n_col,nmax); exist_readout = t.zeros(2,nmax)
    
    for col in range(n_col):
        for siz in range(n_siz):
            for typ in range(n_typ): 
                idx = col*n_siz*n_typ + siz*n_typ + typ
                typ_readout[typ,idx] = 1.
                siz_readout[siz,idx] = 1.
                col_readout[col,idx] = 1.

    exist_readout[0,-1] = 1.
    exist_readout[1,:nmax-1] = 1.

    return exist_readout, typ_readout, siz_readout, col_readout


</t>
<t tx="ekr.20230415045841.17">class hd_mult_frontend(nn.Module): 
    '''
    Maps cosine similarites to object PMFs by marginalization

    Parameters
    ----------
    # cosine readout parameters
    num_features:   int
        input dimensionality
    num_classes:    int
        placeholder
    mat:            torch tensor
        Weight matrix (W)
    fixed_weights:  boolean
        Fix weight matrix (W) if activated
    s:              float
        Inverse softmax temperature
    trainable_s:    boolean
        Trainable inverse softmax temperature if activated    

    # Marginalization parameters
    marg_s:              float 
        inverse softmax temperature
    marg_m:             float
        threshold (shift)
    marg_in_act:         str
        input activation
    marg_exist_act:      str
        input activation for existence probability
    num_pos:            int
        number of positions
    '''
    @others
</t>
<t tx="ekr.20230415045841.18">def __init__(self,num_features, num_classes, mat, fixed_weights=True, s=1.0, trainable_s=True,
            marg_s=1,marg_m=0,marg_in_act = "ReLU",marg_exist_act="Identity", num_pos=1):
    super(hd_mult_frontend, self).__init__()
    # init cosine readout 
    self.metric = fixCos(num_features = num_features, num_classes = num_classes, mat=mat,fixed_weights=fixed_weights,s=s,trainable_s=trainable_s)
    # init marginalization (no trainable s here)
    self.marg = marginalization(s=marg_s, m=marg_m, in_act=marg_in_act,exist_act=marg_exist_act)
    self.num_pos = num_pos

</t>
<t tx="ekr.20230415045841.19">def forward(self,x,B,N): 
    x = self.metric(x)
    x = self.marg(x.view(B,N,self.num_pos,-1))
    return x

</t>
<t tx="ekr.20230415045841.2">@path neuro-vector-symbolic-architectures/nvsa/
@language python
@tabwidth -4
</t>
<t tx="ekr.20230415045841.20">def store_s(self,writer,epoch):
    writer.add_scalar('marg-s/marg-s', self.metric.get_s(), epoch )

</t>
<t tx="ekr.20230415045841.21">class randXentropyloss(nn.Module): 
    '''
    Random cross entropy loss for multi-label classification
    '''
    @others
</t>
<t tx="ekr.20230415045841.22">def __init__(self): 
    super(randXentropyloss, self).__init__()
    self.criterion = nn.CrossEntropyLoss()

</t>
<t tx="ekr.20230415045841.23">def forward(self, x,target, target_onhot):
    B = target.size(0)
    temp = (target != -1).clone().detach()
    temp = temp.float()
    temp1 = t.multinomial(temp,1).reshape(B,1)
    temp2 = t.arange(B).reshape(B,1).to(temp1.get_device())
    idx = t.cat((temp2,temp1), dim = 1)
    targ= target[idx[:,0],idx[:,1]] 
    loss = self.criterion(x,targ) 
    return loss

</t>
<t tx="ekr.20230415045841.24">class addXentropyloss(nn.Module): 
    '''
    Additive cross entropy loss for multi-label classification (see Supplementary Note 1 Eq.(3))
    '''
    @others
</t>
<t tx="ekr.20230415045841.25">def __init__(self): 
    super(addXentropyloss, self).__init__()
    self.criterion = nn.CrossEntropyLoss()

</t>
<t tx="ekr.20230415045841.26">def forward(self, x,target, target_onehot):
    B = target.size(0)
    target_logit = t.sum(x*target_onehot,dim=-1, keepdim=True)
    logit = t.cat((target_logit,x),dim=1)
    new_target = t.zeros(B,dtype=t.int64).to(logit.get_device())
    loss = self.criterion(logit, new_target)
    return loss 

</t>
<t tx="ekr.20230415045841.27">######################### PGM related frontend ############################################
class marginalization_line(nn.Module):
    '''
    Maps cosine similarites to object PMFs by marginalization for line constellation

    Parameters
    ----------
    s:              float 
        inverse softmax temperature
    m:              float
        shift/threshold input
    trainable_s:    boolean
        Trainable inverse softmax temperature if activated    
    in_act:         str
        input activation
    exist_act:      str
        input activation for existence probability
    dims:           int
        dimension on line
    '''
    @others
</t>
<t tx="ekr.20230415045841.28">def __init__(self,s=1,m=0,trainable_s=False,in_act="ReLU",exist_act="Identity",dims=10):
    super(marginalization_line, self).__init__()
    self.col_readout = t.eye(dims,dims+1); self.exist_readout = t.zeros(2,dims+1)
    self.exist_readout[0,-1] = 1.; self.exist_readout[1,:dims] = 1.
    self.col_readout = nn.Parameter(self.col_readout,requires_grad=False)
    self.exist_readout = nn.Parameter(self.exist_readout,requires_grad=False)
    if trainable_s: 
        self.s_color = Parameter(t.Tensor([s]), requires_grad=trainable_s)
        self.s_exist = Parameter(t.Tensor([s]), requires_grad=trainable_s)
    else: 
        self.s_color, self.s_exist = s, s
    self.m = m
    self.in_act = getattr(nn,in_act)()
    self.exist_act = getattr(nn,exist_act)()

</t>
<t tx="ekr.20230415045841.29">def forward(self, x):
    x_1 = self.in_act(x-self.m)
    color_prob = F.softmax(self.s_color*F.linear(x_1,self.col_readout), dim=-1)
    exist_prob = F.softmax(self.s_exist*F.linear(self.exist_act(x),self.exist_readout), dim=-1)

    return [log(exist_prob),log(color_prob)]

</t>
<t tx="ekr.20230415045841.3"></t>
<t tx="ekr.20230415045841.30">def get_s(self):
    return self.s_exist.data.item(), self.s_color.data.item() 



</t>
<t tx="ekr.20230415045841.31">class hd_mult_frontend_pgm(nn.Module): 
    '''
    Maps cosine similarites to object PMFs by marginalization

    Parameters
    ----------
    # cosine readout parameters
    num_features:   int
        input dimensionality
    num_classes:    int
        placeholder
    mat:            torch tensor
        Weight matrix (W)
    fixed_weights:  boolean
        Fix weight matrix (W) if activated
    s:              float
        Inverse softmax temperature
    trainable_s:    boolean
        Trainable inverse softmax temperature if activated    

    # Marginalization parameters
    marg_s:              float 
        inverse softmax temperature
    marg_m:             float
        threshold (shift)
    marg_in_act:         str
        input activation
    marg_exist_act:      str
        input activation for existence probability
    num_pos:            int
        number of positions
    '''
    @others
</t>
<t tx="ekr.20230415045841.32">def __init__(self,num_features, num_classes, mat, fixed_weights=True, s=1.0, trainable_s=True,
            marg_s=1,marg_trainable_s=True,marg_m=0,marg_in_act = "ReLU",marg_exist_act="Identity"):
    super(hd_mult_frontend_pgm, self).__init__()
    self.nline, self.nshape = 6, 9 #TODO not hardcode
    self.marg_trainable_s = marg_trainable_s
    self.metric = fixCos(num_features = num_features, num_classes = num_classes, mat=mat,fixed_weights=fixed_weights,s=s,trainable_s=trainable_s)

    self.marg_line = marginalization_line(s=marg_s, m=marg_m, trainable_s=marg_trainable_s, in_act=marg_in_act,exist_act=marg_exist_act)
    self.marg_shape = marginalization(s=marg_s, m=marg_m, trainable_s=marg_trainable_s, in_act=marg_in_act,exist_act=marg_exist_act,dims=(10,10,7)) # TODO not hardcode

</t>
<t tx="ekr.20230415045841.33">def forward(self,x,B,N): 
    x = self.metric(x)
    out_line = self.marg_line(x[:,:self.nline*11].view(B,N,self.nline,-1))
    out_shape = self.marg_shape(x[:,self.nline*11:].view(B,N,self.nshape,-1))
    return out_line, out_shape 

</t>
<t tx="ekr.20230415045841.34">def store_s(self,writer,epoch):

    # general s from fixCos
    writer.add_scalar('marg-s/marg-s', self.metric.get_s(), epoch )

    # store individual marginalization s if training active
    if self.marg_trainable_s:
        # from shape
        s_exist, s_type, s_size, s_color = self.marg_shape.get_s() 
        writer.add_scalar('marg-s/exist', s_exist, epoch )
        writer.add_scalar('marg-s/type', s_type, epoch )
        writer.add_scalar('marg-s/size', s_size, epoch )
        writer.add_scalar('marg-s/color', s_color, epoch )
        # from line
        s_exist, s_color = self.marg_line.get_s() 
        writer.add_scalar('marg-s/line-exist', s_exist, epoch )
        writer.add_scalar('marg-s/line-color', s_color, epoch )



</t>
<t tx="ekr.20230415045841.35">def generate_IM_pgm(n_in, num_pos_line, num_pos_shape, rng):
    '''
    Generate bipolar codebooks and matrix W for PGM dataset 

    Parameters
    ----------
    n_in:   int
        vector dimension (d)
    num_pos_line: int 
        number of positions for line
    num_pos_shape: int
        number of positions for shape
    rng:    numpy random number generator
        
    Return
    ------
    matrix: torch tensor
        Complete matrix W
    im_dict: torch tensor
        Codebooks
    '''
    # type and size only for shape, color for both shape and line
    num_type, num_size, num_color = 7, 10, 10

    # line
    max_dic = num_color
    n_out = num_pos_line*num_color + num_pos_line # num_pos for object detection
    num_per_pos = num_color+1
    im_dict = ((rng.integers(0,2,(2,max_dic,n_in))*2-1)).astype(np.float32)
    object_dict = ((rng.integers(0,2,(num_pos_line,n_in))*2-1)).astype(np.float32)
    matrix_line = np.zeros((n_out, n_in)).astype(np.float32)
    for pos in range(num_pos_line):
        for col in range(num_color):
            matrix_line[pos*num_per_pos+col]=im_dict[0,col]*im_dict[1,pos]
        matrix_line[(pos+1)*num_per_pos-1] = object_dict[pos]

    # shape
    n_out = num_type*num_pos_shape*num_size*num_color + num_pos_shape # +num_pos for object detection
    num_per_pos = num_color*num_size*num_type+1
    im_dict = ((rng.integers(0,2,(4,max_dic,n_in))*2-1)).astype(np.float32)
    object_dict = ((rng.integers(0,2,(num_pos_shape,n_in))*2-1)).astype(np.float32)
    matrix_shape = np.zeros((n_out, n_in)).astype(np.float32)
    for pos in range(num_pos_shape):
        for col in range(num_color):
            for siz in range(num_size):
                for typ in range(num_type):
                    matrix_shape[pos*num_per_pos+col*num_size*num_type+siz*num_type+typ]=im_dict[0,typ]*im_dict[1,siz]*im_dict[2,col]*im_dict[3,pos]
        matrix_shape[(pos+1)*num_per_pos-1] = object_dict[pos]

    matrix = np.concatenate((matrix_line,matrix_shape),axis=0)    

    return t.from_numpy(matrix), t.from_numpy(im_dict)


</t>
<t tx="ekr.20230415045841.36">@path neuro-vector-symbolic-architectures/nvsa/perception/
#
# Copyright 2023- IBM Inc. All rights reserved
# SPDX-License-Identifier: Apache2.0
#

import torch
import torch.nn as nn
import torch.hub

__all__ = ['ResNet', 'resnet18']

model_urls = {"resnet18": "https://download.pytorch.org/models/resnet18-f37072fd.pth"}


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20230415045841.37">def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                     padding=dilation, groups=groups, bias=False, dilation=dilation)

</t>
<t tx="ekr.20230415045841.38">def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)

</t>
<t tx="ekr.20230415045841.39">class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition"https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.

    expansion: int = 4

    @others
</t>
<t tx="ekr.20230415045841.4">@path neuro-vector-symbolic-architectures/nvsa/perception/
@language python
@tabwidth -4
</t>
<t tx="ekr.20230415045841.40">def __init__(self, inplanes: int, planes: int, stride: int = 1, downsample= None,
    groups: int = 1, base_width: int = 64, dilation: int = 1, norm_layer= None) -&gt; None:
    super().__init__()
    if norm_layer is None:
        norm_layer = nn.BatchNorm2d
    width = int(planes * (base_width / 64.0)) * groups
    # Both self.conv2 and self.downsample layers downsample the input when stride != 1
    self.conv1 = conv1x1(inplanes, width)
    self.bn1 = norm_layer(width)
    self.conv2 = conv3x3(width, width, stride, groups, dilation)
    self.bn2 = norm_layer(width)
    self.conv3 = conv1x1(width, planes * self.expansion)
    self.bn3 = norm_layer(planes * self.expansion)
    self.relu = nn.ReLU(inplace=True)
    self.downsample = downsample
    self.stride = stride

</t>
<t tx="ekr.20230415045841.41">def forward(self, x):
    identity = x

    out = self.conv1(x)
    out = self.bn1(out)
    out = self.relu(out)

    out = self.conv2(out)
    out = self.bn2(out)
    out = self.relu(out)

    out = self.conv3(out)
    out = self.bn3(out)

    if self.downsample is not None:
        identity = self.downsample(x)

    out += identity
    out = self.relu(out)

    return out


</t>
<t tx="ekr.20230415045841.42">class BasicBlock(nn.Module):
    expansion = 1
    @others
</t>
<t tx="ekr.20230415045841.43">def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,
             base_width=64, dilation=1, norm_layer=None):
    super(BasicBlock, self).__init__()
    if norm_layer is None:
        norm_layer = nn.BatchNorm2d
    if groups != 1 or base_width != 64:
        raise ValueError('BasicBlock only supports groups=1 and base_width=64')
    if dilation &gt; 1:
        raise NotImplementedError("Dilation &gt; 1 not supported in BasicBlock")
    self.conv1 = conv3x3(inplanes, planes, stride)
    self.bn1 = norm_layer(planes)
    self.relu = nn.ReLU(inplace=True)
    # self.relu = nn.LeakyReLU(0.1,inplace=True)
    self.conv2 = conv3x3(planes, planes)
    self.bn2 = norm_layer(planes)
    self.downsample = downsample
    self.stride = stride

</t>
<t tx="ekr.20230415045841.44">def forward(self, x):
    identity = x
    out = self.conv1(x)
    out = self.bn1(out)
    out = self.relu(out)
    out = self.conv2(out)
    out = self.bn2(out)
    if self.downsample is not None:
        identity = self.downsample(x)
    out += identity
    out = self.relu(out)
    return out

</t>
<t tx="ekr.20230415045841.45">class ResNet(nn.Module):
    @others
</t>
<t tx="ekr.20230415045841.46">def __init__(self, block, layers, num_classes= 512, zero_init_residual=False,
             groups=1, width_per_group=64, replace_stride_with_dilation=None,
             norm_layer=None, pretrained=False, no_maxpool=False):
    super(ResNet, self).__init__()
    if norm_layer is None:
        norm_layer = nn.BatchNorm2d
    self._norm_layer = norm_layer
    self.inplanes = 64
    self.dilation = 1
    self.in_channels = 3 if pretrained else 1
    if replace_stride_with_dilation is None:
        replace_stride_with_dilation = [False, False, False]
    if len(replace_stride_with_dilation) != 3:
        raise ValueError("replace_stride_with_dilation should be None "
                         "or a 3-element tuple, got {}".format(replace_stride_with_dilation))
    self.groups = groups
    self.base_width = width_per_group

    # If no maxpool -&gt; stride 1 conv and Identity maxpool        
    if no_maxpool:
        self.conv1 = nn.Conv2d(self.in_channels, self.inplanes, kernel_size=7, stride=1, padding=3, bias=False)
        self.maxpool = nn.Identity()
    else: 
        self.conv1 = nn.Conv2d(self.in_channels, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    self.bn1 = norm_layer(self.inplanes)
    self.relu = nn.ReLU(inplace=True)

    self.layer1 = self._make_layer(block, 64, layers[0])
    self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
    self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
    self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])
    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
    self.Tanh=nn.Tanh()
    self.fc = nn.Linear(512 * block.expansion, num_classes)

    for m in self.modules():
        if isinstance(m, nn.Conv2d):
            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)

    if zero_init_residual:
        for m in self.modules():
            if isinstance(m, BasicBlock):
                nn.init.constant_(m.bn2.weight, 0)

</t>
<t tx="ekr.20230415045841.47">def _make_layer(self, block, planes, blocks, stride=1, dilate=False):
    norm_layer = self._norm_layer
    downsample = None
    previous_dilation = self.dilation
    if dilate:
        self.dilation *= stride
        stride = 1
    if stride != 1 or self.inplanes != planes * block.expansion:
        downsample = nn.Sequential(
            conv1x1(self.inplanes, planes * block.expansion, stride),
            norm_layer(planes * block.expansion))

    layers = []
    layers.append(block(self.inplanes, planes, stride, downsample, self.groups,
                        self.base_width, previous_dilation, norm_layer))
    self.inplanes = planes * block.expansion
    for _ in range(1, blocks):
        layers.append(block(self.inplanes, planes, groups=self.groups,
                            base_width=self.base_width, dilation=self.dilation,
                            norm_layer=norm_layer))

    return nn.Sequential(*layers)

</t>
<t tx="ekr.20230415045841.48">def forward(self, x):
    x = x.repeat(1,self.in_channels,1,1)
    x = self.conv1(x)
    x = self.bn1(x)
    x = self.relu(x)
    x = self.maxpool(x)
    x = self.layer1(x)
    x = self.layer2(x)
    x = self.layer3(x)
    x = self.layer4(x)
    x = self.avgpool(x)
    x = torch.flatten(x, 1)
    x = self.fc(x)
    x = self.Tanh(x)
    return x

</t>
<t tx="ekr.20230415045841.49">def _resnet(arch, block, layers, pretrained, progress,**kwargs):
    model = ResNet(block, layers, pretrained=pretrained,**kwargs)

    if pretrained:
        # load from ImageNet-1k pretrained model
        # This is a advanced version to load only layers with same name and size 
        # (first conv and last fc are not loaded)
        print("Load pretrained model from ImageNet1k")
        pretrained_state = torch.hub.load_state_dict_from_url(model_urls[arch], progress=progress)
        model_state = model.state_dict()
        pretrained_state = { k:v for k,v in pretrained_state.items() if k in model_state and v.size() == model_state[k].size() }
        model_state.update(pretrained_state)
        model.load_state_dict(model_state)

    return model

</t>
<t tx="ekr.20230415045841.5">@path neuro-vector-symbolic-architectures/nvsa/perception/
#
# Copyright 2023- IBM Inc. All rights reserved
# SPDX-License-Identifier: Apache2.0
#


import torch as t
import torch.nn as nn
import torch.nn.functional as F
from torch.nn import Parameter
import math
import numpy as np

LOG_EPSILON = 1e-39

@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20230415045841.50">def resnet18(pretrained=False, progress: bool=True, **kwargs):
    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,**kwargs)</t>
<t tx="ekr.20230415045841.51"></t>
<t tx="ekr.20230415045841.52">@path neuro-vector-symbolic-architectures/nvsa/reasoning/
@language python
@tabwidth -4
</t>
<t tx="ekr.20230415045841.53">@path neuro-vector-symbolic-architectures/nvsa/reasoning/
#
# Copyright 2023- IBM Inc. All rights reserved
# SPDX-License-Identifier: Apache2.0
#
import torch as t
from .vsa_block_utils import block_binding2, block_binding3, match_prob, block_unbinding2, block_unbinding3, pmf2vec, match_prob_0, match_prob_multi, cyclic_shift, cosine2pmf 
VSA_WEIGHT= 2
EPS = 10 ** (-20)
# EPS = 10 ** (-38)

@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20230415045841.54">######################################### PGM of detectors and executors ########################### 
class vsa_rule_detector_PGM(object):
    @others
</t>
<t tx="ekr.20230415045841.55">def __init__(self,detector_act="threshold",detector_m=-1, detector_s=1,**kwargs):
    
    if detector_act == "threshold": 
        self.match_act = t.nn.Threshold(detector_m,0)
    elif detector_act == "hardtanh": 
        self.match_act = t.nn.Hardtanh(0,1)
    else: 
        self.match_act = getattr(t.nn, detector_act)()
    self.pmf2vec = pmf2vec

</t>
<t tx="ekr.20230415045841.56">def union(self,p_vsa_d): 
    row1 = block_binding3(p_vsa_d[:,0], p_vsa_d[:,1], p_vsa_d[:,2])
    row2 = block_binding3(p_vsa_d[:,3], p_vsa_d[:,4], p_vsa_d[:,5])
    row_prob = match_prob(row1, row2,self.match_act)

    # Constraint that two rows don't have the same sequence
    row1_shift = block_binding3(p_vsa_d[:,0], cyclic_shift(p_vsa_d[:,1],1), cyclic_shift(p_vsa_d[:,2],2))
    row2_shift = block_binding3(p_vsa_d[:,3], cyclic_shift(p_vsa_d[:,4],1), cyclic_shift(p_vsa_d[:,5],2))
    row_prob_shift = match_prob(row1_shift, row2_shift,self.match_act)

    # Neighboring panels should not have the same value
    flag2 = match_prob(p_vsa_d[:,0],p_vsa_d[:,1],self.match_act)# first column
    flag3 = match_prob(p_vsa_d[:,1],p_vsa_d[:,2],self.match_act) # last column
    flag4 = match_prob(p_vsa_d[:,3],p_vsa_d[:,4],self.match_act)# first column
    flag5 = match_prob(p_vsa_d[:,4],p_vsa_d[:,5],self.match_act) # last column
    flag6 = match_prob(p_vsa_d[:,6],p_vsa_d[:,7],self.match_act) # last column

    # Combine all probabilities
    prob_0 = row_prob*(1-row_prob_shift)*(1-flag2)*(1-flag3)*(1-flag4)*(1-flag5)*(1-flag6)+EPS

    return prob_0, VSA_WEIGHT



</t>
<t tx="ekr.20230415045841.57">def progression_plus(self,p_vsa_c, x_target):
    p1_12 = block_unbinding2(p_vsa_c[:,1],p_vsa_c[:,0])
    p1_23 = block_unbinding2(p_vsa_c[:,2],p_vsa_c[:,1])    
    p1_13 = block_unbinding2(p_vsa_c[:,2],p_vsa_c[:,0])
    p2_12 = block_unbinding2(p_vsa_c[:,4],p_vsa_c[:,3])
    p2_23 = block_unbinding2(p_vsa_c[:,5],p_vsa_c[:,4])    
    p2_13 = block_unbinding2(p_vsa_c[:,5],p_vsa_c[:,3])    
    p3_12 = block_unbinding2(p_vsa_c[:,7],p_vsa_c[:,6]) 
    s1 = match_prob(p1_12,x_target,self.match_act)
    s2 = match_prob(p1_23,x_target,self.match_act)
    s3 = match_prob(p2_12,x_target,self.match_act)
    s4 = match_prob(p2_23,x_target,self.match_act)
    s5 = match_prob(p3_12,x_target,self.match_act)
    s6 = match_prob(p1_13,block_binding2(x_target,x_target),self.match_act)
    s7 = match_prob(p2_13,block_binding2(x_target,x_target),self.match_act)

    s0 = t.clamp(match_prob_0(p1_12,self.match_act),min=0,max=1)
    result = s1*s2*s3*s4*s5*s6*s7*(1-s0)+EPS

    return  result,VSA_WEIGHT

    
</t>
<t tx="ekr.20230415045841.58">class vsa_rule_executor_PGM(object):
    @others
</t>
<t tx="ekr.20230415045841.59">def __init__(self,executor_act="threshold",executor_m=1, executor_s=1, executor_cos2pmf_act="Identity",**kwargs): 
    self.s = executor_s
    self.match_act = t.nn.Threshold(executor_m,0) if executor_act == "threshold" else getattr(t.nn, executor_act)()
    self.cos2pmf_act = executor_cos2pmf_act 
    self.pmf2vec = pmf2vec

</t>
<t tx="ekr.20230415045841.6">def log(x):
    return t.log(x + LOG_EPSILON)

</t>
<t tx="ekr.20230415045841.60">def union(self,vsa_cb_discrete_a,p_vsa_d): 
    temp1 = block_binding3(p_vsa_d[0], p_vsa_d[1], p_vsa_d[2])
    pred = block_unbinding3(temp1, p_vsa_d[6], p_vsa_d[7])
    sim = match_prob_multi(vsa_cb_discrete_a,pred,self.match_act)
    pred = cosine2pmf(sim,self.cos2pmf_act,self.s)
    return pred

</t>
<t tx="ekr.20230415045841.61">def progression_plus(self,vsa_cb_cont_a,p_vsa_c, x_target):
    pred = block_binding2(p_vsa_c[7],x_target)
    sim = match_prob_multi(vsa_cb_cont_a,pred,self.match_act)
    pred = cosine2pmf(sim,self.cos2pmf_act, self.s)
    return pred
</t>
<t tx="ekr.20230415045841.62">@path neuro-vector-symbolic-architectures/nvsa/reasoning/
#
# Copyright 2023- IBM Inc. All rights reserved
# SPDX-License-Identifier: Apache2.0
#
import torch as t
from .vsa_block_utils import block_binding2, block_binding3, match_prob, block_unbinding2, block_unbinding3, pmf2vec, match_prob_0, match_prob_multi, match_prob_multi_batched, cosine2pmf 
VSA_WEIGHT= 2
EPS = 10 ** (-20)


@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20230415045841.63">######################################### Extended Versions of detectors and executors ########################### 
class vsa_rule_detector_extended(object):
    '''
    VSA backend: rule probability computation

    Parameters
    ----------
    detector_act:   str
        activation function applied after vector similarity computation
    detector_m:     str     
        threshold value if detector_act=threshold
    detector_s:     str
        place holder        # TODO remove 

    '''
    @others
</t>
<t tx="ekr.20230415045841.64">def __init__(self,detector_act="threshold",detector_m=-1, detector_s=1,**kwargs): 

    self.match_act = t.nn.Threshold(detector_m,0) if detector_act == "threshold" else getattr(t.nn, detector_act)()
    self.pmf2vec = pmf2vec

</t>
<t tx="ekr.20230415045841.65">def distribute_three(self,p_vsa_d):
    # compute binding along first two rows/columns 
    row1 = block_binding3(p_vsa_d[:,0], p_vsa_d[:,1], p_vsa_d[:,2])
    row2 = block_binding3(p_vsa_d[:,3], p_vsa_d[:,4], p_vsa_d[:,5])
    col1 = block_binding3(p_vsa_d[:,0], p_vsa_d[:,3], p_vsa_d[:,6])
    col2 = block_binding3(p_vsa_d[:,1], p_vsa_d[:,4], p_vsa_d[:,7])
    # Compute the row/column probability 
    row_prob = match_prob(row1, row2,self.match_act)
    col_prob = match_prob(col1, col2,self.match_act)

    # Additional constraints that panels should be distinct
    flag2 = match_prob(p_vsa_d[:,0],p_vsa_d[:,1],self.match_act)#  (1,1) and (1,2) 
    flag3 = match_prob(p_vsa_d[:,1],p_vsa_d[:,2],self.match_act) # (1,2) and (1,3)
    flag4 = match_prob(p_vsa_d[:,3],p_vsa_d[:,4],self.match_act)# (2,1) and (2,2)
    flag5 = match_prob(p_vsa_d[:,4],p_vsa_d[:,5],self.match_act) # (2,2) and (2,3)
    flag6 = match_prob(p_vsa_d[:,6],p_vsa_d[:,7],self.match_act) # (3,1) and (3,2)
    
    # Compute overall probability, EPS for numerical stability  
    prob_0 = row_prob*col_prob*(1-flag2)*(1-flag3)*(1-flag4)*(1-flag5)*(1-flag6)+EPS
    return prob_0, VSA_WEIGHT

</t>
<t tx="ekr.20230415045841.66">def constant(self,p_vsa_d): 
    # Compute similarity between panels within each row
    s1_12 = match_prob(p_vsa_d[:,0],p_vsa_d[:,1],self.match_act) # (1,1) and (1,2)
    s1_13 = match_prob(p_vsa_d[:,0],p_vsa_d[:,2],self.match_act) # (1,1) and (1,3)
    s2_12 = match_prob(p_vsa_d[:,3],p_vsa_d[:,4],self.match_act) # (2,1) and (2,2)
    s2_13 = match_prob(p_vsa_d[:,4],p_vsa_d[:,5],self.match_act) # (2,2) and (2,3)
    s3 = match_prob(p_vsa_d[:,6],p_vsa_d[:,7],self.match_act)    # (3,1) and (3,1)

    # Compute overall probability, EPS for numerical stability  
    result = s1_12*s1_13*s2_12*s2_13*s3+EPS
    return  result, VSA_WEIGHT


</t>
<t tx="ekr.20230415045841.67">def progression_plus(self,p_vsa_c, x_target):
    # Compute difference between neighboring panels 
    p1_12 = block_unbinding2(p_vsa_c[:,1],p_vsa_c[:,0])
    p1_23 = block_unbinding2(p_vsa_c[:,2],p_vsa_c[:,1])    
    p2_12 = block_unbinding2(p_vsa_c[:,4],p_vsa_c[:,3])
    p2_23 = block_unbinding2(p_vsa_c[:,5],p_vsa_c[:,4])    
    p3_12 = block_unbinding2(p_vsa_c[:,7],p_vsa_c[:,6]) 
    # Compute difference between first and last panel in each row
    p1_13 = block_unbinding2(p_vsa_c[:,2],p_vsa_c[:,0])
    p2_13 = block_unbinding2(p_vsa_c[:,5],p_vsa_c[:,3])    

    # Compare the delta vector with target delta vector (1, or 2)
    s1 = match_prob(p1_12,x_target,self.match_act)
    s2 = match_prob(p1_23,x_target,self.match_act)
    s3 = match_prob(p2_12,x_target,self.match_act)
    s4 = match_prob(p2_23,x_target,self.match_act)
    s5 = match_prob(p3_12,x_target,self.match_act)
    # Compare the delta vector with TWICE target delta vector (1, or 2)
    s6 = match_prob(p1_13,block_binding2(x_target,x_target),self.match_act)
    s7 = match_prob(p2_13,block_binding2(x_target,x_target),self.match_act)
    # check if delta is not zero
    s0 = t.clamp(match_prob_0(p1_12,self.match_act),min=0,max=1)

    # Compute overall probability, EPS for numerical stability  
    result = s1*s2*s3*s4*s5*s6*s7*(1-s0)+EPS
    return  result,VSA_WEIGHT

</t>
<t tx="ekr.20230415045841.68">def progression_minus(self,p_vsa_c, x_target):
    # Same implementation as progression_plus, only the 
    # order of the panels in the unbinding is inverted

    # Compute difference between neighboring panels 
    p1_12 = block_unbinding2(p_vsa_c[:,0],p_vsa_c[:,1])
    p1_23 = block_unbinding2(p_vsa_c[:,1],p_vsa_c[:,2])    
    p2_12 = block_unbinding2(p_vsa_c[:,3],p_vsa_c[:,4])
    p2_23 = block_unbinding2(p_vsa_c[:,4],p_vsa_c[:,5])    
    p3_12 = block_unbinding2(p_vsa_c[:,6],p_vsa_c[:,7]) 
    # Compute difference between first and last panel in each row
    p1_13 = block_unbinding2(p_vsa_c[:,0],p_vsa_c[:,2])    
    p2_13 = block_unbinding2(p_vsa_c[:,3],p_vsa_c[:,5])    

    # Compare the delta vector with target delta vector (1, or 2)
    s1 = match_prob(p1_12,x_target,self.match_act)
    s2 = match_prob(p1_23,x_target,self.match_act)
    s3 = match_prob(p2_12,x_target,self.match_act)
    s4 = match_prob(p2_23,x_target,self.match_act)
    s5 = match_prob(p3_12,x_target,self.match_act)
    # Compare the delta vector with TWICE target delta vector (1, or 2)
    s6 = match_prob(p1_13,block_binding2(x_target,x_target),self.match_act)
    s7 = match_prob(p2_13,block_binding2(x_target,x_target),self.match_act)

    # check if delta is not zero
    s0 = t.clamp(match_prob_0(p1_12,self.match_act),min=0,max=1)

    # Compute overall probability, EPS for numerical stability  
    result = s1*s2*s3*s4*s5*s6*s7*(1-s0)+EPS
    return  result,VSA_WEIGHT

</t>
<t tx="ekr.20230415045841.69">def arithmetic_plus(self,p_vsa_c,vsa_cb_cont_a): 
    # Bind first two panels in each row
    p1_12 = block_binding2(p_vsa_c[:,0],p_vsa_c[:,1])
    p2_12 = block_binding2(p_vsa_c[:,3],p_vsa_c[:,4])
    p3_12 = block_binding2(p_vsa_c[:,6],p_vsa_c[:,7])
    # Compare last panel 
    s1 = match_prob(p1_12,p_vsa_c[:,2],self.match_act)
    s2 = match_prob(p2_12,p_vsa_c[:,5],self.match_act)
    # for last row, check if bound vector is within the dictionary range 
    flag =  t.clamp(t.sum(match_prob_multi_batched(vsa_cb_cont_a,p3_12,self.match_act),dim=-1) ,min=0,max=1)

    # Compute overall probability, EPS for numerical stability  
    result = s1*s2*flag+EPS
    return  result, 6*VSA_WEIGHT 

</t>
<t tx="ekr.20230415045841.7">def generate_IM(n_in,dims=(5,6,10,4),rng=None):
    '''
    Generate bipolar codebooks and matrix W 

    Parameters
    ----------
    n_in:   int
        vector dimension (d)
    dims:   tupel 
        codebook sizes (type, size, color, pos)
    rng:    numpy random number generator
        
    Return
    ------
    matrix: torch tensor
        Complete matrix W
    im_dict: torch tensor
        Codebooks
    '''
    num_type, num_size, num_color, num_pos = dims
    max_dic = num_pos if num_pos&gt;num_color else num_color
    n_out = num_type*num_pos*num_size*num_color + num_pos # +num_pos for object detection
    num_per_pos = num_color*num_size*num_type+1
    im_dict = ((rng.integers(0,2,(4,max_dic,n_in))*2-1)).astype(np.float32)
    object_dict = ((rng.integers(0,2,(num_pos,n_in))*2-1)).astype(np.float32)
    matrix = np.zeros((n_out, n_in)).astype(np.float32)
    for pos in range(num_pos):
        for col in range(num_color):
            for siz in range(num_size):
                for typ in range(num_type):
                    matrix[pos*num_per_pos+col*num_size*num_type+siz*num_type+typ]=im_dict[0,typ]*im_dict[1,siz]*im_dict[2,col]*im_dict[3,pos]
        matrix[(pos+1)*num_per_pos-1] = object_dict[pos]
    return t.from_numpy(matrix), t.from_numpy(im_dict)

</t>
<t tx="ekr.20230415045841.70">def arithmetic_minus(self,p_vsa_c,vsa_cb_cont_a): 
    # Unbind first two panels in each row
    p1_12 = block_unbinding2(p_vsa_c[:,0],p_vsa_c[:,1])
    p2_12 = block_unbinding2(p_vsa_c[:,3],p_vsa_c[:,4])
    p3_12 = block_unbinding2(p_vsa_c[:,6],p_vsa_c[:,7])
    # Compare with last panel 
    s1 = match_prob(p1_12,p_vsa_c[:,2],self.match_act)
    s2 = match_prob(p2_12,p_vsa_c[:,5],self.match_act)
    # for last row, check if bound vector is within the dictionary range 
    flag = t.clamp(t.sum(match_prob_multi_batched(vsa_cb_cont_a,p3_12,self.match_act),dim=-1) ,min=0,max=1)

    # Compute overall probability, EPS for numerical stability  
    result = s1*s2*flag+EPS
    return  result,6*VSA_WEIGHT
    
</t>
<t tx="ekr.20230415045841.71">class vsa_rule_executor_extended(object):
    '''
    VSA backend: rule execution

    Parameters
    ----------
    executor_act:   str
        Activation after computing the match
    executor_m:     float
        Threshold value if executor_act=threshold
    executor_s:     float 
        Scaling of similarities before executor_cos2pmf_act
    executor_cos2pmf_act: str
        Cosine to pmf function 
    '''
    @others
</t>
<t tx="ekr.20230415045841.72">def __init__(self,executor_act="threshold",executor_m=1, executor_s=1, executor_cos2pmf_act="Identity", **kwargs): 
    self.s = executor_s
    self.match_act = t.nn.Threshold(executor_m,0) if executor_act=="threshold" else getattr(t.nn, executor_act)()
    self.cos2pmf_act = executor_cos2pmf_act 
    self.pmf2vec = pmf2vec

</t>
<t tx="ekr.20230415045841.73">def distribute_three(self,vsa_cb_discrete_a,p_vsa_d): 
    # Bind all vectors in the first row
    temp1 = block_binding3(p_vsa_d[0], p_vsa_d[1], p_vsa_d[2])
    # Unbind the first row with first two panels in last row =&gt; prediction
    pred = block_unbinding3(temp1, p_vsa_d[6], p_vsa_d[7])
    # Compute similarities of predcition and codebooks
    sim = match_prob_multi(vsa_cb_discrete_a,pred,self.match_act)
    # Transform similarities to PMF
    pred = cosine2pmf(sim,self.cos2pmf_act,self.s)
    return pred

</t>
<t tx="ekr.20230415045841.74">def constant(self,vsa_cb_discrete_a,p_vsa_d): 
    # Prediction is simply the penultimate panel    
    pred =p_vsa_d[7] 
    # Compute similarities of predcition and codebooks
    sim = match_prob_multi(vsa_cb_discrete_a,pred,self.match_act)
    # Transform similarities to PMF
    pred = cosine2pmf(sim,self.cos2pmf_act,10)
    return pred

</t>
<t tx="ekr.20230415045841.75">def progression_plus(self,vsa_cb_cont_a,p_vsa_c, x_target):
    # prediction is binding of penultimate panel and target delta
    pred = block_binding2(p_vsa_c[7],x_target)
    # Compute similarities of predcition and codebooks
    sim = match_prob_multi(vsa_cb_cont_a,pred,self.match_act)
    # Transform similarities to PMF
    pred = cosine2pmf(sim,self.cos2pmf_act, self.s)
    return pred

</t>
<t tx="ekr.20230415045841.76">def progression_minus(self,vsa_cb_cont_a,p_vsa_c, x_target):
    # prediction is unbinding of penultimate panel and target delta
    pred = block_unbinding2(p_vsa_c[7],x_target)
    # Compute similarities of predcition and codebooks
    sim = match_prob_multi(vsa_cb_cont_a,pred,self.match_act)
    # Transform similarities to PMF
    pred = cosine2pmf(sim, self.cos2pmf_act,self.s)
    return pred

</t>
<t tx="ekr.20230415045841.77">def arithmetic_plus(self,vsa_cb_continuous_a, p_vsa_c): 
    # prediction is binding of panels in last row 
    pred = block_binding2(p_vsa_c[6],p_vsa_c[7])
    # Compute similarities of predcition and codebooks
    sim = match_prob_multi(vsa_cb_continuous_a,pred,self.match_act)
    # Transform similarities to PMF
    pred = cosine2pmf(sim, self.cos2pmf_act,self.s)
    return pred 

</t>
<t tx="ekr.20230415045841.78">def arithmetic_minus(self,vsa_cb_continuous_a, p_vsa_c): 
    # prediction is unbinding of panels in last row 
    pred = block_unbinding2(p_vsa_c[6],p_vsa_c[7])
    # Compute similarities of predcition and codebooks
    sim = match_prob_multi(vsa_cb_continuous_a,pred,self.match_act)
    # Transform similarities to PMF
    pred = cosine2pmf(sim,self.cos2pmf_act,self.s)
    return pred</t>
<t tx="ekr.20230415045841.79">@path neuro-vector-symbolic-architectures/nvsa/reasoning/
#
# Copyright 2023- IBM Inc. All rights reserved
# SPDX-License-Identifier: Apache2.0
#

import torch as t
import torch.nn.functional as F
import numpy as np


'''
Sparse block codes toolbox for NVSA backend
'''

@others
@language python
@tabwidth -4
</t>
<t tx="ekr.20230415045841.8">class fixCos(nn.Module):
    '''
    Linear layer with (potentially) fixed weights and 
    cosine similarity metric  

    Parameters
    ----------
    num_features:   int
        input dimensionality
    num_classes:    int
        placeholder
    mat:            torch tensor
        Weight matrix (W)
    fixed_weights:  boolean
        Fix weight matrix (W) if activated
    s:              float
        Inverse softmax temperature
    trainable_s:    boolean
        Trainable inverse softmax temperature if activated    
    '''
    @others
</t>
<t tx="ekr.20230415045841.80">def cosine2pmf(sim,act="Softmax",s=40): 
    # Infer PMF from the similarities (e.g., cosine) 
    if act == "Softmax": 
        out = t.nn.functional.softmax(sim.view(1,-1)*s, dim=-1)
    elif act == "Identity": 
        out = t.nn.functional.normalize(sim.view(1,-1), p=1, dim = -1)
    return out

</t>
<t tx="ekr.20230415045841.81">def block_binding2(x,y):
    """
    Bind two vectors together

    Parameters
    ----------
    x: torch FloatTensor (_, _k, _L)
        input vector 1.
    y: torch FloatTensor (_, _k, _L)
        input vector 2.

    Returns
    -------
    res: torch FloatTensor (_, _k, _L)
        bound output vector
    """
    res  = binding_circular(x,y)
    return res

</t>
<t tx="ekr.20230415045841.82">def cyclic_shift(x,n):
    """
    Blockwise cyclic shift 

    Parameters
    ----------
    x: torch FloatTensor (_, _k, _L)
        input vector 1.
    n: int
        number of blocks to be shifted

    Returns
    -------
    out: torch FloatTensor (_, _k, _L)
        shifted output vector
    """
    return t.roll(x,n,dims=1)


</t>
<t tx="ekr.20230415045841.83">def block_unbinding2(x,y): 
    """
    Unbind vector y from x

    Parameters
    ----------
    x: torch FloatTensor (_, _k, _L)
        input vector 1.
    y: torch FloatTensor (_, _k, _L)
        input vector 2.

    Returns
    -------
    res: torch FloatTensor (_, _k, _L)
        unbound output vector
    """
    res  = inv_binding_circular(x,y)
    return res 

</t>
<t tx="ekr.20230415045841.84">def block_binding3(x,y,z): 
    return block_binding2(block_binding2(x,y),z)

</t>
<t tx="ekr.20230415045841.85">def block_unbinding3(x,y,z): 
    return block_unbinding2(block_unbinding2(x,y),z)

</t>
<t tx="ekr.20230415045841.86">def binding_circular(A, B, alpha=1):
    """
    Binds two block codes vectors by blockwise cicular convolution. 

    Parameters
    ----------
    A: torch FloatTensor (_, _k, _l)
        input vector 1
    B: torch FloatTensor  (_, _k, _l)
        input vector 2
    alpha: int, optional
        specifies multiplicative factor for number of shifts (Default value '1')
    Returns
    -------
    C: torch FloatTensor (_k)
        k-dimensional offset vector that is the result of the binding operation.
    """
    ndim = A.dim()
    # add batch dimension (1) if not there yet
    if ndim==2: 
        A = A.unsqueeze(0)
        B = B.unsqueeze(0)
    
    batchSize,k,l = A.shape
    
    # prepare inputs
    A = t.unsqueeze(A,1) # input
    B = t.unsqueeze(B,2) # filter weigths
    B = t.flip(B, [3]) # flip input
    B = t.roll(B, 1, dims=3) # roll by one to fit addition

    # reshape for single CONV
    A = t.reshape(A, (1, A.shape[0]*A.shape[2], A.shape[3]))
    B = t.reshape(B, (B.shape[0]*B.shape[1], B.shape[2], B.shape[3]))

    # calculate C = t.remainder(B+A*alpha, self._L)
    C = F.conv1d(F.pad(A, pad=(0,l-1), mode='circular'), B, groups=k*batchSize)
    
    C = t.reshape(C, (batchSize, k, l))

    # Remove batch dimension if it was not there intially
    if ndim==2: 
        C = C.squeeze(0)
    return C

</t>
<t tx="ekr.20230415045841.87">def inv_binding_circular(C,A, alpha=1):
    """
    Inverse binding of two block codes vectors by blockwise cicular correlation. 

    Parameters
    ----------
    A: torch FloatTensor (_, _k, _l)
        input vector 1
    B: torch FloatTensor  (_, _k, _l)
        input vector 2
    alpha: int, optional
        specifies multiplicative factor for number of shifts (Default value '1')
    Returns
    -------
    C: torch FloatTensor (_k)
        k-dimensional offset vector that is the result of the binding operation.
    """

    ndim = A.dim()
    # add batch dimension (1) if not there yet
    if ndim==2: 
        A = A.unsqueeze(0)
        C = C.unsqueeze(0)
    batchSize,k,l = A.shape

    A = t.unsqueeze(A,1) # input
    C = t.unsqueeze(C,2) # filter weigths

    A = t.reshape(A, (1, A.shape[0]*A.shape[2], A.shape[3]))
    C = t.reshape(C, (C.shape[0]*C.shape[1], C.shape[2], C.shape[3]))
        
    B = F.conv1d(F.pad(A, pad=(0,l-1), mode='circular'), C, groups=k*batchSize)
    B = t.reshape(B, (batchSize, k, l))
        
    B = t.flip(B, [2]) # flip input
    B = t.roll(B, 1, dims=2) # roll by one to fit addition

    # Remove batch dimension if it was not there intially
    if ndim==2: 
        B = B.squeeze(0)

    return B



</t>
<t tx="ekr.20230415045841.88">def match_prob(x,y, act=t.nn.Identity()): 
    '''
    Compute similarity between two block codes vectors

    Parameters
    ----------
    x: torch FloatTensor (B,k,l) 
        input vector 1
    y: complex vector (B,k,l)
        input vector 2 
    Output
    ------
    sim: torch FloatTensor (B,)
        output similarity 
    '''
    _,k,l = x.shape
    sim = 1/k*t.sum(x*y, dim=(1,2))
    sim = act(sim)
    return sim

</t>
<t tx="ekr.20230415045841.89">def match_prob_0(x,act=t.nn.Identity()): 
    '''
    Compute similarity between a block codes vectors and the zero vector

    Parameters
    ----------
    x: torch FloatTensor (B,k,l) 
        input vector 1
    Output
    ------
    sim: torch FloatTensor (B,)
        output similarity 
    '''
    _,k,l = x.shape
    # Just add up all 0 elements of every block
    sim = 1/k*t.sum(x[:,:,:1], dim=(1,2))
    sim = act(sim)
    return sim

</t>
<t tx="ekr.20230415045841.9">def __init__(self, num_features, num_classes, mat, fixed_weights=True, s=1.0, trainable_s=True):
    super(fixCos, self).__init__()
    self.num_features = num_features
    self.n_classes = num_classes
    self.s = Parameter(t.Tensor([s]), requires_grad=trainable_s)
    self.mat = mat/math.sqrt(num_features)
    self.W = Parameter(mat, requires_grad=False) if fixed_weights else Parameter(mat)

</t>
<t tx="ekr.20230415045841.90">def match_prob_multi(x,y,act=t.nn.Identity()): 
    '''
    Compute similarity between a dictionary and a query vector

    Parameters
    ----------
    x: torch FloatTensor (scene_dim,k,l) 
        dictionary
    y: torch FloatTensor (k,l) 
        query vector
    Output
    ------
    sim: torch FloatTensor (scene_dim,)
        output similarity 
    '''

    _, k,l= x.shape
    y =y.unsqueeze(0)
    sim = 1/k*t.sum(x*y, dim=(1,2))
    sim = act(sim)
    return sim

</t>
<t tx="ekr.20230415045841.91">def match_prob_multi_batched(dictionary,y,act=t.nn.Identity()): 
    '''
    Compute similarity between a dictionary and a batch of query vectors

    Parameters
    ----------
    x: torch FloatTensor (scene_dim,k,l) 
        dictionary
    y: torch FloatTensor (B,k,l) 
        query vector
    Output
    ------
    sim: torch FloatTensor (B, scene_dim,)
        output similarity 
    '''

    bs, k,l = y.shape
    dictionary =dictionary.unsqueeze(0)
    y = y.unsqueeze(1)
    sim = 1/k*t.sum(dictionary*y, dim=(2,3))
    sim = act(sim)
    return sim

</t>
<t tx="ekr.20230415045841.92">def pmf2vec(dictionary,pmfs): 
    '''
    Map PMF to d-dimensional complex vector

    Parameters
    ----------
    dictionary: torch FloatTensor (scene_dim, k, l)
        codebook 
    pmfs: torch FloatTensor (B,scene_dim)

    Return 
    ------
    out: Tensor (B,k, l)
    '''
    scene_dim , k, l = dictionary.shape
    ndim = pmfs.dim() 
    bs = pmfs.shape[0]

    # batched version
    if ndim == 2:
        pmfs = pmfs.unsqueeze(0)
        bs = 1
    
    superpos = F.linear(pmfs.reshape(-1,scene_dim),dictionary.reshape(scene_dim,-1).transpose(1,0))
    
    # Reshape depending on batched/ no batched versions 
    superpos = superpos.view(-1,k,l) if ndim==2 else superpos.view(bs,-1,k,l)

    return superpos

</t>
<t tx="ekr.20230415045841.93">def check_collision(codebook_block): 
    # check for collisions inside the codebook 
    sum = 0
    for k in range(codebook_block.shape[0]): 
        sum += match_prob_multi(codebook_block,codebook_block[k]).sum()

    return sum&gt;codebook_block.shape[0]


</t>
<t tx="ekr.20230415045841.94">def block_continuous_codebook(
    device,d=2048,
    scene_dim=12,
    k=1,
    rng = np.random.default_rng(seed=42),
    fully_orthogonal=True,
):
    '''
    Create continuous codebook with sparse block codes codewords. 
    

    Parameters
    ----------
    x: torch FloatTensor (scene_dim,k,l) 
        dictionary
    y: torch FloatTensor (B,k,l) 
        query vector
    Output
    ------
    sim: torch FloatTensor (B, scene_dim,)
        output similarity 
    '''

    codebook_block = sample_block_continuous_codebook(device,d,scene_dim,k,rng)
    # resample codebooks if we want to have fully orthogonality
    while fully_orthogonal and check_collision(codebook_block):
        codebook_block = sample_block_continuous_codebook(device,d,scene_dim,k,rng) 

    return codebook_block, codebook_block # TODO remove one of the codebooks

</t>
<t tx="ekr.20230415045841.95">def sample_block_continuous_codebook(
    device,
    d=2048,
    scene_dim=511,
    k=1,
    rng = np.random.default_rng(seed=42),
):

    l = d//k
    codebook_block = t.zeros((scene_dim,k,l)).to(device)

    # Zero element: in each block the first element is set to 1
    codebook_block[0,:,0] = 1

    # Sample first element
    for k_it in range(k):
        # sample index which is not l/2
        idx = rng.integers(1,l)
        codebook_block[1,k_it,idx]=1

    # Define the remaining codewords by binding 
    for i in range(2,scene_dim): 
        codebook_block[i]=block_binding2(codebook_block[i-1],codebook_block[1])

    return codebook_block

</t>
<t tx="ekr.20230415045841.96">def block_discrete_codebook(
    device,
    d=2048,
    scene_dim=511,
    k=1,
    rng = np.random.default_rng(seed=42),
):

    l = d//k
    codebook_block = t.zeros((scene_dim,k,l)).to(device)
    for scene in range(scene_dim):
        for k_it in range(k): 
            codebook_block[scene,k_it,rng.integers(0,l)]=1

    return codebook_block, codebook_block

</t>
</tnodes>
</leo_file>
